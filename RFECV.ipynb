{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1c5Gn3lbY6BIgfBBvJVdIikBqytNYtxi7",
      "authorship_tag": "ABX9TyO3AUY8oDMI3E3mhT9UWS3b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pathway2008/Weblog/blob/main/RFECV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gwebx6EARonE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/Weblog/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Weblog/test.csv')\n",
        "sub = pd.read_csv('/content/drive/MyDrive/Weblog/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['sessionID','userID'],axis=1,inplace=True)\n",
        "test.drop(['sessionID','userID'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "hyuB99FnRsZC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "warnings.filterwarnings('ignore')\n",
        "!apt-get -qq install fonts-nanum\n",
        "\n",
        "\n",
        "fe = fm.FontEntry(\n",
        "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
        "    name='NanumGothic')\n",
        "fm.fontManager.ttflist.insert(0, fe)\n",
        "plt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ItRzBg9RsUR",
        "outputId": "d37ca561-8de6-4a23-fecc-c8bc0c1014f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "object_columns = train.drop(columns=['TARGET']).select_dtypes(include='object')\n",
        "for feature in object_columns.columns:\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Convert the column to string type\n",
        "    train[feature] = train[feature].astype(str)\n",
        "    le.fit(train[feature])\n",
        "    train[feature] = le.transform(train[feature])\n",
        "\n",
        "    # Make sure the test set has the same data type\n",
        "    test[feature] = test[feature].astype(str)\n",
        "\n",
        "    # Handle unseen labels in the test set\n",
        "    for label in np.unique(test[feature]):\n",
        "        if label not in le.classes_:\n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "\n",
        "    test[feature] = le.transform(test[feature])"
      ],
      "metadata": {
        "id": "xuVSzz9WRsSC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkegam1PRsPa",
        "outputId": "4fc3e9d2-68b8-4177-e846-9dafc7688003"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
        "from math import sqrt\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.feature_selection import RFECV\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "jtbQKN4URsNE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVp5C3csR5FE",
        "outputId": "5ba7b2d7-4a5f-4d68-8755-c994a773a0d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 252289 entries, 0 to 252288\n",
            "Data columns (total 17 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   TARGET               252289 non-null  float64\n",
            " 1   browser              252289 non-null  int64  \n",
            " 2   OS                   252289 non-null  int64  \n",
            " 3   device               252289 non-null  int64  \n",
            " 4   new                  252289 non-null  int64  \n",
            " 5   quality              252289 non-null  float64\n",
            " 6   duration             252289 non-null  float64\n",
            " 7   bounced              252289 non-null  int64  \n",
            " 8   transaction          252289 non-null  float64\n",
            " 9   transaction_revenue  252289 non-null  float64\n",
            " 10  continent            252289 non-null  int64  \n",
            " 11  subcontinent         252289 non-null  int64  \n",
            " 12  country              252289 non-null  int64  \n",
            " 13  traffic_source       252289 non-null  int64  \n",
            " 14  traffic_medium       252289 non-null  int64  \n",
            " 15  keyword              252289 non-null  int64  \n",
            " 16  referral_path        252289 non-null  int64  \n",
            "dtypes: float64(5), int64(12)\n",
            "memory usage: 32.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=False)"
      ],
      "metadata": {
        "id": "8EYrfuN1R8Qv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse_scorer(y_true, y_pred):\n",
        "    return sqrt(mean_squared_error(y_true, y_pred))"
      ],
      "metadata": {
        "id": "VY4GLaiRR8On"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train.drop(['TARGET'], axis=1)\n",
        "y = train['TARGET']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 43)"
      ],
      "metadata": {
        "id": "pNHmM6wdR-0P"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "\n",
        "rfecv = RFECV(estimator=xgb_model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit RFECV on the training data\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfecv.support_]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# Transform the training and testing sets using only the selected features\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_test_selected = rfecv.transform(X_test)\n",
        "\n",
        "# Now, you can train your XGBoost model using the selected features\n",
        "xgb_model.fit(X_train_selected, y_train)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train_selected, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "y_pred = xgb_model.predict(X_test_selected)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcLW3KKxSvg_",
        "outputId": "7310006c-4de1-49e8-dd53-7a88701a32b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['browser', 'OS', 'device', 'new', 'quality', 'duration', 'bounced',\n",
            "       'transaction', 'transaction_revenue', 'continent', 'subcontinent',\n",
            "       'country', 'traffic_source', 'keyword'],\n",
            "      dtype='object')\n",
            "xgb_scores: 2.8848577963868527\n",
            "RMSE: 2.7634728673342157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(random_state=43)\n",
        "\n",
        "rfecv = RFECV(estimator=xgb_model, step=1, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit RFECV on the training data\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfecv.support_]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# Transform the training and testing sets using only the selected features\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_test_selected = rfecv.transform(X_test)\n",
        "\n",
        "# Now, you can train your XGBoost model using the selected features\n",
        "xgb_model.fit(X_train_selected, y_train)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train_selected, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "y_pred = xgb_model.predict(X_test_selected)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYad2UKnU8tm",
        "outputId": "d4948652-59f2-492d-9fbf-30c946e915a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['browser', 'device', 'new', 'quality', 'duration', 'bounced',\n",
            "       'transaction', 'continent', 'subcontinent', 'country', 'traffic_source',\n",
            "       'keyword'],\n",
            "      dtype='object')\n",
            "xgb_scores: 2.9168561335046284\n",
            "RMSE: 2.8094806047963967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "\n",
        "rfecv = RFECV(estimator=xgb_model, step=1, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit RFECV on the training data\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfecv.support_]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# Transform the training and testing sets using only the selected features\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_test_selected = rfecv.transform(X_test)\n",
        "\n",
        "# Now, you can train your XGBoost model using the selected features\n",
        "xgb_model.fit(X_train_selected, y_train)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train_selected, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "y_pred = xgb_model.predict(X_test_selected)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foR3fAunTmSy",
        "outputId": "a764baf9-67ca-4cd2-d382-8381706398e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['browser', 'OS', 'device', 'new', 'quality', 'duration', 'bounced',\n",
            "       'transaction', 'transaction_revenue', 'continent', 'subcontinent',\n",
            "       'country', 'traffic_source', 'traffic_medium', 'keyword',\n",
            "       'referral_path'],\n",
            "      dtype='object')\n",
            "xgb_scores: 2.8491038194831644\n",
            "RMSE: 2.745348382572756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "\n",
        "rfecv = RFECV(estimator=xgb_model, step=1, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit RFECV on the training data\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfecv.support_]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# Transform the training and testing sets using only the selected features\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_test_selected = rfecv.transform(X_test)\n",
        "\n",
        "# Now, you can train your XGBoost model using the selected features\n",
        "xgb_model.fit(X_train_selected, y_train)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train_selected, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "y_pred = xgb_model.predict(X_test_selected)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-1xcGk0WHYm",
        "outputId": "7915a20a-5956-416e-e9f8-702db2339d93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['browser', 'OS', 'device', 'new', 'quality', 'duration', 'bounced',\n",
            "       'transaction', 'transaction_revenue', 'continent', 'subcontinent',\n",
            "       'country', 'traffic_source', 'traffic_medium', 'keyword',\n",
            "       'referral_path'],\n",
            "      dtype='object')\n",
            "xgb_scores: 2.8491038194831644\n",
            "RMSE: 2.745348382572756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfecv = RFECV(estimator=xgb_model, step=1, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1),\n",
        "         np.sqrt(-rfecv.cv_results_['mean_test_score']),\n",
        "         marker='o', linestyle='-', color='b')\n",
        "plt.title('RMSE vs. Number of Features')\n",
        "plt.xlabel('Number of Features Selected')\n",
        "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "3jaA9uMeW_r4",
        "outputId": "c5997d49-71b6-4c31-8ca1-ebfe69eb68d3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAI/CAYAAADKhhAQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADTxklEQVR4nOzdeVzN2f8H8NdtX1S0CEkiSwjZ9z1bjJF9mUHGMMY6mGFmjH0f+zYYgzFjCYNhQtn3wWQpWw2yjKJQqbSf3x/3d+9Xqlu3PvW51ev5ePRQn89Z3vd00btzPucohBACREREREREVCToyR0AERERERERSYdJHhERERERURHCJI+IiIiIiKgIYZJHRERERERUhDDJIyIiIiIiKkKY5BERERERERUhTPKIiIiIiIiKECZ5RERERERERQiTPCIiIiIioiKESR4REZGO69atG/T09HD16lW5Q9F5R44cQevWrWFlZQUrKyt06NBB7pCIiAqcgdwBEBERkWaxsbEQQiAuLk7uUHSav78/PD09IYRA2bJl4ejoiMDAQLnDIiIqcJzJIyLZ1a1bFwqFItMPKysruLm5Ydy4cbhz547Gdvbt2wc9PT0oFAro6enh0KFDuY7p8ePHMDMzU8fxww8/aCyfkpKC3bt3o1+/fqhUqRJMTU1haGgIGxsbNGvWDBMnTsTTp08zrVu7du0sX/+HH56enrl+TYXNRx99BIVCAQMDA+zfvz/H9TZt2lTsxoqUFixYACEEJk2ahGfPnuHvv//GixcvtGpj79696n9HsvtwcHDIp1eSNwkJCZg7dy42bdokdyhEJBPO5BGR7KKiogAArq6usLa2BgAIIfDu3TuEhYUhKCgIQUFBWLduHebPn4+vv/4603bevn0LIQQUCgWEEFi6dCm6d++eq5jWrVuHd+/eqduKiYnJsmxAQAAGDhyI+/fvAwBKliyJqlWrwsTEBFFRUbh69SouXbqE7t27w9HRMUN9Vdvvv/6suLm55er1FEaqcUlNTcWYMWPQvn17WFpaZltPNdvFWa/i5++//4a+vj5mz54NPb3c/R5bNWtqbm6OunXraixrb2+fqz7yW3h4OKZPnw4nJyeMGDFC7nCISAZM8ohIZ8yfPx8ff/xxhuvPnz/HTz/9hHnz5uGbb76Bo6MjBgwYkGU7NWrUQExMDM6cOYMbN25k+4PahxISErB582YYGBigdevWOHHiRJZl79y5g9atWyM2Nhaenp6YP38+ateuna5MbGwsDh8+jGbNmmnsN6vXX9yZmpri+fPn+P7777Fq1Sq5wyEd9fr1a8THx8Pe3h5mZmZ5bs/FxQXnz5+XIDIiooLH5ZpEpPPKlSuH2bNnY+7cuQCA6dOnayxvYGCAMWPGAABWrFihdX87d+7Eq1ev0KNHD5QvX15j2QkTJiA2NhbdunXDoUOHMiR4AFCiRAn0798fJiYmWsdCwJgxY2BhYYF169YhICBA7nBIR6lmbvn3jIiISR4RFSKjRo2Cnp4eHjx4gODgYI1lR4wYAXNzc+zatQsvX77Uqp+1a9cCAMaOHauxXGJiIo4fPw4AmDJlChQKhVb9UM6UK1cOc+bMQWpqKkaOHIm0tDS5QyIdlJqaKncIREQ6g0keERUapUqVgo2NDQDlxijZlf3000+RmJiI9evX57iPy5cv459//oGbmxtat26tsazqGUBVf7po+fLlUCgUGDx4cLZljx07BgMDAzRp0iTd9cjISEydOhVubm4wNzeHgYEBSpUqhUaNGmHixIl4+/ZtfoWvNmbMGNStWxfXrl3T6vuZmZo1a8LAwABhYWEay4WHh8PAwAAlSpTI9H7Tpk1hbGyM2NhYPH/+HF999RWqVq0KMzMzlClTBu3bt8e+ffvU7xFAOZazZs1C7dq1YWFhASsrK7Rv3x4HDhzQ6jX4+vrCy8sLjo6OMDY2hp2dHdq0aYPVq1cjMTEx2/pCCOzcuRNdunSBvb09jI2NUaZMGXh6emLXrl3pYv6Qubk5atasCQB49eoVxo4diwoVKsDMzAx16tRBUlKSVq8FUC6RXrduHTp16gQHBwcYGxvD2toadevWxddff41///0303o//vijehMUZ2dnAMp/G97fHGXJkiVaxyOFo0ePolevXurXU7p0abRr1w4bNmxASkpKlvWSkpKwc+dO9OvXD7Vq1UKZMmVgZGQES0tLuLm5YeLEiZn++7d3795sx0K1wkHlyy+/hEKhwJ49e7J9PTVr1oSenh6uXLmS4d6SJUvStfPXX3+hWbNmsLCwgL29PTZu3JihTnx8PJYsWYLGjRujVKlSMDU1RcWKFfHpp5/i8uXLGmMJDAzEsGHDUKlSJRgbG8PQ0BD29vbo0KEDli5dmu1rISoWBBGRzJycnAQAsX///mzLlixZUgAQx48fz3Bvy5YtAoCoU6eOEEKIe/fuCYVCIcqUKSMSExNzFMugQYMEALFhwwYhhBBDhgwRAMT48eMzLV+hQgUBQAwfPjxH7WdGm9evrXv37gkAwtTUVLx9+1Zj2X79+gkAYt68eenqlylTRgAQhoaGwsXFRTRp0kTUqVNHWFhYCADi1q1bkscthBCtW7cWAMTy5cuFEEJcunRJKBQKYWVlJcLCwrKst3z5cgFAtG7dOtP7qvF+9OiRxv4fPXokAIis/qts0qSJACB8fX2FjY2NACDKlCkjGjRoIOzt7dV1Bw0aJNLS0sTt27dF+fLlBQBha2sr6tevL2xtbdXlJk+enO1Y+Pn5if79+wsAwsjISNSsWVPUrVtX/b0AIKpVqyZCQ0OzbOvNmzeibdu26vJOTk6iUaNG6nEBIDp37izi4uIyra+q8/r1a+Hm5iYACBcXF9GoUSNRpkyZbN9nH7p48aL679H7Y1itWjWhr6+vfu/NmTMnQ93du3eL5s2bi+bNm4sGDRoIAMLY2Fh9rXnz5mLXrl1axfPhvyPaSkhIUH+PAIiyZcuKhg0biipVqqiv1atXT7x8+TLT+l9++aW6nIWFhahUqZJo1KiRcHNzEyYmJgKAsLS0FBcuXEhX78yZM6JFixYax2LFihXp6qj+fduyZUu2r0v1/jh16lSGezNmzFC3s3HjRnWM9evXF66uruL7779PV/7WrVvq77menp5wdXUVDRo0UP99UCgUGeqo7N27VxgaGgoAwtzcXNSsWVM0adJE1KhRQxgaGgpra+tsXwtRccAkj4hkl9Mk5/Tp0+r/2KOjozPcz+yHs65duwoAYtu2bdnG8eLFC2FkZCRKlSql/gE3uyRvz549QqFQqBO9nCaT78vPJE8IIdzd3QUAjT/sxsXFCXNzc6FQKNIlCKrk4uOPP86QWKWkpIibN2+K1NTUfIn7wyRPCCE+//xzAUD0798/y3oFleSp4rO2thYVK1bM8MPv6dOnRbly5QQAsXfvXlG9enVhYWEhtm/fLlJSUtTlDhw4IKysrAQAcfjwYY191alTRwAQ48aNE5GRker7CQkJYv369cLc3FxdLikpKUM7ycnJ6uS0ffv2IigoKN39f/75R9SqVUsAEP369cs0FlWSN3z4cOHi4iKuX7+eabmcuHTpkjAzMxMARLNmzcSlS5fS3Y+MjBTfffedOtn79ttvs2xL9f1ycnLKdTxC5D3J69WrlwAg3N3dxcWLF9PdCwkJEa1atRIARNOmTTP9u7Ny5UqxZs0a8fjx4wz34uLixMSJEwUAUalSpXTvo/fldCykTvKmT58ujIyMxPfffy/i4+Mzbefx48fC2tpaABBjx45Nl+ympqaKvXv3qv8+rF+/Pl3d6OhoYWlpKQCImTNnZugjLi5O3LlzJ9vXQlQcMMkjItnlJMl58OCBcHZ2FgDE4sWLMy2T2Q9nfn5+6t+cZ2fOnDkCgJg0aZL6WnZJnhBC/Pzzz8LIyEg9i3Ls2LFs+3pffid5ixcvFgBE7969syyza9cuAUC0bNlSfS06Olr9m/bMkur8llmS9+rVK/Vv+/38/DKtV9BJnoWFhXj48GGmZXbu3CkACDs7O6FQKDKdgRZCiEWLFgkAolOnThr7+vD9+SFfX191uc2bN2fZT9OmTbNMEMLDw9Uzkx8mKUIokzwzMzNhbm4ugoODs4wlO4mJiaJy5coCgOjWrZvGX5Ds27dPPcNz7ty5TMvoQpK3e/duAUA4OzuL2NjYTMvExcWJqlWrCgBix44dWveRmpoqqlWrlmXCJYR8SZ6FhUW2qxq6dOkiAIgpU6ZkWcbf318AECVLlkw3o/znn38KAKJBgwbZxktU3PGZPCLSSUIIREVF4eLFi5gyZQpq166NR48eYfjw4Zg0aVKO2/Hw8ECtWrUQEBCAc+fOZVkuJSUFGzZsgJ6eHkaPHq1VrMOHD8fFixfRuHFj3L9/H506dUKbNm1w8eJFrdrp2bNntocv+/v7a9UmAPTv3x8KhQJHjhzBu3fvMi2ze/duAMAnn3yivqbayMLS0hIWFhZa95sfrK2t1c9YjR49OkfPn+W3YcOGqZ+B+tDHH38MhUKBiIgI9OjRA+3bt8+0XI8ePQAoz3nTpHTp0pgzZ06W97t06aI+huO3335Ldy8lJUW92+z69euhr6+faRv29vbqs9W2b9+eaZn4+Hj06NEDVapU0RivJrt27cKDBw9gbm6OX375BUZGRlmW9fLyQv/+/SGEUO+ym99u3ryZ7d/HD5/3+/HHHwEod/U1NzfPtF0zMzN89dVXALIeX0309PTg7u4OALh165bW9fPT27dv8c0332R5//bt2zhy5AgcHBwwc+bMLMt16NABTZo0QVRUFA4fPqy+rnqWUVcPoSfSJTwnj4h0Rs+ePbO8Z21tjR9//BGjRo3Sut3x48djxIgRWLFiBVq2bJlpmQMHDuDZs2fo3r07KlWqpHUf9evXx6VLl7Bjxw589913OHPmDJo3b46+ffti2bJlOfqhJLvD0BUKRbaHpWfG0dERzZs3x/nz5+Hr64tevXqlu//27VscOXIExsbG6NOnj/p6qVKl0KpVK5w9exZTpkzBokWLskwMCtKQIUPwyy+/4Ny5c5g/fz5mzZolazyaNugxMTGBvb09wsPD0bt37yzLVaxYEQAQFRWlsa9evXrB1NRUY5nBgwfjwIEDuHr1KtLS0tSHgl+/fh1hYWFwc3NDnTp1NLah2nwns002VDS9npzYv38/AGDAgAGws7PLtvyYMWOwa9cu+Pv7IyYmBpaWlnnqPzs5OQy9QoUK6s8jIiJw9epVWFlZoVu3bhrr5WR84+PjcfbsWdy8eRMPHz5EREQEYmNjkZSUhLt37wLI/v1S0GrXrq0x8ff19QWgTNqzO8uwSZMmuHz5Mq5cuYK+ffsCANq2bQtLS0v89ddf2Lt3b57fg0RFGZM8ItIZHyY5xsbGSEtLw+nTp+Hq6pqrBA9Q/tA7bdo0HDx4EKGhoeofqN+3Zs0aANkfm6CJQqHAoEGD0KdPH/z888+YPXs2fHx8cPLkSWzduhWenp4a6+fnYegDBgzA+fPnsW/fvgxJ3oEDB5CQkAAvLy+ULFky3b3t27ejU6dOWLp0KQ4dOoSpU6di4MCBMDY2zpc4c0KhUGD9+vWoW7cuFi1ahMGDB+dpRimvsttZVTVWtWrVyrZMdho1apRtmYYNGwIAYmNj8eLFC5QtWxYAcOPGDQDA06dP0aJFC41tREdHA4DGHUhVO2zm1j///ANAOWuTE02aNIG5uTni4uIQEBCANm3a5Kn/7Gh7GLpqfBMTE9GqVSuNZRMSEgAodydNTk6GoaGh+l5cXBwWL16MZcuWITY2VmM7unacSHbvCdUY/fnnn9meefnkyRMA6d+DJUuWxJ49e9CvXz/06dMH7du3xzfffAMPD4+8BU5UBDHJIyKdkVmSk5CQgCpVquDChQs4ePCgelmbNkxMTDBq1CjMnTsXa9asUS+pUgkKCsKZM2dQvXr1HP/AqYmRkRFGjx6NQYMG4csvv8Tvv/+OHj164MCBA9n+hj+/9OnTB+PHj8fhw4eRmJiYLqnIbKmmSoUKFXDjxg389NNP+PHHH+Ht7Y1p06ZhwoQJGD16dL7PpmSlZs2amDhxIpYsWYLRo0fnahmrVHJ6PqIUY6VK2DQpU6aM+vPo6Gh1nVevXgFQzv5cuHAhR/1pem329vY5aiMrERERAAAnJ6ccldfX14eDgwOCg4O1PvuyIKjGNyEhIcfja2homC7JS0xMRPfu3XHq1CkAyqS+T58+aNiwIZydnWFrawsTExN4e3tj27Zt+fNC8iC794RqjB4/fpztMTgqH74HO3bsiLt372Lx4sXYuHEjOnbsiNq1a2Pq1Kno27evTqw2INIFfCaPiHSaiYmJ+tmNadOm5frA49GjR8PIyAibN29GXFxcunuqWTzVmVFSsbKywm+//YaRI0ciNTUVw4cPV/8Gv6DZ2dmhffv2ePv2LY4dO6a+/ubNG/j5+cHa2hpdu3bNtK6xsTHGjx+PBw8eYNOmTbCyssK0adPg5OSE33//vaBeQgYzZsyAo6Mjjh8/jh07dkjevtSHa0vx3spJTO/P7mTWZ6dOnSCUG69l+/Hs2bMs+7Gyssrdi/ggNqHhTL4PqcqqlqDqomrVquV4fJOSktItW1y2bBlOnToFExMT7Nu3D3///TcmT56M1q1bq88i1NPTk+VZ1Jy893L6nliwYEGOx+jDZ0sB5S8yli1bhtDQUEyfPh3Pnj3DwIEDUbNmzWxnCImKC939V5KI6P8NGTIElStXxt27d7Fly5ZctVG2bFn07dsXUVFR2Lp1q/p6dHQ0fvvtN1hYWGDIkCESRZzesmXLYGRkhJcvX+LMmTP50kdODBgwAIDy0GSVP/74A8nJyejTp4/GjS8A5QzlZ599hjt37mDu3LmIiorCp59+Cj8/v3yNOyvm5uZYuXIlAOCrr75SLzHMqeySC9VMky559OhRtmVevHih/tzGxkb9uWpZ6fv35aSacVQty8tOamoqnj9/nq6uLpFifFWHhs+cORNeXl5ZlpP6e5jd3wUhhHoWLi+kfg/a2tpi9uzZePDgAXr16qXe+ErTMmOi4oJJHhHpPAMDA/Vs3owZMxAfH5+rdiZOnAgAWLVqlfqHmi1btiAuLg5Dhw7Ntx0kzczM1L/h1jYRkVLPnj1hYmKCQ4cOISkpCYDmpZpZ0dfXx3fffYdJkyYhLS0Ns2fPzpd4c6Jnz57w9PTEixcvMG3atBzVMTExAZD99+Lq1at5jk9qOVmWqorb3t4etra26uuurq4AlMuT3759mz8BaqFx48YAgBMnTuSo/N9//424uDiYmJigQYMG+RlarqjGNyoqCvfu3dO6fnx8PEJDQwFo3oQqJSVFstmqnP5dCAoKynJnXm2oxujSpUt5but9JUuWxO7du9GoUSNERkZi7dq1krZPVBgxySOiQkG1FOf58+fqbeC1Va9ePbRs2RLBwcHw9fWFEALr1q2DQqHAmDFjpA34PY8fP1bPCrm4uORbP9mxtLRE165dERUVhePHjyMiIgInT56Es7MzmjdvrnV7qpmG69evSx2qVlavXg1TU1Ns2LBB426FKqrnhgIDAzWW+/XXXyWJT0p//fUXHj58qLGMaunqh5tRNGjQAObm5khJSUk3my0X1Y6JO3fuzNEzdqtWrQKgPG5ClZzokgoVKqiP0ti0aZPW9d9PojTNqu/fvz/bpMzAQLnlQnYzdDn9uyDV83+qzXL+/vtvyY9/0NfXVz+zLfe/SUS6gEkeERUKenp66q3yFy9enOulQxMmTAAArFy5EseOHUNISAg6d+6MqlWrShVqOkIIfP311wAANzc31KtXL1/6yan+/fsDUC7Z3Lt3L1JTUzF48OBctaWaTfhwR86C5uzsjO+++w5paWkYNWpUts8OqWaQNP3gunHjRgQEBOjcJg4pKSnw9vZWz8R+6NixYzhw4AAAZNiN1szMTD1jO3369FzNNkmpR48ecHNzQ2xsLIYMGaLxObOdO3di9+7d0NfXx9SpUwswSu2MHDkSgPIXD5rO5cyMjY2NenfhrGaRIyIiMGnSpHS7cWZGtXIgIiJC4w6cqr8LBw4cyDJxvHXrFtasWZPtcu6caNmypXo2z9vbO9vdQ7WlK/8mEekCJnlEVGh4eXnB3d0d0dHRuT4QuUePHqhYsSL8/f3Vh/bm5diELl26YO3atZnORAQGBuKjjz6Cj48PSpQooRO74XXr1g0lSpTAwYMH1ZumZJXkRUVFYdWqVQgJCUl3PTk5GZs3b1Yvjxw0aFD+Bp0DU6ZMQbVq1XD9+vVsZ1G8vb1hYGCAEydO4LvvvkNycrL6XnJyMpYtW4Yvv/wSI0eORIkSJfI7dK0MHDgQZ86cQZcuXfDgwQP19aSkJPz888/o3bs3hBAYPnx4prOzc+bMQbly5RAdHY3mzZvjl19+ybAZUFxcHPbs2ZPvh47r6elh69atsLCwwNGjR9G6desMy/hevHiByZMnq9+jM2fOzPbsOjmNHz8etWvXRnJyMjp27Igff/wxw9LYxMREHDlyBJMmTcpQX5UkTpw4ESdPnkx37/Tp02jRogXCwsIwbtw4jXFYWFigdOnSePfunXpjKUA5W/j+97tjx46oWLEiXr9+jf79+2f45Zmvry86duyIqlWrSnJMgUKhwIYNG6Cvr49//vkHTZs2xYkTJzLMOIaHh2PlypXYs2dPuuvXr1/Hr7/+muF52devX+Prr7/Gvn37AOjGv0lEshNERDJzcnISAMT+/fuzLXvgwAEBQBgZGYlHjx6lu7dlyxYBQNSpU0djG8uWLRMABADh4uIi0tLSsiw7ZMgQAUCMHz8+w73k5GShUCjUbTk6OooGDRqIRo0aibJly6qv16hRQ/zzzz9Z9qF6/a6urqJ58+YaP1q3bi1ev36t8fVlZ/DgwerYGjZsmGW5s2fPqsvZ2toKNzc3UadOHWFhYaG+7uHhIeLj4/MUT1Zat24tAIjly5fnqPyJEyfUcQEQrVu3zrLsqlWr1N+70qVLiy5duoiOHTsKW1tbAUC0atVKREdHCysrK5HVf5Wq+E6dOqUxLtX398P364dUcWfX11dffSUACIVCIVxdXYW7u7uwtLRU1x84cKBITk7Osp979+6JatWqqcubmpqK2rVri3r16oly5coJfX199fdW2zhz4/r16+niKVOmjGjYsKGoVq2a0NPTEwCEmZmZWLVqlcZ2Hj16JAAIJyenPMWT039HshIWFiaaNm2qfj2GhoaiZs2aokGDBsLR0VEYGhoKAKJKlSoZ6kZHR4uGDRuq65YrV040aNBAlCtXTv292rlzpzrGqVOnZhnHuHHj0v07V7duXWFiYiK2bduWrtyFCxfU7x9TU1PRpk0b4enpKSpXriwACAcHBxEUFCR69OiR5ft9xowZAoCYMWNGjsbo4MGD6d6zNjY2on79+qJWrVrCxsZGfX3evHnp6s2ePVsAEHp6esLBwUHUr19fVKtWTRgZGanrfP/99zmKgaioK3RJ3vPnz9X/AWn6yO1f8tu3b4thw4aJihUrChMTE1GhQgXx6aefisDAwGzrPnnyRIwbN064uLgIExMTUa5cOeHl5SUuXLiQq1iIiosaNWoIAMLPzy9H5Vu1aiUAiC+//DLddR8fHwFANGvWTGP96OhoUapUKQFArFu3TmPZ0aNHCwDi22+/zfT+wYMHxZdffikaNmwobGxshIGBgTAxMRFOTk6id+/eYvfu3Rp/4BZCCDc3t2z/TVN96Ovri7CwMI3tZefEiRNCX19fKBQK8fPPP2dZ7uXLl8Lb21u4uroKExMTAUAYGBiIcuXKiR49eggfH58sE+Rjx44JZ2dn0bt372xff1a6du0qAIiNGzfmuM6wYcPUY9W9e3eNZc+ePSt69eolypYtKwwNDYWtra1o0qSJWL16tUhISBBCCOHo6CjMzc0zre/p6SkUCoX4+++/NfZTo0aNHH3fzMzMsu3r6tWrQgjl+Pbo0UM4ODgIIyMjUbZsWdGjRw9x+PBhjX2oJCUliS1btoiPPvpIlC9fXpiYmAhTU1NRoUIF0apVKzFnzhxx7969TOuam5tnGWduJSUlic2bN4uuXbuqX5O1tbWoV6+e+O6778TTp0+zbSMsLEzo6+uLmjVr5imWnP47oklaWprYu3ev6Nu3r6hYsaIwMzMTJiYmwsHBQTRp0kR8++23Wf7i5927d+LHH38UjRo1EpaWlsLExERUq1ZNjBs3TgQHBwshhNi3b5/Gf5dU7UyePFmdWNrb24uPPvpI/PvvvxnKPnz4UHzxxRfqn18sLCxEzZo1xbRp09Tv208++UQoFApx5cqVDPWXLFkiAIglS5bkeIxevXol5s+fL1q3bi3s7OyEoaGhsLS0FJUrVxYfffSRWLt2rYiMjExX5++//xZeXl6iQoUKwsDAQAAQxsbGokqVKsLb21tcvnw5x/0TFXUKIbQ4oEYHhIaGwtnZGbVq1YKnp2eW5Tp27Ih27dpp1bavry/69OmD5ORkdOnSBc7Oznj06BGOHDkCAwMD7N69G927d8+07tWrV+Hp6YnIyEh06NABNWrUQFhYmPrg4bVr16qXYRARFXXdu3fH4cOHAQDXrl1D/fr1ZY6IiIio+Ci0Sd6QIUMk3R0sLCwMNWrUgLGxMfz8/FC7dm31vVu3bsHDwwMJCQkICgqCo6NjurpxcXFwc3PDixcvcPjwYbRt21Z978mTJ/Dw8MDDhw9x+fJl/qBDRMXCvn378Nlnn8Hd3R1HjhyBsbGx3CEREREVG9x45f+pDvZdt25dugQPAGrXro3169cjJiYm0/Og1q1bh0ePHmHOnDnpEjxAuaXyjh07kJKSotM7ghERSalXr1548+YNTp48yQSPiIiogHEmD8otqW1tbWFtbY0HDx5AoVBkKCOEgLOzM16/fo1Xr16l2764Zs2aePLkCcLCwrLcia1169Y4d+4c/vvvP5QtW1aSuImIiIiIiD7EmTwonxeJjo5Gp06dMk3wAOW2vx07dsTbt29x7do19fXw8HDcuXMHLVq00LjVdqdOnSCEwOnTp6UOn4iIiIiISI1JHoCbN28CAOrUqaOxnLu7OwDlM3pS1CUiIiIiIpKagdwB5NaVK1fQpk0b3L59G9HR0bC0tIS7uzuGDh2KgQMHZjkjl5nQ0FAAyufnNFHdV5XPa90PJSYmIjExUf11WloaXr9+DRsbG61eDxERERERFS1CCLx9+xblypWDnp7mubpCl+SZm5vD3NwcFhYWcHZ2Rr169ZCSkoKQkBCcPn0ax48fx44dO7B//34YGRnlqM3o6GgAgKWlpcZyFhYW6crnte6HFixYgFmzZmUfMBERERERFUtPnz5F+fLlNZYpdEmenZ0dYmNjM70XERGBTz/9FL6+vpg6dSqWLVuWozZVs2fZJYUmJibpyue17oemTZuGr776Sv11dHQ0KlSogEePHqmTRNJecnIyTp06hbZt26bbMIfyF8ddHhx3eXDc5cFxlwfHXR4cd3no0ri/ffsWzs7OOcoLCl2Sp4mdnR327duHKlWqYO3atZg5c2a2M2zA/xKwpKQkjeUSEhIAAKamppLU/ZCxsXGmW41bW1vn6HVQ5pKTk2FmZgYbGxvZ/3IWJxx3eXDc5cFxlwfHXR4cd3lw3OWhS+Ou6j8nj3EVuY1XzMzM0L9/fyQlJeHy5cs5qqPaFTMmJkZjOdX993fRzEtdIiIiIiIiqRW5JA8AqlSpAgCIjIzMUXnVpihPnjzRWE5138nJSZK6REREREREUiuSSV5ycjKA7DdDUXF1dQUA3LhxQ2M51f3q1atLUpeIiIiIiEhqRTLJUx1WXqtWrRyVb9q0KUxNTeHn5wchRKZl0tLS4OfnBzMzMzRt2lR9vVKlSnB2dsaFCxey3BAGAI4ePQoAaN++fU5fBhERERERkdaKXJJ3//597N69Gw0aNEDFihVzVMfU1BQ9e/bEo0ePsH///kzL7N+/H48fP0aPHj3Um62oDBgwALGxsdi4cWOmda9du4Zz586hadOm2Z6nR0RERERElBeFLsl7+PAhwsLCMr139uxZeHh4IC0tLcfHJ6hMnz4dxsbGGD16NAIDA9Pdu3XrFkaPHg0jIyN8//33Gep+9dVXsLa2xvTp03Hq1Kl09548eYJBgwZBoVBg9uzZWsVERERERESkrUJ3hMKff/6JKVOmoEmTJqhcuTJsbGzw9u1bXLlyBTdv3oSFhQV27tyJli1bZqi7aNEi+Pr6Yvv27Rlm1KpXr44tW7ZgyJAhqF+/Pjw9PVGxYkU8evQIvr6+EEJgy5YtqFGjRoZ2bWxssG/fPnTv3h0dOnRAhw4d4OrqivDwcBw6dAjv3r3DvHnz0KFDh3wbFyIiIiIiIqAQJnndunXD/fv3cfbsWQQEBCAhIQEWFhaoWrUqvvvuO4wePRrlypXLtO7s2bMRHx+P3bt3Y8qUKRnuDxgwAK6urliyZAlOnz4NX19f2NjYwMvLC1OmTEH9+vWzjKtNmza4efMmFi1ahGPHjuHMmTOwtLREu3btMGHCBD6LR0REREREBaLQJXkuLi5Yv359rur269cPhw8fhoeHR5Zl6tati99//z1X7VeqVAkbNmzIVV0iIiIiIiIpFLokLy9++eUXuUMgIiIiIiLKV4Vu4xUiIiIiIiLKGpM8IiIiIiKiIoRJHhERERERURFSrJ7Jo9xJTQXOnQPCwoCyZYGWLQF9fbmjIiIiIiKizDDJI43++AMYPx549ux/18qXB1auBLy85IuLiIiIiIgyx+WalKU//gB6906f4AHAf/8pr//xhzxxERERERFR1pjkUaZSU5UzeEJkvKe6NmGCshwREREREekOJnmUqXPnMs7gvU8I4OlTZTkiIiIiItIdTPIoU2Fh0pYjIiIiIqKCwSSPMlW2rLTliIiIiIioYDDJo0y1bKncRVOhyPy+QgE4OirLERERERGR7mCSR5nS11cekwBkTPRUX69YwfPyiIiIiIh0DZM8ypKXF7B3L+DgkP66vb3yOs/JIyIiIiLSPUzySCMvLyA0FDh1CqhcWXlt+XImeEREREREuopJHmVLXx9o0wZo21b59e3bsoZDREREREQaMMmjHHNzU/4ZGChvHERERERElDUmeZRjqiTv1i154yAiIiIioqwxyaMcUyV5jx4Bb9/KGwsREREREWWOSR7lmK3t/w4/53N5RERERES6iUkeaaV2beWfXLJJRERERKSbmOSRVrj5ChERERGRbmOSR1phkkdEREREpNuY5JFW3l+uKYS8sRARERERUUZM8kgrrq7Kw9HfvAGeP5c7GiIiIiIi+hCTPNKKsTFQtarycy7ZJCIiIiLSPUzySGvcYZOIiIiISHcxySOtcfMVIiIiIiLdZSBFI2lpaQgMDERwcDCeP3+OuLg4GBkZoWTJkqhYsSLq1q0LW1tbKboiHcAkj4iIiIhId+U6yUtKSsKePXuwZ88enDhxAvHx8RCZbLeoUCgAAFWrVsXHH3+MTz75BDVq1Mh9xCQ71XLNO3eA5GTA0FDeeIiIiIiI6H+0TvLi4uKwYsUKrFixAq9evULJkiXRrl07tG7dGpUrV4adnR3s7OwQHx+Ply9f4sWLF7hy5QrOnj2LxYsXY/HixWjXrh1mzZqFZs2a5cdronzm5ARYWABv3wLBwUDNmnJHREREREREKloleT4+PpgwYQKioqLQq1cvfP7552jRooV6ti4rgwcPBgC8evUKv/76KzZu3IiWLVuiX79+WLFiBUqXLp37V0AFTqEAatUCLl1SLtlkkkdEREREpDtytPFKdHQ0+vXrh88//xxjxozBf//9h+3bt6Nly5bZJnjvs7GxwcSJE3H37l0cP34cT548gZubG44cOZLrF0Dy4A6bRERERES6KUdJ3k8//YTSpUvj33//xbfffotSpUrlueO2bdvi/PnzWLduHSZNmpTn9gICAmBiYgKFQoElS5ZoVXfhwoVQKBQ5+qiZybTV5cuXoaenl23dzZs35/l16gpuvkJEREREpJtytFzz66+/1mrGThu9evVCz54989RGcnIyvL29YWhoiMTERMTFxWlVv0WLFvjmm280lklJScGyZctgmMkuIwkJCRBCoHnz5mjRokWWbdSrV0+ruHSZKsnjTB4RERERkW7JUZKXXwmeip5e3o7rW7BgAW7fvo3Fixfjq6++0rp+ixYtNCZnALBnzx4IITBo0KAsy3To0AEzZ87Uuv/CSJXkPXkCREcDVlbyxkNEREREREqF/jD0oKAgzJs3D5MnT4a7u3u+9bNmzRoYGxvD29s73/ooTEqVAsqXV34eFCRvLERERERE9D9aJ3kDBw7Evn37srwfGhoKPz8/jW3MmjUL5ubm2nadQWpqKry9veHk5IQZM2bkub2sBAYG4uzZs+jbty9sbGzyrZ/Chks2iYiIiIh0j9ZJ3q5du/DPP/9keX/jxo3o0qWLxjYSEhKQkJCgbdcZLF26FNeuXcOmTZtgYmKS5/aysnr1agDA6NGj862Pwki1wyY3XyEiIiIi0h2SL9cUQkjdZKaCg4MxY8YMjBgxAq1bt863fqKiovD777/D3d0dTZo0ybd+CiPusElEREREpHu0OgxdVwghMHz4cFhbW2Px4sX52tcvv/yC+Pj4HM3i+fr64ujRowgJCcHbt29hbW2NRo0aYdSoUejatWu29RMTE5GYmKj+OiYmBoBy99Dk5OTcv4h8Ur06ABgiMFAgKSkF+bw/T66pxk4Xx7Ao47jLg+MuD467PDju8uC4y4PjLg9dGndtYiiUSd6aNWtw/vx5HDx4EFb5uK2jEALr1q2DlZUVBg4cmGU5S0tLWFhYwMTEBFWrVkXz5s2RkJCAu3fvwtfXF4cOHcKIESOwYcMGjTuVLliwALNmzcpw3c/PD2ZmZpK8JiklJyugr98N0dF6+PXXU7Czeyd3SBr5+/vLHUKxxHGXB8ddHhx3eXDc5cFxlwfHXR66MO7x8fE5LlvokrzQ0FBMmzYN/fr1w0cffZSvfR05cgQPHjzAuHHjNCZZ9erVU8+6fejRo0fo27cvNm3ahFq1amHcuHFZtjNt2rR0R0DExMTA0dERHTt2hKWlZe5fSD6qXl2B27cBO7t26Nq1YJbqais5ORn+/v7w8PDI9JxDyh8cd3lw3OXBcZcHx10eHHd5cNzloUvjnlW+kZlCl+SNGDECJiYm6s1Q8tOaNWsAAF988UWu23B2dsaff/6JypUrY+HChRg7dmyWs3nGxsYwNjbOcN3Q0FD2N1VW6tQBbt8G7twxQI8eckejmS6PY1HGcZcHx10eHHd5cNzlwXGXB8ddHrow7tr0X6jOyfv5559x/PhxrFixAnZ2dvna17///oujR4+iXbt2qK58+CzXypYtiy5duiAsLAwhISESRagbuPkKEREREZFuydVM3ubNm3H48OFM77148QIAUFu1v76GMtp49eoVJk+ejC5dumDw4MFa19fW2rVrIYSQ7NiEKlWqAAAiIyNRtWpVSdrUBUzyiIiIiIh0i9ZJnomJCSIiIhAREaGxXFBQkMb72m4k8uzZM0RHR+PIkSMaNy8BlIetqzYwuXTpktZHH8TFxWHr1q1wcHBAD4nWIKp2w9HVZ+tyS5XL37sHJCUBRkbyxkNEREREVNxpneRps6uLlMqXL48pU6YgLS0tyzJPnz6Fj48PmjZtimbNmkGhUMDR0VHrvn777TdERUVhwoQJMDCQ5rHFa9euwcTEBC4uLpK0pyvKlwesrIDoaGWip2ECl4iIiIiICkCh2XjFxsYm2zPxTp8+DR8fH3Ts2BEzZ87MdV9r166FgYEBRowYkes2Pozr7Nmz6N27N0xMTCRpU1coFMolm+fPK5dsMskjIiIiIpJXodp4pSCcOXMGgYGB6NGjB8qVK5ejOnfu3EFUVFSm9/bv34+ePXvC0tIS8+bNkzBS3aFK7G7dkjcOIiIiIiIqoJm8yMhImJmZyX6g9/jx4xEcHIxdu3ZleYi66tgEbTZc2bhxIzZs2IDmzZvDyckJpUqVwuvXr3H+/HmEhITA3t4ePj4+RWrDlfdx8xUiIiIiIt2hdZIXFxcHfX39HC07PHz4MMaNG4fHjx8DABo0aIBZs2ahc+fO2keaA6qYMostIiICq1atAgD4+fmhT58+Gcq8evUKBw4cQN26ddGuXbsc9zt48GBERUXh/PnzuHDhApKTk2FlZQVXV1d4e3tj5MiRKFWqVC5fle5jkkdEREREpDu0TvImTZqEbdu24dWrVxpn5pYvX47JkyfDwMAALVu2RHx8PAICAuDp6Yn169fj888/z1PgmWnSpAmEEJnes7W1RYcOHRASEoJmzZplWsbGxka9C6Y2GjRogK1bt2pdr6ioVUv557NnwJs3QBHOZ4mIiIiIdJ7Wz+RdunQJjRs31pjgnTp1Cl9//TXKly+PgIAAnD59GleuXMG9e/dQo0YNjB8/Hv/++2+eAteWQqGAv78/QkND4eDgUKB9F3VWVoCTk/JzzuYREREREclL6yTv6dOnqFOnTpb3ExMT8fnnn8PAwAAHDx5EzZo11fcqV66MHTt2IDk5GWvXrs1dxKSTuGSTiIiIiEg3aJ3kxcbGwtjYOMv7P/74Ix48eIBJkyahbt26Ge67ubmhTZs28PPz07Zr0mHcYZOIiIiISDdoneRZW1vj2bNnmd578eIFFi9eDHt7e0ybNi3LNqpXr47Q0FBtuyYdxpk8IiIiIiLdoPXGKw0aNMC5c+eQkpICA4P01b/88kvExsZi1apVMDc3z7INQ0NDKBQK7aMlnfV+kpeWBujxBEYiIiIiIllo/aP4gAED8N9//2HOnDnprs+bNw9//PEHWrZsiSFDhmhs48mTJ7CxsdG2a9JhVasCRkZAbCzw/ydmEBERERGRDLSeyRs4cCDWrFmDuXPn4tq1a2jevDmuX7+OP/74A3Z2dvj111811k9JScGZM2fQuHHjXAdNusfQEHB1BW7eVM7mOTvLHRERERERUfGkdZKnUCjw119/YdCgQThy5AiOHDkCAKhUqRIOHDiAChUqaKy/d+9evH79WqvDxqlwcHNTJnm3bgEffSR3NERERERExZPWSR6g3HzlyJEjuHv3LoKCglCqVCm0bt0ahoaG2dbt3bs3GjdujLJly+ama9Jhqh02ufkKEREREZF8cpXkqbi6usLV1VW7Dg0M4My1fEUSd9gkIiIiIpIf90Akyahm8oKDgYQEeWMhIiIiIiqumOSRZMqWBaytgdRU4O5duaMhIiIiIiqetF6uee3aNcTHx+e5YxMTEzRq1CjP7ZDuUCiUSzbPnFEu2XR3lzsiIiIiIqLiR+skT8qjD1JTUyVri3RD7drKJO/WLbkjISIiIiIqnrRO8oQQMDIyQteuXeHg4JDrjk1NTXNdl3QXN18hIiIiIpKX1kle7dq1cevWLRw+fBidOnXC8OHD0b17d+jr6+dHfFTIMMkjIiIiIpKX1huv3LhxAxcuXMAnn3yCM2fOoFevXnB0dMS0adPw4MGD/IiRCpFatZR/hoUBkZHyxkJEREREVBzlanfNpk2bYvPmzQgLC8OGDRtQoUIFLFq0CFWrVkXbtm2xY8cOJCYmSh0rFQIlSgCVKik/52weEREREVHBy9MRCubm5vjss89w+fJlBAUFYdy4cbh9+zYGDx6McuXKYcKECQgKCpIqViokuGSTiIiIiEg+kp2TV6NGDSxfvhz//fcfdu3ahfr162PNmjWoU6cOmjRpgl9++UWSoxdI96kORecOm0REREREBU/yw9ANDQ3Rt29f+Pn54eHDh/j+++8RHh6Ozz77DGXLlsUXX3yBgIAAqbslHcKZPCIiIiIi+Uie5L2vQoUKmDVrFh49egRfX1907NgRW7ZsQcOGDdG0adP87JpkpErygoKAtDR5YyEiIiIiKm60PkIhNxQKBTp37gxzc3PExsbi2LFjuHr1akF0TTJwcQFMTID4eODhQ+XXRERERERUMPJ1Jg8AoqKisHLlStSsWRNt2rTByZMn0bdvX5w8eTK/uyaZGBgANWooP+eSTSIiIiKigpVvSd758+fx6aefoly5cpg4cSISExMxf/58PHv2DLt27UKrVq3yq2vSAXwuj4iIiIhIHpIu14yKisKvv/6KjRs34u7du9DX10f37t0xatQoeHh4SNkV6TjusElEREREJA9JkrwLFy5g48aN2Lt3L969e4cKFSpg9uzZGD58OMqUKSNFF1TIcCaPiIiIiEgeuU7yoqOjsW3bNmzatAl37tyBnp4eunbtipEjR6JLly5QKBRSxkmFjCrJCwlRbsBiZiZvPERERERExYXWSd7ff/+NdevWqWftHBwcMH36dIwYMQIODg75ESMVQvb2gJ0dEBEB3LkDNGggd0RERERERMWD1kles2bNoKenh44dO2LUqFHo1q0bZ+0oA4VCOZt38qRyySaTPCIiIiKigqF1kieEgEKhwLlz53Du3Llcd2xmZobw8PBc1yfdp0ryuPkKEREREVHB0TrJq169Ot69e5fnjk1NTfPcBuk21Q6b3HyFiIiIiKjgaJ3k3blzJz/ioCKIO2wSERERERW8fDsMvaAFBATAxMQECoUCS5Ys0br+7t27oVAosv04ceJElm08ffoU48ePR5UqVWBqagoHBwf06tULFy9ezMtLK7Rq1lQ+m/fyJfDihdzREBEREREVD5Iehi6X5ORkeHt7w9DQEImJiYiLi9O6DdUS1K5du8JNNQX1AYVCgcqVK2d67+rVq/D09ERkZCQ6dOgAT09PhIWF4fDhwzh48CDWrl2LkSNHah1XYWZmBri4KI9RCAxU7rhJRERERET5S5Yk7/bt21i4cCG2b98uSXsLFizA7du3sXjxYnz11Vd5aqtPnz4YOnSoVnXi4uLQr18/xMXF4cSJE2jbtq363pMnT+Dh4YExY8agQYMGqF+/fp7iK2zc3P6X5HXoIHc0RERERERFX66Xa6ampuLQoUP47rvvMGrUKPzwww/ZPq/377//YtCgQahTpw527dqV267TCQoKwrx58zB58mS4u7tL0qa21q1bh0ePHmHOnDnpEjwAqFChAnbs2IGUlBRMnTpVlvjkpNp8hTtsEhEREREVjFzN5P3999/o378/njx5AiGE+vqCBQswduxYLFu2LF35p0+fYvbs2di2bRtSUlJQs2ZNzJo1K2+RQ5loent7w8nJCTNmzMDly5fz3GZubN26FSVKlMDnn3+e6f369eujVatWOHHiBMLCwlC2bNkCjlA+3HyFiIiIiKhgaT2T9+TJE3Tu3Bnh4eH46quvcPjwYVy8eBE+Pj5o2bIlVq5cidGjRwMAXrx4gXHjxqFq1arYvHkzatasiX379iEwMBBeXl55Dn7p0qW4du0aNm3aBBMTkzy3lxvh4eG4c+cOWrRogRIlSmRZrlOnThBC4PTp0wUXnA5QJXm3bwOpqfLGQkRERERUHGg9k7dkyRLExMTg8OHD6NKlS7p7vXv3xpAhQ7BhwwbExMTgwIEDiI+PR926dTFjxgz06NFDssCDg4MxY8YMjBgxAq1bt5asXW3dvHkTAFCnTh2N5VRLSW/duoUBAwbke1y6olIl5QYs8fHAv/8C1arJHRERERERUdGmdZJ37Ngx1KpVK0OCp7J69Wr88ccf2LlzJ2rXro1Zs2bho48+ynOg7xNCYPjw4bC2tsbixYslbXvbtm1YuXIlQkNDERcXh9KlS6NFixYYN24cmjVrlqF8aGgoAOWzd5qo7qvKZyYxMRGJiYnqr2NiYgAodw9NTk7W8pXojho19HHtmh6uX09BpUoi+woSU41dYR7DwojjLg+Ouzw47vLguMuD4y4Pjrs8dGnctYlB6yTv2bNn6N+/f5b3LS0t0b59e5w/fx7Xr1/XtvkcWbNmDc6fP4+DBw/CyspKkjatrKxQsmRJGBgYoEGDBmjfvj1iY2Nx8+ZN+Pj4wMfHB7NmzcL06dPT1YuOjgagfN2aWFhYpCufmQULFmT6rKKfnx/MzMy0fUk6w8qqLgAnHDjwL0xN78sWh7+/v2x9F2ccd3lw3OXBcZcHx10eHHd5cNzloQvjHh8fn+OyWid5CQkJsLGx0VimcuXKOHTokLZN50hoaCimTZuGfv36STpD2LNnT/Ts2TPTezdu3EDv3r3xww8/oHbt2umWnapm3oyMjDS2r3pm8P2Zug9NmzYt3REQMTExcHR0RMeOHbNNInXZgwd6OHECePeuKrp2zfycwfyUnJwMf39/eHh4wNDQsMD7L6447vLguMuD4y4Pjrs8OO7y4LjLQ5fGXbXKLydytbtmdi8wu4QnL0aMGAETExOsXr063/r4UN26dbF3717Uq1cPCxcuTJfkqZK3pKQkjW0kJCQAAExNTbMsY2xsDGNj4wzXDQ0NZX9T5UXduso/b9/Wg6Fhrk/tyLPCPo6FFcddHhx3eXDc5cFxlwfHXR4cd3nowrhr078sh6Hn1s8//4zjx49j+/btsLOzK9C+69atC3d3d1y5cgUJCQnq5E61o2Z2mbXqvqYdOIsq1Q6bDx8CsbFAMRwCIiIiIqICk6sk78qVKxnOwvvwPgAsX7483Tl67zM1NcUXX3yR4z5fvXqFyZMno0uXLhg8eLB2AUukSpUqCAgIwOvXr1GuXDkA/9tQ5cmTJxrrqu47OTnlb5A6yM4OKFMGCA9XHqXQuLHcERERERERFV25SvJOnjyJkydPZltu0qRJWd5TKBRaJXnPnj1DdHQ0jhw5AoVCobHsrFmz1BuYXLp0CU2aNMlxP5qodrR5//k4V1dXAMrn9jRR3a9evboksRQ2bm7KJC8wkEkeEREREVF+0jrJ8/HxQVxcXJ471vRsWmbKly+PKVOmIC0tLcsyT58+hY+PD5o2bYpmzZpBoVDA0dExr6Gq/fPPP3Byckq35LJSpUpwdnbGhQsXEBsbm+VyzKNHjwIA2rdvL1k8hYmbG+Dvr0zyiIiIiIgo/2id5PXu3Ts/4siWjY1NtmfinT59Gj4+PujYsSNmzpwpaf/btm3D48ePMXny5Az3BgwYgPnz52Pjxo3pdsdUuXbtGs6dO4emTZtme55eUVW7tvLPW7fkjYOIiIiIqKiTb6tDHXP9+vVMz55IS0vDpk2b8Pnnn8PBwQHffPNNhjJfffUVrK2tMX36dJw6dSrdvSdPnmDQoEFQKBSYPXt2vsWv61SbrwQGAlk8pklERERERBLI0UxeYGAgKlWqBHNz83wJ4uTJk2jXrl2+tP2+8ePHIzg4GLt27cpwiPqsWbNw8uRJtGjRAuXLl4elpSVevHiB06dP49mzZ3BxccGBAwdga2uboV0bGxvs27cP3bt3R4cOHdChQwe4uroiPDwchw4dwrt37zBv3jx06NAh31+jrnJ1BfT0gFevgLAw4P/3rSEiIiIiIonlKMm7desWOnXqhJkzZ+Kzzz6Dnp40E4BBQUGYPHkyQkNDce/evTy3pzrWQPXn+yIiIrBq1SoAgJ+fH/r06ZPu/pgxY2BiYoJLly7hxIkTSEtLQ6lSpVC7dm1MnToVw4YNg5mZWZZ9t2nTBjdv3sSiRYtw7NgxnDlzBpaWlmjXrh0mTJhQbJ/FUzE1BapWBe7dU87mMckjIiIiIsofOUryBg0aBBsbGwwfPhzLly/HhAkTMGjQoFyf+XbhwgWsXbsWe/bsweDBg7F3795ctfOhJk2aZHlkg62tLTp06ICQkBA0a9Ysw33VDFxeVKpUCRs2bMhTG0WZm9v/krxOneSOhoiIiIioaMrxlFznzp1x7949dOzYEePGjUO5cuXw+eef488//0RUVFS29a9fv46lS5eiTp06aNWqFW7evIkjR45gy5YtBXJAuEKhgL+/P0JDQ+Hg4JDv/VFGqufyuPkKEREREVH+0Wp3TQsLC6xcuRITJkzAjz/+iN9++w2bN2+GQqFArVq1ULlyZZQuXRo2NjaIj49HREQEwsPD8c8//yA6OhpCCNSvXx+//vorBgwYINmyTyocVDts8hgFIiIiIqL8k6vD0J2dnbF27VosWbIER44cwbFjx3DlyhUcOXIECQkJ6cqWKVMGjRs3RsuWLfHxxx+jRo0akgROhY9qJu/OHSAlBTDI1buPiIiIiIg0ydOP2WZmZujVqxd69eqlvvbmzRvExcXB0NAQJUuWhLGxcZ6DpKKhYkWgRAkgNhYIDgaY7xMRERERSU/y9ZKlSpVC+fLlYW9vzwSP0tHTA2rVUn7OJZtERERERPmDD8VRgXr/UHQiIiIiIpIekzwqUKrNV7jDJhERERFR/mCSRwWKM3lERERERPmLSR4VKFWSFxoKxMTIGgoRERERUZHEJI8KlLU1oDqLPihI3liIiIiIiIoiJnlU4Lhkk4iIiIgo/zDJowLHJI+IiIiIKP9IkuSlpaVBCCFFU1QMcIdNIiIiIqL8I0mSV7NmTQwbNkyKpqgYeH8mj78bICIiIiKSliRJ3pMnT2BraytFU1QMVK8O6OsDUVHAf//JHQ0RERERUdEiSZLn6uqKu3fvStEUFQPGxspED+CSTSIiIiIiqUmS5M2fPx8nTpzA3r17pWiOigFuvkJERERElD8kSfI6duyIY8eOYc6cOfj444+xa9cuPHr0CHFxcVI0T0UQkzwiIiIiovxhIEUjlStXxrt375CamorAwEAcOnQo2zqmpqaIjY2VonsqhLjDJhERERFR/pAkyatSpQoSExO1qmNqaipF11RIqWby7t0DkpIAIyN54yEiIiIiKiokSfKOHj0qRTNUjFSoAFhaAjExwP37/0v6iIiIiIgobyR5Jo9IWwoFn8sjIiIiIsoPTPJINkzyiIiIiIikJ8lyzfe9ffsWe/bswcWLFxEWFgY9PT04ODigdevW6NmzJ0xMTKTukgopVZLHzVeIiIiIiKQjaZK3cuVKTJ8+HXFxcRBCpLu3adMmlCpVCvPnz8fnn38uZbdUSKl22ORMHhERERGRdCRbrjllyhRMnDgRqampGDt2LE6fPo0nT57gyZMnOHPmDMaOHYt3797hiy++wKxZs6TqlgqxWrWUfz59CkRFyRoKEREREVGRIUmSd+bMGSxduhRNmjRBaGgoVqxYgVatWqF8+fIoX748WrZsiRUrVuDhw4dwd3fHnDlzcO3aNSm6pkKsZEnlLpsAZ/OIiIiIiKQiSZK3bt06mJmZYc+ePbCzs8uynL29Pfbu3QsjIyOsWrVKiq6pkOPmK0RERERE0pIkybtw4QI6deoEBweHbMtWrFgRnTp1wpkzZ6Tomgo5JnlERERERNKSJMmLjIxExYoVc1y+UqVKePnypRRdUyGn2nyFO2wSEREREUlDkiTP0tISEREROS4fEREBS0tLKbqmQk41kxcUBHywISsREREREeWCJEmem5sbjh49ivj4+GzLxsXF4ejRo3B3d5eiayrkqlUDDA2BmBjgyRO5oyEiIiIiKvwkSfIGDRqEyMhIfPnll9mW/fLLL/Hq1SsMHTpUiq6pkDM0BFxdlZ9zySYRERERUd5JkuQNGzYMzZo1w6+//oq2bdvC398fKSkp6vupqanw9/dH69atsX37dnh4eKB///5SdK0WEBAAExMTKBQKLFmyROv6SUlJ2L17N3r16oXy5cvDyMgIVlZWaN68OX766SekpqZmWffy5cvQ09ODQqHQ+LF58+a8vMQii5uvEBERERFJx0CKRhQKBXx9fdGnTx/4+/vj7NmzMDY2hoODAxQKBf777z8kJCRACIEePXrgt99+k6JbteTkZHh7e8PQ0BCJiYmIi4vTug03NzcEBwejbNmyaN68OcqXL4+wsDAcP34cX3zxBfbu3YvDhw/DxMQkQ13Va2vevDlatGiRZR/16tXTOq7igEkeEREREZF0JEnyAOXmK8eOHcNff/2FX3/9FVeuXMGzZ8+gUCjg4OCAFi1awNvbGy1btpSqS7UFCxbg9u3bWLx4Mb766qtctfHxxx+jffv26NChA/T0/jfB+fLlS3z00Uc4ceIE5s2bhzlz5mTZRocOHTBz5sxc9V+ccYdNIiIiIiLpSJbkqXh6esLT01PqZrMUFBSEefPmYfLkyXnazGXRokWZXi9dujR+++03VKtWDVu3btWY5FHuqGby7t8HEhMBY2N54yEiIiIiKswkeSZv6NChmDVrlhRNaSU1NRXe3t5wcnLCjBkz8q0fFxcXuLi44NmzZznaQZS04+AAlCwJpKYC9+7JHQ0RERERUeEmSZK3d+9exMbGStGUVpYuXYpr165h06ZNmT4rJyVzc3Po6enB0NAwX/spjhQKLtkkIiIiIpKKJEmevb09wsPDpWgqx4KDgzFjxgyMGDECrVu3zte+IiIiEBgYiIYNGzLJyyfcfIWIiIiISBqSPJM3btw4fP/99wgODkbVqlWlaFIjIQSGDx8Oa2trLF68ON/7W716NVJSUjBixAiN5Xx9fXH06FGEhITg7du3sLa2RqNGjTBq1Ch07do1234SExORmJio/jomJgaAcvfQ5OTkvL0IHVejhh4Afdy6lYbk5KyPq8gN1dgV9THUNRx3eXDc5cFxlwfHXR4cd3lw3OWhS+OuTQySJHnjx49HXFwc2rVrhylTpqBv374oW7asFE1nas2aNTh//jwOHjwIKyurfOsHAB49eoSlS5eievXq+PTTTzMtY2lpCQsLC5iYmKBq1apo3rw5EhIScPfuXfj6+uLQoUMYMWIENmzYAIVCkWVfCxYsyPTZRj8/P5iZmUn2mnTR27elALTC1auJ8PX1y5c+/P3986Vd0ozjLg+Ouzw47vLguMuD4y4Pjrs8dGHctdkbRCGEEHntcPjw4Xj37h2ePHmCS5cuqY9NKF26NCwsLDKtY2ZmhsOHD2vdV2hoKGrVqoVu3bph165d6e6dPn0abdu2xYwZMyQ5yiA1NRXt2rXDhQsXcOrUqVwd//Do0SP07dsX165dw8qVKzFu3Lgsy2Y2k+fo6IjIyEhYWlrm6jUUFm/fAjY2yqWwYWHJsLGRru3k5GT4+/vDw8ODy20LEMddHhx3eXDc5cFxlwfHXR4cd3no0rjHxMTA1tYW0dHR2eYGkszk/f7770hKSlJ/LYTA06dP8fTp0yzrmJqa5qqvESNGwMTEBKtXr85VfW18++23OHv2LObNm5fr8/2cnZ3x559/onLlyli4cCHGjh2b5WyesbExjDM5P8DQ0FD2N1V+s7YGKlYEQkOBe/cM0aaN9H0Uh3HURRx3eXDc5cFxlwfHXR4cd3lw3OWhC+OuTf+SbLySkJCAtLQ0rT7i4uK07ufnn3/G8ePHsWLFCtjZ2UkRepa2bt2KxYsXw8vLC9OmTctTW2XLlkWXLl0QFhaGkJAQiSIselQ7bHLzFSIiIiKi3JMkySsIr169wuTJk9GlSxcMHjw4X/s6evQoRowYgQYNGmD79u0an6PLqSpVqgAAIiMj89xWUcUdNomIiIiI8k6SJG/69OlYu3atFE1l6dmzZ4iOjsaRI0egUCgy/Wjbti0AYNasWeprly9f1qqfv//+G71790aFChVw+PBhyTY8Ue2GU9SfrcsLnpVHRERERJR3kjyTt3LlymyPF8ir8uXLY8qUKUhLS8uyzNOnT+Hj44OmTZuiWbNmUCgUcHR0zHEf9+7dg6enJ8zMzHDs2DHY29tLEToA4Nq1azAxMYGLi4tkbRY1qpm8oCAgLQ3QKzTzzEREREREukOSJM/Kykp9plt+sbGxyfZMvNOnT8PHxwcdO3bUenfN//77D506dUJiYiJOnTolaTJ2+vRpnD17Fr1794aJiYlk7RY1VaoAxsZAXJxyA5ZKleSOiIiIiIio8JFkrmTo0KHYv38/Xr58KUVzBe7Nmzfo3Lkznj9/jj179qBBgwZa1b9z5w6ioqIyvbd//3707NkTlpaWmDdvngTRFl0GBkCNGsrPuWSTiIiIiCh3JJnJmzlzJl68eIEWLVpgyZIl6Nq1q+xbjGZm/PjxCA4Oxq5du9Idoj5hwgQEBQWhdu3aOH36NE6fPp1lG926dUOLFi3SXdu4cSM2bNiA5s2bw8nJCaVKlcLr169x/vx5hISEwN7eHj4+PqhatWp+vbQiw80NuH5dufnKxx/LHQ0RERERUeEjSZI3f/582NrawtHREV5eXrCwsECdOnWyPQx9zZo1UnSvploKmdmSyIiICKxatQoA4Ofnhz59+qjvvXjxAgBw69Yt3MpmCqlkyZIZkrzBgwcjKioK58+fx4ULF5CcnAwrKyu4urrC29sbI0eORKlSpfL02ooL7rBJRERERJQ3kiR5s2bNSrchSkxMDM6dO6exjr6+vuRJXpMmTSCEyPSera0tOnTogJCQEDRr1izdvaNHj+ap3wYNGmDr1q15aoOUuMMmEREREVHeSJLkPX36FElJSVrVMTIykqLrHFMoFPD39y/QPkl7qpm8kBDg3TvA1FTeeIiIiIiIChtJkryyZctK0QwRypQBbGyAV6+Au3eBevXkjoiIiIiIqHDhSWSkUxQKLtkkIiIiIsoLJnmkc7j5ChERERFR7mmd5Pn5+eHRo0d56vTw4cMYPXp0ntqgootJHhERERFR7mmd5HXp0gU///xzlvcXL14MBwcHjW1cuHABGzZs0LZrKia4XJOIiIiIKPe0TvKEEFkeUwAAb968QXh4eJ6CouKtZk3ls3kvXgAREXJHQ0RERERUuPCZPNI55uZApUrKz7lkk4iIiIhIO0zySCdxySYRERERUe4wySOdxM1XiIiIiIhyh0ke6SQmeUREREREucMkj3SSarlmUBCQmipvLEREREREhYlBbipduXIFy5Yty/IeACxfvjzLXThVZYiyUrkyYGoKvHsHPHwIVKkid0RERERERIVDrpK8kydP4uTJkxrLTJo0SeN9hUKRm66pmNDXB2rUAP75R7n5CpM8IiIiIqKc0TrJ27VrF969e5fnjk1NTfPcBhVttWsrk7zAQKBXL7mjISIiIiIqHLRO8vr27ZsfcRBlwM1XiIiIiIi0x41XSGfxrDwiIiIiIu0xySOdpZrJe/AAiIuTNxYiIiIiosKCSR7prNKllR9CAHfuyB0NEREREVHhwCSPdBqXbBIRERERaYdJHuk0br5CRERERKQdJnmk05jkERERERFph0ke6bT3l2sKIW8sRERERESFAZM80mk1agB6ekBkJPDihdzREBERERHpPiZ5pNNMTQEXF+XnXLJJRERERJQ9A20Kh4eHIykpSZKOjYyMUKZMGUnaoqKtdm0gOFi5ZNPDQ+5oiIiIiIh0m1ZJXvny5SEkejBKT08PycnJkrRFRZubG7B3L2fyiIiIiIhyQqskb+7cuUhMTMz03ps3b7B+/XokJyfDyckJrVq1goODA9LS0vDgwQOcPHkSb968QeXKlTFo0CCYm5tL8gKo6OMOm0REREREOadVkjd16tRMr7979w4NGzaElZUVNm7ciI8//jhDmeTkZKxduxbTpk3D3bt3sXv37lwFTMWPaofN27eBlBTAQKt3LRERERFR8SLJxivLli1DSEgI/P39M03wAMDQ0BATJkzAvn37sHfvXqxdu1aKrqkYcHYGzM2BxETg33/ljoaIiIiISLdJkuTt3r0bnTt3Rp06dbIt27VrV7Rv3x6bN2+WomsqBvT0gJo1lZ9zySYRERERkWaSJHkPHz6Ei2qf+xyoVasWQkJCpOiaion3D0UnIiIiIqKsSZLkGRgY4NmzZzku//z5cxgaGkrRNRUT3HyFiIiIiChnJEnyqlevDl9fX4SFhWVb9r///sNff/2FBg0aSNG1WkBAAExMTKBQKLBkyZJct3P58mX06dMHjo6OMDU1ReXKlTFmzBg8fvw427p37tyBt7c3nJ2dYWpqCicnJwwZMgRBQUG5joeUmOQREREREeWMJEnep59+iri4OHTp0gV3797Nsty9e/fQuXNnxMfHY8KECVJ0DUC5c6e3t7d6djAuLi5X7WzevBktWrSAr68vmjdvjpEjR6JSpUpYt24d6tevj7///jvLur6+vmjYsCF+++031K5dGyNHjkTdunWxc+dONGrUCIcOHcpVTKSkSvIePgTevpU3FiIiIiIiXSbJZvQjR47EoUOHcOzYMdSqVQv169dHo0aNYG9vDwB48eIFAgMDcfHiRaSmpmLGjBno2rWrFF0DABYsWIDbt29j8eLF+Oqrr3LVxq1bt/DFF1/AxcUFfn5+qFChgvreyZMn0b17d/Tt2xdBQUGwsLBIVzcsLAyDBg2ChYUF/Pz8UFv1ANn/t+vh4YHBgwcjKCgIjo6OuXuRxZytLVC2LBAWpjxKoUkTuSMiIiIiItJNkszk6evr4/Dhw1i8eDEcHR1x7do1rFu3DjNmzMCMGTOwbt06nDt3Dk2aNMHRo0cxY8YMKboFAAQFBWHevHmYPHky3N3dc93OtGnTkJycjN9//z1dggcA7dq1w5w5c/DkyROsWrUqQ925c+ciKioK69atS5fgAUDt2rWxfv16xMTEYPbs2bmOj/43m8fNV4iIiIiIsiZJkgcoE73JkycjNDQUISEh+Ouvv/D7779j586d8Pf3x8uXL3Hu3Dl07NhRqi6RmpoKb29vODk55SlxDA8Px9GjR9GmTRvUr18/0zKff/45zMzMsH379nTXU1JS8Pvvv8PZ2Rk9e/bMtG7Pnj3h5OSE3bt3Izk5OddxFneq/JnP5RERERERZU2S5Zofqly5MipXrpwfTaezdOlSXLt2DadOnYKJiUmu2zl9+jTS0tLQuXPnLMuUKFECzZs3h7+/P54/f45y5coBAK5du4bo6GgMGDAACoUi07oKhQIdO3bEpk2bcO3aNTRt2jTXsRZn3HyFiIiIiCh7+ZLkFYTg4GDMmDEDI0aMQOvWrfPU1s2bNwEg28Pc3d3d4e/vj8DAQHWSp01dQPmMXlZJXmJiIhITE9Vfx8TEAFBuLMMZQMDVFQAMceuWQFJSCrLIqTNQjR3HsGBx3OXBcZcHx10eHHd5cNzlwXGXhy6NuzYxSJrkvX37Ftu2bcORI0dw7949REVF4ZtvvsHXX38tZTcQQmD48OGwtrbG4sWL89xeaGgoAGR4Fu9Dqvuq8nmt+6EFCxZg1qxZGa77+fnBzMxMY/vFQXKyHvT0PPHmjR5+++0kbGwStKrv7++fT5GRJhx3eXDc5cFxlwfHXR4cd3lw3OWhC+MeHx+f47KSJXlnzpxB//798fLlSwghULJkSURHRyMqKipduUuXLqFbt25Yv349+vbtm6u+1qxZg/Pnz+PgwYOwsrLKc+zR0dEAAEtLS43lVLtqqsrnte6Hpk2blm530JiYGDg6OqJjx47Ztl9cVK2qwL17QOnS7dGpk8hRneTkZPj7+8PDw0N9zAblP467PDju8uC4y4PjLg+Ouzw47vLQpXFXrfLLCUmSvODgYHTp0gXm5uZYunQphg4dipIlS0JPL+O+Lk2bNoWVlRV8fHxyleSFhoZi2rRp6NevHz766CMpwlcvkTQyMtJYTvXc3/tLKvNS90PGxsYwNjbOcN3Q0FD2N5WuqFMHuHcPuHPHAN26aVeX4ygPjrs8OO7y4LjLg+MuD467PDju8tCFcdemf0mSvLlz50KhUODs2bNwVT44pVGDBg1w9erVXPU1YsQImJiYYPXq1bmqnxlVApaUlKSxXEKCcnmgqampJHVJe25uwO7d3HyFiIiIiCgrkiR5J06cQLdu3XKU4AFAuXLlEBERoXU/P//8M44fP47t27fDzs5O6/pZKVGiBIDsp0BV91Xl81qXtMcdNomIiIiINJPknLxXr16hfPnyOS6fkpKSqz4mT56MLl26YPDgwVrX10S1KcqTJ080llPdd3JykqQuaU91Vt6dO4AObHJERERERKRzJEnySpcujfv37+e4/NWrV9VHEOTUs2fPEB0djSNHjkChUGT60bZtWwDArFmz1NcuX76cbduqGcgbN25oLKe6X716dUnqkvacnAALC2WCFxwsdzRERERERLpHkuWaHTt2xK+//oqAgADUq1dPY9njx4/j6tWr+Oyzz7Tqo3z58pgyZQrS0tKyLPP06VP4+PigadOmaNasGRQKBRwdHbNtu3379gCAo0ePYurUqZmWefv2LS5cuABnZ2c4Ozurrzdt2hSmpqbw8/ODECLTA9HT0tLUxyDwIPS8USiAWrWAS5eUSzZr1pQ7IiIiIiIi3SJJkjd9+nTs2rULnTt3xooVKzBw4MBMyx08eBDDhw+HoaEhJkyYoFUfNjY22Z6Jd/r0afj4+KBjx46YOXNmjtt2cnJCs2bNcObMGfzzzz+oX79+hjIbN25EfHw8+vfvn+66qakpevbsiR07dmD//v3w8vLKUHf//v14/PgxBgwYoN6ohXKvdm1lknfrFvDBt4OIiIiIqNiTZLmmk5MT/vzzTyQlJeGTTz5BpUqV8MknnwAAjh07hkGDBsHFxQVeXl6IiYnBTz/9hBo1akjRtWTmzJkDhUKBQYMG4enTp+nunTp1Cj/88ANKlSqFiRMnZqg7ffp0GBsbY/To0Qj8YEeQW7duYfTo0TAyMsL333+fr6+huODmK0REREREWZMkyQOAdu3a4fbt2xg5ciRiYmLw+++/AwCuX7+OnTt3Ijw8HL169cLly5cxbNgwqbrVyvjx49GlS5dMDyRv164dFi1ahODgYLi6umLAgAGYMGECOnXqhPbt20OhUGDPnj2Z7upZvXp1bNmyBa9fv0b9+vXRs2dPTJw4ER9//DEaNGiA169fY/PmzTqX2BZWTPKIiIiIiLImyXJNFQcHB6xbtw7r1q3Do0eP8PLlSwCAtbU1KleunOnh6FJSLYXMbElkREQEVq1aBQDw8/NDnz59MpSZMmUKGjZsiBUrVuDkyZOIioqCvb09hg0bhqlTp6JKlSpZ9j1gwAC4urpiyZIlOH36NHx9fWFjYwMvLy9MmTIl0yWglDuqJO/xYyA6GrCykjceIiIiIiJdIkmS99dff8HMzEy9uyWADBuUFIQmTZpACJHpPVtbW3To0AEhISFo1qxZlm20adMGbdq0yVX/devWVc9gUv4pVQooXx549gwICgKaN5c7IiIiIiIi3SHJ1NrQoUOxd+9eKZrKNwqFAv7+/ggNDYWDg4Pc4VAecckmEREREVHmJEnyUlNToa+vL0VTRDmiOhT91i154yAiIiIi0jWSJHmdO3eGn58fUlNTpWiOKFucySMiIiIiypwkSd6KFStgYmKC3r17IzIyUoomiTR6P8nL4jFMIiIiIqJiSZKNV+7fv4+ZM2di9erVKF++PNq2bYtGjRqhdOnSsLCwyLSOqalppjtcEuVE9eqAgYFyd82nT4EKFeSOiIiIiIhIN0iS5LVu3RoKhUK9s+WxY8dw7NgxAMoNTz4khIBCoWCSR7lmZKRM9IKClLN5TPKIiIiIiJQkSfJ27tyJhIQEreqYmppK0TUVY7VrK5O8W7cAT0+5oyEiIiIi0g2SJHn9+vWTohkirXDzFSIiIiKijCTZeIVIDkzyiIiIiIgyYpJHhZbqrLx794CkJHljISIiIiLSFZIs11SJj4/HlStXEBYWhuTk5CzLpaamIi0tDcOHD5eyeypmypcHrKyUO2zeu/e/pI+IiIiIqDiTLMlbuXIlZsyYgbdv32ZbVggBPT09JnmUJwqFcsnm+fPKJZtM8oiIiIiIJFquuX//fkycOBElSpTA9OnTsWnTJggh0LVrV2zatAnz58+Hp6cn9PX14ebmBj8/PwQHB0vRNRVzqsTu1i154yAiIiIi0hWSzOStXbsWVlZWCAgIQOnSpQEAX3zxBapXrw5vb291ueDgYHh5eWHcuHG4fPmyFF1TMcfNV4iIiIiI0pNkJu/69evo3LmzOsEDABMTkwxLN6tWrYq//voLjx8/xtKlS6Xomoo5JnlEREREROlJkuTFxsaiXLly6a7Z2triyZMnGco6OTnB09MTPj4+UnRNxVytWso/nz0D3ryRNxYiIiIiIl0gSZJXqlQpREZGprtWsWJFBAQEZFq+fPnyePz4sRRdUzFnZQU4OSk/52weEREREZFESV7ZsmXx7NmzdNfq16+PiIgI+Pv7Zyj/4MEDmJubS9E1EZdsEhERERG9R5Ikr1WrVrh8+TLi4uLU1wYNGgQAGDt2bLoE8NSpU/D19UWTJk2k6JqIO2wSEREREb1HkiRvzJgxKFu2LHx9fdXX6tSpg1GjRiE4OBhVq1ZF69at0bBhQ3Tq1Al6enqYNm2aFF0TcSaPiIiIiOg9khyhUKVKFfz7778Zrq9duxZOTk5YtWoVzp07BwCoW7cuFi5ciGbNmknRNZE6yQsKAtLSAD1JfnVBRERERFQ4SZLkafL111/j66+/RnR0NPT19VGiRIn87pKKmapVASMj4O1b4PFjwNlZ7oiIiIiIiORTYHMeVlZWTPAoXxgaAq6uys+5ZJOIiIiIijsubKMigc/lEREREREpSbJcc/HixUhISNCqjqmpKaZMmSJF90TcYZOIiIiI6P9JkuRNnTo12zIKhUL9uRACBgYGTPJIMpzJIyIiIiJSkiTJu3TpUpYzeSkpKQgPD8fZs2fh4+MDV1dXLF++HNWqVZOiayIA/0vygoOBhATAxETeeIiIiIiI5CJJkte4ceNsywwaNAjz58/HgAED0KdPH1y+fBklS5aUonsilCsHWFsDr18Dd+8C7u5yR0REREREJI8C3XjFxsYG+/btQ1paGubOnVuQXVMRp1BwySYRERERESDD7poWFhbo27cvjhw5UtBdUxHHzVeIiIiIiGQ6QsHOzg7h4eFydE1FGGfyiIiIiIhkSvICAgJgaWkpR9dUhDHJIyIiIiKSIcn77bffsH//fjRv3jxX9Z89e4alS5eia9euqFy5MszNzWFiYoJKlSph4MCBOHHihNZt7tq1CwqFIkcf5ubmGeqHhYXBwMAg27rTp0/P1WumnKlVS/lnWBgQGSlvLEREREREcimQw9DT0tIQGRmJ8+fPIzAwECYmJvjhhx9y1deGDRswd+5cODo6wt3dHZ6enoiNjUVgYCB27tyJnTt3YsiQIfjll1+gp5ezHNbNzQ3ffPNNtuXWrl0LfX39DNcTExORmpqKWrVqwdPTM8v6bdu2zVE8lDslSgCVKgEPHypn8zjcRERERFQcFdhh6CpNmzbF0qVLUbdu3Vz1NXDgQPTs2RP16tXLcO/GjRsYMGAAtm3bBjc3N0yaNClHbdasWRMLFy7UWObatWtYtGgRRo8enWWZ+vXrZ9sO5S83NyZ5RERERFS85fth6ACgUChgZmaGSpUqwdraOk99ubq6Znmvbt26OHjwIKpXr46tW7fmOMnLidWrVwMAvvjiC8naJOnVrg0cPMgdNomIiIio+Cqww9ALStWqVWFnZ4fnz59L1mZERAR2796Nli1bopbqwS/SSdx8hYiIiIiKO1l218xPkZGRiIyMhIuLi2Rtbtq0CYmJiRqXapJuUCV5QUFAWpq8sRARERERyaFIJXkpKSkYM2YM0tLScrSRSk6kpqbip59+gr29PXr16iVJm5R/XFwAExMgPl75bB4RERERUXEjyXJNHx8fjc/k5YS5ubnWSVRKSgqioqIQGhqKixcvYv369Xjw4AHWrl0LLy+vPMWjcvDgQTx9+hTfffcdDA0NNZa9cuUK2rRpg9u3byM6OhqWlpZwd3fH0KFDMXDgQCgUCo31ExMTkZiYqP46JiYGAJCcnIzk5OS8v5hiwtXVANevK3D9egqcnIR67DiGBYvjLg+Ouzw47vLguMuD4y4Pjrs8dGnctYlBIYQQee1QX18fQoh0Scz7zX6Y3GTWpUKhQGpqao777NSpE/z8/NJd69y5M5YtW6ZxcxZttWvXDmfPnsWjR4/g6OiYaZmIiAg4OzujZs2aqFGjBkqVKoWUlBSEhITg9OnTSEhIQNeuXbF//34YGRll2dfMmTMxa9asDNd37NgBMzMzyV5TUbdypTtOnaqAAQPuol+/YLnDISIiIiLKs/j4eAwcOFA9maSJJEnev//+ixs3bmDcuHFISEjAwIED0axZM5QuXRrJycn477//cP78efzxxx8QQmDhwoUZNjAxNTVFo0aNctzn1q1bce/ePSQkJODFixe4evUqHjx4AHd3d6xfv16SzWDu3LmDmjVr4qOPPsLBgwdz1UZERAQ+/fRTHD16FBMnTsSyZcuyLJvZTJ6joyMiIyOz/UbS/6xYoYevv9ZHz55p2L07FcnJyfD394eHh0e2s7EkHY67PDju8uC4y4PjLg+Ouzw47vLQpXGPiYmBra1tjpI8SZZrWlhYYMKECahevTr27NkDGxubDGU+++wzLFiwAH379sWMGTMQEBCAChUq5LrPoUOHZrh2/PhxDB48GB4eHggICMjz5itr1qwBgDxtuGJnZ4d9+/ahSpUqWLt2LWbOnJnlN8XY2BjGxsYZrhsaGsr+pipMVEcw3r6tB0PD/z12ynGUB8ddHhx3eXDc5cFxlwfHXR4cd3nowrhr078kG68sWbIE7969w759+zJN8FTKli2LgwcPQgiBBQsWSNF1Oh06dMCuXbvw9u1bzJkzJ09tRUdHY/v27XBxcUHHjh3z1JaZmRn69++PpKQkXL58OU9tUfZUO2z++69yAxYiIiIiouJEkiTvzz//RLdu3VCqVKlsy1pbW6Nbt244evSoFF1n0KZNG5QuXRrHjh3LUztbt25FbGwsRo0ale2GKTlRpUoVAMojHih/2dsDdnbKIxTu3JE7GiIiIiKigiVJkvfs2TPY2trmuLyNjQ3Cw8Ol6DpTFhYWiIqKynV9IQTWrVsHU1NTDBs2TJKYVLvh8Nm6/KdQ8FB0IiIiIiq+JEnySpQogfv37+e4/I0bNzQu68yL6OhoPHnyJMudMHPCz88PwcHB6NevH6ytrSWJ69q1awCQYcMZyh9M8oiIiIiouJIkyWvYsCH8/f0REBCQbdnDhw/j9OnTeX7OLSsLFy5EcnJyng4ul2LDlffdv38fu3fvRoMGDVCxYkVJ2iTNatdW/nnrlrxxEBEREREVNEmSvIkTJyI5ORkeHh7Ytm1bumMAVF68eIGZM2eid+/esLS0xA8//KB1P+Hh4QjMYmomPj4ekyZNwsKFC+Hk5IRp06Zp3T4APHr0CL6+vqhfvz4aNmyYozoPHz5EWFhYpvfOnj0LDw8PpKWlaTw+gaTFmTwiIiIiKq4kOUKhQ4cOWLp0KaZMmQJvb2+MHj0alSpVQrly5ZCamoqnT5/iwYMHSEtLg729Pf74449czWj5+flhyJAhcHFxQcOGDWFvbw99fX08ffoU/v7+ePPmDRo1aoQ9e/bAysoqQ/1FixbB19cX27dvz/L4hnXr1iEtLU2rWbw///wTU6ZMQZMmTVC5cmXY2Njg7du3uHLlCm7evAkLCwvs3LkTLVu21Po1U+7UrKl8Nu/lS+DFC7mjISIiIiIqOJIkeYByNs/DwwMrVqyAn58fbt++jdu3bwNQnv9Wr1499O7dG1988QUsLCxy1Ufr1q0xYcIEXLx4EUePHkVMTAz09PRgZ2eHVq1aYdCgQejVqxf09DKfoJw9ezbi4+Oxe/duTJkyJcP9tLQ0bNmyBWXLlsWAAQNyHFe3bt1w//59nD17FgEBAUhISICFhQWqVq2K7777DqNHj0a5cuVy9Zopd8zMABcXICQECArK++6oRERERESFhWRJHqDcVOTnn38GAMTFxSE6OhpGRkawtrbOMvHShpOTE5YvX57r+v369cPhw4fh4eGR6X09Pb1cHXHg4uKC9evX5zouyh9ubv9L8v7/BAsiIiIioiJP0iTvfebm5jA3N8+v5nPll19+kTsEKkC1awN//AEEBjLJIyIiIqLiQ5KNV4h0kWrzlaAgeeMgIiIiIipI+TaTBwCxsbFYunQprl69CjMzM7Rt2xZDhw6FqalpfnZLBOB/Sd6dOwqkpsobCxERERFRQdE6ydu0aRPOnDmDjRs3wszMLMtygYGB6NmzJx49egQhBABg3759WLp0KY4dO4bKlSvnPmqiHKhUSbkBS3y8AuHhJeQOh4iIiIioQGi9XHPXrl24ePGixgTv1atX6N69Ox4+fIipU6fi4cOHCAoKwvTp0/H06VN4enpmepYekZT09ZVHKQDA48e529GViIiIiKiw0TrJu3PnDtq3b6+xzOjRo/H06VMsXrwY8+bNQ8WKFVGjRg3MnDkTa9euRXBwMDZv3pzroIlySpXknT3rgDNnuGyTiIiIiIo+rZO8N2/ewNraOsv7x48fx549e9CmTRtMnjw5w/3hw4ejWrVq2LNnj7ZdE2nljz+AAweUn1++7AAPDwNUrKi8TkRERERUVGmd5BkZGeHNmzeZ3hNCYNKkSdDX18eqVasyLaNQKNCwYUPcunVL266JcuyPP4DevYGoqPTX//tPeZ2JHhEREREVVVoneVWrVkVgYGCm91avXo3AwEAMHz4cNVXr5DJhb2+PuLg4bbsmypHUVGD8eOD/9/tJR3VtwgRw6SYRERERFUlaJ3ldu3bFlStXcPny5XTXb968ie+++w52dnZYuHChxjZevXoFKysrbbsmypFz54Bnz7K+LwTw9KmyHBERERFRUaN1kvfll1+iRIkS8PT0xJ49e/D8+XP89ddf6NixI+Lj47F69WqULFlSYxtXr15FhQoVchszkUZhYdKWIyIiIiIqTLRO8uzt7bFr1y4kJiaif//+cHR0xEcffYSIiAjMnz8fffv21Vg/ICAAt2/fRqtWrXIdNJEmZctKW46IiIiIqDDR+jB0AOjSpQsCAwOxfv163L59G6VKlYK3tzfatWuXbV19fX1Mnz4d/fr1y03XRNlq2RIoX165yUpmz+UBgKOjshwRERERUVGTqyQPAJydnbF48WKt69WpUwd16tTJbbdE2dLXB1auVO6iqVBknug1a6YsR0RERERU1Gi9XJOoMPDyAvbuBRwc0l9XHfG4ezdw8GDBx0VERERElN+Y5FGR5eUFhIYC/v4p+Oqra/D3T8HLl8DYscr7gwcDt2/LGiIRERERkeSY5FGRpq8PtG4t0KrVf2jdWkBfH1i6FGjbFoiNBT7+GHjzRu4oiYiIiIikwySPih1DQ8DHB3ByAv79F+jfnwejExEREVHRwSSPiiVbW+DAAcDUFPDzA6ZNkzsiIiIiIiJpMMmjYqtuXWDrVuXnS5YAv/8uZzRERERERNJgkkfFWt++/5vF++wz4J9/5I2HiIiIiCivmORRsTdnDtC1K5CQAPTsCbx8KXdERERERES5xySPij19fWDHDqBaNeDpU+Uh6klJckdFRERERJQ7BlI3eO/ePdy7dw9v376FECLLcqampujTp4/U3RPlipWV8nD0Ro2Ac+eA8eOB9evljoqIiIiISHuSJXnnz5/H6NGjcTsHp0sLIaBQKJjkkU6pVk05o9e9O/DTT4C7O/D553JHRURERESkHUmSvOvXr6Njx45ISkpC9+7d0bRpU9ja2sLAIOvmTU1NpeiaSFKensC8ecC33wJjxgA1agAtWsgdFRERERFRzkmS5M2ZMwdJSUk4ePAgPD09pWiSSDZTpwI3bigPTO/VC7h2DXB0lDsqIiIiIqKckWTjlfPnz8PDw4MJHhUJCgXwyy9AnTrKnTZ79gTevZM7KiIiIiKinJEkyYuOjoarq6sUTRHpBHNz4MABwMZGeXbe558DGvYRIiIiIiLSGZIkeTY2Nnj16pUUTRHpjIoVgT17lEcs/PYbsHy53BEREREREWVPkiSvWbNmOH78OJJ4uBgVMW3b/i+5mzIF8POTNx4iIiIiouxIkuRNnToVkZGRGDVqFFJTU6VokkhnjBkDDBsGpKUB/fsDDx7IHRERERERUdYk2V3T3Nwcs2fPxvfff48LFy6gT58+cHZ2hqGhYZZ1eBg6FRYKhfJg9Lt3gcuXgR49gEuXAAsLuSMjIiIiIspIkiSvVq1aAJSHnIeEhGD+/PkAAIVCkWn5vByG/uzZM+zevRsnTpzA/fv3ER4ejtTUVJQrVw5NmjTB8OHD0b59e63bvXz5Mpo1awaRze4aP//8M4YPH57pvVevXmHFihXYt28fHj9+jBIlSsDd3R3jxo1D165dtY6JdIexMbBvH9CgAXD7NvDpp8qv9SSZCyciIiIiko4kSd7PP/8MhUKRZVKXmdwehr5hwwbMnTsXjo6OcHd3h6enJ2JjYxEYGIidO3di586dGDJkCH755RfoafETeEJCAoQQaN68OVpoOP26Xr16mV5/+PAhPDw88PDhQzRr1gwdOnRAVFQUDh06BE9PT3z33XeYO3eu1q+XdEe5csD+/UCrVsqdN+fMAWbMkDsqIiIiIqL0JEnyhg0bJkUzOTJw4ED07Nkz02Trxo0bGDBgALZt2wY3NzdMmjRJ6/Y7dOiAmTNnalUnLS0NgwYNQmhoKHbs2IEBAwao771+/RrdunXDvHnz0LBhQ/To0UPrmEh3NG4M/PQT4O0NzJypPEvv44/ljoqIiIiI6H8K3WIzV1fXLGfT6tati4MHD0KhUGDr1q0FFtO+fftw+fJlfPnll+kSPACwtraGj48PTE1NMWXKlAKLifLPsGHAuHHKzz/5RLl8k4iIiIhIVxS6JC87VatWhZ2dHZ4/f15gfaoSyq+++irT++XLl0efPn0QEhKCy5cvF1hclH9+/FF5vEJsrHIjltev5Y6IiIiIiEhJkuWaKo8fP8apU6cQFhaG5OTkLMulpqZCCIHZs2dL2T0AIDIyEpGRkWjQoIHkbWcmJSUFZ8+eRfXq1VGxYsUsy3Xq1Am//vorTp06hSZNmhRIbJR/DA0BHx+gYUPlkQoDBgB//QUYSPo3ioiIiIhIe5L9SDpx4kSsWbMGaWlp6t0zAah3q3x/UxYhBIyMjCRP8lJSUjBmzBikpaXhm2++kbTtrDx48ACxsbGoU6eOxnLu7u4AgFu3bhVEWFQAbG2VG7A0a6Y8JH3aNGDJErmjIiIiIqLiTpIkb/PmzVi5ciXq1q2LcePGoUKFCujQoQMGDhwIb29vRERE4MKFC9ixYwfKly+PjRs3om7dunnuNyUlBVFRUQgNDcXFixexfv16PHjwAGvXroWXl1eu2vT19cXRo0cREhKCt2/fwtraGo0aNcKoUaMyPQYhNDQUAFChQgWN7aruq8pnJjExEYmJieqvY2JiAADJyckaZ0ZJM9XY5ccY1qgB/PyzAgMHGuDHH4FatVIwcKDmYziKi/wcd8oax10eHHd5cNzlwXGXB8ddHro07trEoBDZHQyXA82bN8ejR48QEhICc3NzAICxsTHGjh2LH3/8UV3u9evX8PLyQkhICP755x+UKVMm13126tQJfn5+6a517twZy5Ytg6urq9btBQQEoE2bNqhbty6qVq0KKysrJCQk4O7duzh79ixSU1MxYsQIbNiwId2spI+PD/r164c5c+bg+++/19iHvr4+qlWrhjt37mR6f+bMmZg1a1aG6zt27ICZmZnWr4kKzm+/uWLv3qowMkrF/Pnn4OISLXdIRERERFSExMfHY+DAgYiOjoalpaXGspLM5N2+fRvdu3dXJ3gAYGZmhujo9D/oWltbY9++fXBxccGiRYuwfPnyXPc5YMAAuLu7IyEhAS9evMDVq1dx9OhRvHjxAuvXr0fjxo21aq9evXrqmbMPPXr0CH379sWmTZtQq1YtjFNtrQioZ96MjIyy7cPY2DjdTN2Hpk2blm7zlpiYGDg6OqJjx47ZfiMpa8nJyfD394eHhwcMDQ3zpY/OnYH4+DT4+upjxYrWuHQpBfb2+dJVoVEQ404ZcdzlwXGXB8ddHhx3eXDc5aFL455VrpIZSZK8d+/eoXTp0umu2dnZZbo00cbGBt26dcOhQ4fylOQNHTo0w7Xjx49j8ODB8PDwQEBAAFxcXHLd/vucnZ3x559/onLlyli4cCHGjh2rns0zMTEBACQlJWXbTmJiosZD4I2NjWFsbJzhuqGhoexvqqIgv8dxxw7lOXr37yswYIAhTpwAcpD7F3l8/8qD4y4Pjrs8OO7y4LjLg+MuD10Yd236l+QIBVtbW7x48SLdtUqVKuGff/5BWlpapuX/++8/KbpOp0OHDti1axfevn2LOXPmSNp22bJl0aVLF4SFhSEkJER9vUSJEgCyz6xjY2ORlpamLk9Fj5UVcPAgYGkJnD//v7P0iIiIiIgKkiRJnoODAx4/fpzuWqNGjRAdHY0//vgjQ/mgoCCULFlSiq4zaNOmDUqXLo1jx45J3naVKlUAKI9pUFFtqPLkyRONdVX3nZycJI+LdEe1asDOnYBCAWzYoPwgIiIiIipIkiR5HTp0wJUrV/Dq1Sv1tSFDhsDAwABjx47F1atX1dd//fVXnDhxAq1bt5ai60xZWFggKipK8nZVO9q8/3yci4sLDA0NcePGDY11VferV68ueVykW7p2BebPV34+Zgxw7py88RARERFR8SJJkjdmzBi0bNkSFy9eVF+rXLkyZsyYgRcvXqBJkyZwcnKCnZ0dhg0bBnNzc0yfPl2KrjOIjo7GkydP4OjoKHnb165dg4mJSbpn/YyNjdG8eXPcv39f4/EIR48eBQC0b99e8rhI93zzDdCvH5CSAvTuDTx9KndERERERFRcSJLklStXDsePH0f37t3TXf/222+xa9cuNG3aVP3MWo8ePXDhwgXUrFlTiq4zWLhwIZKTk9GrVy9J2z19+jTOnj2Lbt26qTdbURk4cCAAYNmyZZnWffbsGfbs2QNHR0c0a9ZM0rhINykUwObNQJ06wMuXwMcfA+/eyR0VERERERUHkiR5mvTt2xfnz5/HmzdvEBERgT/++AO1a9fOVVvh4eEIDAzM9F58fDwmTZqEhQsXwsnJCdOmTdOq7Tt37mS5xHP//v3o2bMnLC0tMW/evAz3hw4diipVqmDt2rXYuXNnuntv3rxB3759kZCQgBkzZsDAQJINTakQMDcHDhwAbG2BgABgxAgg76dSEhERERFpVqgyDj8/PwwZMgQuLi5o2LAh7O3toa+vj6dPn8Lf3x9v3rxBo0aNsGfPHlhZWWWov2jRIvj6+mL79u3qDVNUNm7ciA0bNqB58+ZwcnJCqVKl8Pr1a5w/fx4hISGwt7eHj48PqlatmqFdQ0NDHDhwAG3btsXAgQOxbt061KtXD1FRUTh06BDevHmDUaNGYfjw4fk2NqSbKlYE9uwBOnQAfv8dcHcHJk2SOyoiIiIiKsokT/KCgoJw5MgR3Lt3D1FRURgwYAB69+4tSdutW7fGhAkTcPHiRRw9ehQxMTHQ09ODnZ0dWrVqhUGDBqFXr17Q08t8gnL27NmIj4/H7t27MWXKlHT3Bg8ejKioKJw/fx4XLlxAcnIyrKys4OrqCm9vb4wcORKlSpXKMrYaNWogMDAQixYtwqFDh7Bx40aYmZnB3d0do0aNQp8+fSQZAyp82rQBVqwAxo4Fvv4aqFUL6NRJ7qiIiIiIqKiSLMkLDw+Ht7c3jh07BvH/a9IUCgWqVauWLskLCAjAvHnzMGXKFDRp0kSrPpycnPJ0gHq/fv1w+PBheHh4ZLjXoEEDbN26NddtA0Dp0qWxdOlSLF26NE/tUNHz5ZfAjRvK5/T69weuXgXe27+HiIiIiEgykiR5MTExaNGiBR49eoTu3btj6NChcHZ2hru7e4aytWrVwunTp2Fra6t1kpdXv/zyS4H2R6SiUABr1wJ37gCXLgE9egCXLwMWFnJHRkRERERFjSRJ3rx58/Dw4UPs2LED/fv311jWyMgIzZs3x9mzZ6XomqjQMDYG9u0DGjRQJnuffAL88QeQxepiIiIiIqJckeTHy/3796N9+/bZJngqDg4OCA8Pl6JrokKlbFlg/35lwnfwIDB7ttwREREREVFRI0mS9/TpU62ORTA1NcU7HhpGxVSjRsCGDcrPZ81SJn1ERERERFKRJMkrUaIEXrx4kePy9+7dg62trRRdExVKQ4YA48crP//0UyAoSN54iIiIiKjokCTJa9q0Kf766y9ERkZmW/bhw4c4ceIEGjduLEXXRIXWjz8C7doBsbHKjVhev5Y7IiIiIiIqCiRJ8iZPnozo6Gh0794djx8/zrLc8+fP0atXL6SkpOCzzz6TomuiQsvAAPDxAZydgYcPlUcrpKTIHRURERERFXaSJHmtWrXCggUL8Pfff6NatWoYNmwYNm/eDAC4e/cuNm3ahM8++wzVq1fHzZs34e3tjS5dukjRNVGhZmMDHDgAmJkB/v7A1KlyR0REREREhZ1km7d/8803+PPPP1G5cmVs27YNn3/+OQDg4MGDGDlyJH755RdYWFhgxYoV2LRpk1TdEhV6tWsD27YpP1+6FNi+Xd54iIiIiKhwk+ScPJVu3bqhW7duCAwMxLVr1/Dy5UsAgLW1NWrXro0GDRpAX19fyi6JioTevYHvvwfmzgVGjABcXZXn6RERERERaUvSJE/Fzc0Nbm5u+dE0UZE1axZw8yZw6BDQsyfw999AcDAQFqY8X69lS4C/IyEiIiKi7ORLkkdE2tPTA377DWjcGLh3T7khS1LS/+6XLw+sXAl4eckXIxERERHpPsmeySOivLO0BL78Uvn5+wkeAPz3n3JZ5x9/FHxcRERERFR4aD2Tt3TpUsTFxeW5Y1NTU0yZMiXP7RAVJampwKJFmd8TAlAogAkTlOfqcekmEREREWVG6yRvypQpUCgUEELkqWOFQsEkj+gD584Bz55lfV8I4OlTZbk2bQosLCIiIiIqRHL1TJ6hoSG6d+8OLy8vGBkZ5apjU1PTXNUjKsrCwqQtR0RERETFj9ZJ3rhx47Bt2zbs27cPp06dwieffILhw4ejVq1a+REfUbFStmzOypUunb9xEBEREVHhpfXGKytWrEBYWBi2bduGmjVrYuXKlahTpw6aNm2KzZs3S/K8HlFx1bKlchdNhUJzuR9+AP79t2BiIiIiIqLCJVe7a5qYmOCTTz7BmTNnEBwcjClTpuDx48cYMWIEypYti88//xxXr16VOlaiIk9fX3lMApAx0VN9bWICXLwI1KkDrFkDpKUVbIxEREREpNvyfISCi4sLFi5ciKdPn2L//v1o06YNtmzZgiZNmqBOnTpYu3YtoqKiJAiVqHjw8gL27gUcHNJfL18e2LdPeYZeu3ZAfDwwdizg4QE8fixPrERERESkeyQ7J09fXx89evTAn3/+iadPn2LOnDmIj4/H2LFjUa5cOXz66ac4d+6cVN0RFWleXkBoKHDqFLBjh/LPR4+U152cAH9/5SyemRlw8iTg5gb8/LNy900iIiIiKt7y5TD0MmXK4Ntvv0VISAhOnDgBLy8v7N27F23atEH16tWxfPlyvH79Oj+6Jioy9PWVxyQMGKD88/1z8fT0lIem37wJNG8OvH0LjBgBeHoqD00nIiIiouIrX5K897Vt2xa//fYbwsLCsHr1apiammLy5MmoWLFifndNVOS5uABnzgA//ggYGwNHjgC1agG//cZZPSIiIqLiKt+TPJX4+Hi8fv0ar1+/hhAC+u9PSxBRrunrA5MmAdevAw0bAlFRwCefKJd2vnghd3REREREVNDyPck7cuQIevbsCScnJ/zwww8oVaoU1q1bhydPnuR310TFiqurctfNuXMBQ0PgwAHlrN7evXJHRkREREQFKV+SvLCwMMydOxfOzs7o1q0b/Pz8MHjwYFy6dAk3btzAqFGjYGFhkR9dExVrBgbAd98BV68CtWsDkZFAnz7K5/pevZI7OiIiIiIqCJImeUePHoWXl5d61s7c3BwrVqzA8+fP8csvv6Bx48ZSdkdEWahTR5noff+9cjnnrl3KWb1Dh+SOjIiIiIjym0FeGwgPD8fmzZuxefNmPH78GEZGRujXrx9GjRqF5s2bSxEjEeWCkREwZw7w0UfAkCHA3bvKz4cOBVasAKys5I6QiIiIiPJDrmfyjh07pp61mz59OoyNjfHjjz/iv//+w/bt25ngEemIhg2BgABg8mRAoQC2blXO6vn5yR0ZEREREeUHrZO8xYsXo1KlSujatSt8fX3h5eWFkydP4u7du5g4cSKsra3zI04iygMTE2DJEuDcOeWxC8+eAZ06AV98AcTGyh0dEREREUlJ6+WaU6dOhZGREXr37g1vb2/Y2dkBAAICArRqx8TEBDVq1NC2eyLKg+bNgRs3gKlTgTVrgJ9+Ao4dA7ZsAVq3ljs6IiIiIpJCrp7JS0pKwt69e7E3D3uzKxQKpKSk5Lo+EeWOuTmwejXQsycwbBjw6BHQpg0wfjwwfz5gZiZ3hERERESUF1oneV988QXi4+Pz3LGpqWme2yCi3GvXDggMVB6k/vPPwMqVwJEjwLZtQJMmckdHRERERLmldZK3du3a/Igjx549e4bdu3fjxIkTuH//PsLDw5Gamopy5cqhSZMmGD58ONq3b691u2lpaThy5Ah27dqF8+fP4/nz5zAyMkK1atXQp08fjB8/HiYmJpnWDQsLg6OjI1JTUzX28f3332POnDlax0aUXywtgU2bAC8v4LPPgOBg5ZLOKVOAWbMAY2O5IyQiIiIibeX5CIWCtmHDBsydOxeOjo5wd3eHp6cnYmNjERgYiJ07d2Lnzp0YMmQIfvnlF+jp5XxfmS5dusDPzw/W1tZo0aIFevTogdevX+PkyZOYOnUqduzYgZMnT8LGxiZD3cTERKSmpqJWrVrw9PTMso+2bdvm6jUT5bcuXYCgIOWSze3bgUWLgL/+Us7q1asnd3REREREpI1Cl+QNHDgQPXv2RL1MfvK8ceMGBgwYgG3btsHNzQ2TJk3Kcbtt27bFiBEj0KNHDxgaGqqvv337FoMHD8aff/6JCRMmYPv27Vm2Ub9+fSxcuFC7F0SkI0qVAn79VTmrN3KkMulr3Fh5oPq33wLv/bUgIiIiIh2W63Py5OLq6pppggcAdevWxcGDB6FQKLB161at2p06dSp69+6dLsEDAAsLC2zZsgUlS5bEnj17JHkekUiXffyxMsHr3RtISQFmzlQ+oxcUJHdkRERERJQThS7Jy07VqlVhZ2eH58+fS9amtbU1GjVqhMTERISGhkrWLpGusrMDfHyAnTsBa2vlYer16wMLFyoTPyIiIiLSXUUuyYuMjERkZCRcXFwkbdfc3BwAYMydKKiYUCiA/v2B27eB7t2BpCRg2jSgRQvg/n25oyMiIiKirBSpJC8lJQVjxoxBWloavvnmG8naTU5Oxrlz51C2bFlUqlRJsnaJCoMyZYCDB4GtW5W7cf79N1C3LrBiBZCWJnNwRERERJRBodt45X0pKSmIiopCaGgoLl68iPXr1+PBgwdYu3YtvLy8JOtn+/btiIyMxPfffw+FQpFluStXrqBNmza4ffs2oqOjYWlpCXd3dwwdOhQDBw7UWBdQ7tKZmJio/jomJgaAMslMTk6W5sUUQ6qx4xjmzcCBQMuWwMiR+jh+XA8TJwJ//JGGTZtSkdnvPjju8uC4y4PjLg+Ouzw47vLguMtDl8ZdmxgUQgiRj7Hkm06dOsHPzy/dtc6dO2PZsmVwdXWVrJ+oqCjUrFkTSUlJCA4ORqlSpTKUiYiIgLOzM2rWrIkaNWqgVKlSSElJQUhICE6fPo2EhAR07doV+/fvh5GRUZZ9zZw5E7NmzcpwfceOHTAzM5PsNRHlhRCAn58TtmyphYQEA5iYpGDo0Nvo1CkU2fweg4iIiIhyKT4+HgMHDlRPJmkiSZIXHh6OkiVLZnlY+IfGjBmDqlWrYty4cbnuc+vWrbh37x4SEhLw4sULXL16FQ8ePIC7uzvWr1+Pxo0b57rt9w0aNAg7duzA77//joEDB2pdPyIiAp9++imOHj2KiRMnYtmyZVmWzWwmz9HREZGRkdl+IylrycnJ8Pf3h4eHR4bdUyn3Hj4ERozQx7lzylXfHTqkYcOGVDg6AqmpwOnTqfD3D4KHRy20aaMPfX2ZAy4m+H6XB8ddHhx3eXDc5cFxl4cujXtMTAxsbW1zlORJslzT0dER06ZNw+zZs3NUPiEhAWvWrMlTkjd06NAM144fP47BgwfDw8MDAQEBed58Zf369dixYwdGjBiRqwQPAOzs7LBv3z5UqVIFa9euxcyZM7P8phgbG2e6sYvh/7V332FRXG0bwO+lLUVsCBZQFFTUKDbsAqIiirErij0auzHWqFFj1MSWRGNM7LEmKmqMihLAQrGX2JO8ViwgFlQEaQqc74/5FkV2lwUWFpb7d11zwc6cmXn27MDus+fMOcbGOr+o9AHrUbucnIDQUGDlSmDGDODIEQM0bGiAQYOke/giI40BuGDZMsDODlixQpqDjwoGr3fdYL3rButdN1jvusF6143CUO85Ob9WBl5JS0tDag7GVZfL5Xj48KE2Tp1J+/btsXPnTsTHx2PBggV5OtaRI0cwYcIENG/eHCtXrszTsczNzdGvXz+8efMGZ86cydOxiAoTAwPg88+By5elufTi4oBffgEiIzOXi4qS5t3bu1cnYRIREREVK1obXTO7QUUAqbkzLCwMfn5+sLKy0tapM2nTpg1sbGwQFBSU62NcunQJPXv2hJ2dHfbt26eVaRNq1KgBQJrigUjfODkBYWFAqVLKtys6hU+cKHXlJCIiIqL8k6skz9zcHIaGhhmLTCbD4sWLM61TtpiamqJt27Z48eKF0u6W2mJpaYnY2Nhc7Xvnzh106tQJxsbGCAwMRPny5bUSk2I0HN5bR/rq1Cng1SvV24UAHj4EwsMLLiYiIiKi4ihX9+S5u7sjOTk543FYWBgqV66sdg45mUwGuVyOihUrwsPDA4MGDcrNqbP16tUrPHjwAPb29jne98mTJ/Dy8kJ8fDyOHj0KJycnrcV14cIFAEDdunW1dkyiwiQ6WrNyPXsC3bsDXl6ApyeQT436RERERMVWrpK8v/76K9NjAwMDDBgwAAsXLtRKUHmxePFivH37Fr169crRfnFxcejUqRPu37+Pffv2oXnz5lqL6caNG/Dz84OLiwuqVq2qteMSFSYVK2pWLjZWmlh982ZAJgOaNpUSvo4dgSZNAKMiPXsnERERke5p7Z68gvD48WNcu3ZN6bbExERMmTIFixcvhr29PWbOnKnxcVNSUtC9e3dcunQJq1evRufOnXMU1927dxGtohkjPDwcnp6eSE9PVzt9AlFR5+oqjaKp6vZcmUzaHhQETJ0K1K0rdeE8exaYPx9o2RKwtgZ8fICNG6XBWoiIiIgo57TynfmOHTvg7OysjUOpFRwcjCFDhqB69epo0qQJypcvD0NDQzx8+BCHDx/Gy5cv0bRpU+zevRullIwAsWTJEgQEBGDbtm2oUqVKxvqFCxciJCQE9vb2uH37NmbMmKEyhlatWqFLly6Z1h04cADTpk1D8+bN4ejoCCsrK8THx+PcuXO4cuUKLC0tsWPHDri6umqvMogKGUNDaZqE3r2lhO79GTgVid+KFUCHDtLy3XfSKJzBwUBgIHD4sNTKt3u3tABSItixo9TS5+oKaGEMJCIiIiK9p5Ukr2/fvto4TLbc3d0xceJEnDp1CoGBgYiLi4OBgQGsra3h5uaGAQMGoFevXjAwUN5AOX/+fCQmJsLPzw/Tpk3LWP/kyRMAwP3797FkyRK1MYwaNSpLkvfxxx/jxo0bCA8Px8WLF5GcnAxLS0vUrFkTs2bNwtixY1GpUqU8Pnuiwq9nT2DPHmlahfenUbCzA378Mes8eXZ2wLBh0pKaCpw/L7X0BQYC584B169Ly/ffA+bmgIfHu66d1aurbjUkIiIiKs60fvdLfHw8du/ejVOnTiE6OhoGBgawtbWFu7s7evToAVNT01wf297eHsuXL8/1/n379sXBgwfh6emZaf2aNWuwZs2aXB+3evXqWL16da73J9InPXsC3boBISGp+Ouvy+jUqQE8PIxgaKh+PyMjoEULafn6a+D5c+DIESnhCwwEHj8GDh2SFgBwcHiX8Hl4AJaW+f7UiIiIiIoErSZ5K1aswJw5c5CQkADxfl8tAOvXr0eZMmWwcOFCjBw5Upun1djGjRt1cl6i4sbQEHB3F0hIiIK7e/1sEzxlrKyAvn2lRQjg2jUp2QsKAo4fB+7eBVavlhZjY6BVKynh69gRcHZmKx8REREVX1obeGXatGmYNGkS0tLS8NlnnyE0NBQPHjzAgwcPEBYWhs8++wxJSUkYM2YM5s2bp63TElExIJNJidsXXwBHjwIvXgAHDgDjxkktem/fAqGhwIwZQIMGQKVKwNChwM6dUosgERERUXGilZa8sLAw/PDDD2jevDn2798Pa2vrTNvt7Ozg6uqKmTNnonPnzliwYAE6d+4MFxcXbZyeiIqZEiWALl2kBQBu3353L9+xY1LXzi1bpEUmk6ZmUAzg0rSp+mka0tKklsLoaGlaCFdX5KolkoiIiEhXtNKSt2rVKpibm2P37t1ZErz3lS9fHnv27IGJiQl++uknbZyaiAjVq0utev7+Uivf0aPAtGlAvXpSV89z56RpGlq1kqZp6NMH+PXXzIPDAMDevUDVqtI9fv37Sz+rVpXWExERERUVWmnJO3nyJLy8vGBra5tt2apVq8LLywthYWHaODURUSZyOdC2rbQsXSrNtxccLLX0BQcDL19KI4Du2SOV/+gjqZXPwgJYsCDz1A+AtH/v3lL5D0cHJSIiIiqMtJLkxcTEoGrVqhqXd3BwQGBgoDZOTUSklq0t8Mkn0pKWlnWahn/+kRZVhJC6fE6cKI0ayq6bREREVNhppbtmyZIl8ezZM43LP3v2DCVLltTGqYmINGZoCDRvDsydC5w+DTx7Bvj5SS156ggBPHwIhIcXTJxEREREeaGVJK9evXoIDAxEYmJitmUTEhIQGBiIhg0bauPURES5VrYs4OMDDB6sWfnevYFBg4CNG6UpHD7s2klERERUGGglyRswYABiYmIwbty4bMuOGzcOz58/x9ChQ7VxaiKiPKtYUbNyL14Av/0GDB8OODpKg7IMHQps3gzcv5+PARIRERHlgFaSvE8++QQtW7bE1q1b4eHhgcOHDyM1NTVje1paGg4fPgx3d3ds27YNnp6e6NevnzZOTUSUZ66ugJ2d6gnUZTJpe1AQMHu2NEqnkRHw4IE0TcMnn0gJX7VqwLBhwNatUvdOIiIiIl3QysArMpkMAQEB6NOnDw4fPozw8HDI5XLY2tpCJpMhKioKycnJEEKgW7du+O2337RxWiIirTA0BFaskLpjymSZu2EqEr8VK4AOHaQFABISgFOngJAQaTl/Hrh3D9i0SVoAqbWvTRtpKoY2baRBYEg5zk9IRESkPVpJ8gBp8JWgoCAcOnQIW7duxblz5xAZGQmZTAZbW1u0bt0aw4YNg6urq7ZOSUSkNT17StMkfP555vnz7OyAH3/MOn2ChQXg6SktAPD6NXDiBBAaKiV9f/8N3LkjLb/+KpWpUeNdwtemjebdRPXd3r3K633FCk5bQURElBtaS/IUOnfujM6dO2v7sERE+a5nT2mahNy0KJUoIY3SqRipMy5OSvpCQqTE7+JF4NYtaVm3Tirj5JQ56StfPp+eWCG2d6/Ugsr5CYmIiLRH60keEVFRZmgoJVx5VbIk4O0tLQAQG/su6QsJAS5fBm7ckJY1a6Qydeq8697p7g5YW+c9jsIsLU1qwVM2SinnJyQiIso9rSd5QgiEhITg1KlTiI6OhoGBAWxtbeHm5oaWLVtq+3REREVC6dLAxx9LCwC8fCnNu6fo3nnlCvDvv9KyapVUpm7ddy197u6AlZX6c6SlAWFhMoSH28LCQgYPD90kR+np0kikz569W2JiMj9+9gyIiMjcRfNDivkJBw8G3NwAe3tpgJsqVQBz8wJ7OkREREWOVpO8/fv3Y9KkSbh//z7EB1/NymQy1KpVC8uWLYOXl5c2T0tEVOSUKSO1UHXrJj1+/lxK+hTdO69dA65fl5aVK6Uyzs5S0ufhISU9Zcq8O967+9qMALhg2TLt3df25o3yJE3ZumfPpAQvPT1v53zf9u3S8j5r63dJn739u0XxuFQp7Z2fiIioqNFakvfTTz9h0qRJAIAuXbqgZ8+ecHBwAABERETgjz/+gL+/P7y9vbFu3ToMHz5cW6cmIiryrKyAHj2kBZCSpbCwdy19//4LXL0qLStWSF0ZGzSQWvnkcmDJEs3uaxNCGhlUXaL24bq4uNw9pzJlpGSsXDnp54fLo0fA9OnZH6d7dyA1VZqL8P59KR5FbBcuKN+nVCn1SWC5cqqnzMipwtKCSkREpKCVJO/KlSuYPHkyHB0d8ccff6BevXqZtrdu3RqDBg3ClStX0KNHD4wbNw6urq6oWbOmNk5PRKR3rK2lBK13b+nxkydS0qdo6fvf/4BLl6RFFUXS17+/dL+fInlLTs55PIaG75I1VUnb++utrABjY/XHTEuTWimjopTfl6eYn3DPnsxJU2ysNF2FIul7//f796Xn+erVu6RYGXNzqdunqiSwYkXAQIOZZPOzBZWIiCi3tJLk/fjjjzAyMsKBAwdQq1YtleXq16+Pffv2oXHjxli+fDlWr16tjdMTEem98uUBHx9pAaTRP8PCgN9/Bw4eVL9vSkrWZNDUVHWCpmx96dKaJT05ocn8hD/+mLVVrHRpqRWzQQPlx01IyJz0fZgEPnoEJCZKifL//qf8GMbGUhKoLAG0t5cSOX9/jgxKRESFk1aSvNDQULRt21Ztgqfg7OyMdu3a4fDhw9o4NRFRsVSxItCvn5RgZJfkAcC0aUCfPu+SNgsL7XVXzIuczk+oCQsLqeWyTh3l21NSpAFdlCWA9+5Jcbx9+26eQ2VkMinp5cigRERUGGklyXv8+DF65uCduE6dOggPD9fGqYmIijVNJ1T39gaaNMnfWHIrL/MT5oZcDlSvLi3KpKZKrX3KEsD794EHD6REMS1N9TkUI4MeP66dKTmIiIhyQitJnrm5OV69eqVx+bi4OJhz/GsiojxzdZVavbK7r83VteBjywltzU+oDUZGUlfNKlWUb09PB9auBcaOzf5YP/wg3Z/4wa3qRERE+Uord1jUqlULwcHBSE1NzbZsamoqgoOD8dFHH2nj1ERExZrivjYga/dLdfe1Ue4ZGAC1a2tW9uBBaeqL+vWB776TknEiIqL8ppUkr3fv3oiMjMRXX32Vbdk5c+YgKioK/fv318apiYiKPcV9bba2mdcrRqbk4B/ap2hBVXVfo0z2bloMExNplM8vvgAqVwbatwc2bwbi4ws0ZCIiKka0kuSNGzcOTk5OWLJkCYYOHYqbN29mKXPz5k0MGjQIS5cuRcOGDTFixAhtnJqIiCAlcvfuAYcPp2Ly5As4fDgVERFM8PKLJi2o69ZJUyxER0vdO1u3lrrUHj0KfPKJNGKqry9w6JA00AsREZG2aCXJMzExwZEjR1CnTh1s3boVtWvXRvXq1eHp6YkOHTqgRo0aqF27Nn7//Xc0bNgQhw4dgoG2x+ImIirmDA0Bd3cBN7couLsLdtHMZ5q2oJYtC4wcKQ3Ccvcu8M03gJMTkJQE7NwJfPyxdIwJE4Dz55XfW0lERJQTWsu0bG1tcfHiRaxcuRIuLi54+PAhjh49iiNHjiAyMhJubm7YsmULzp07h/Lly2vrtERERDqT0xbUatWAWbOA//6TEroJE6QpLZ49kyaGb9oUqFULWLAAiIgo0KdCRER6RKvNacbGxhg3bhzOnj2LhIQEREdH4/Hjx3j9+jVCQkIwaNAgtuAREZFeyU0LqkwGuLhIXT6jooCAAKnrppkZcPMm8NVXgIOD1MVzzRrgxYv8fx5ERKQ/8i3jMjIyQvny5WFjYwND9hkiIiJSytgY6NQJ2L4dePIE2LJFGpxFJgNOngTGjAEqVJAGcdm7V5qjj4iISB2dNKv9888/GDRokC5OTUREVGhZWgKDBwOHD0uTqX/3nTT9wtu3wL59QK9eUsKnuMcvPV3XERMRUWGU6yQvLS0N/v7+mDVrFkaPHo2vvvoK//77r9p9bt++jQEDBqB+/frYuXNnbk9NRESk92xtgalTgcuX303BYGsLxMYC69cDbm5Sl85Zs4D//U/X0RIRUWGSqyTv7NmzqF69Orp3745FixZh3bp1+Oabb1C/fn1Mnjw5S/mHDx9ixIgRqFOnDnbs2IHatWvDz88vz8ETEREVB/XqAUuWAPfvA8eOSVMwWFpKjxculCZnd3GRJr5/8kTX0RIRka7lOMl78OABOnbsiMePH2Py5Mk4ePAgTp06hV27dsHV1RUrVqzA2LFjAQBPnjzBhAkTULNmTfz666/46KOP8Mcff+DatWvoycmbiIiIcsTQEPDwADZulJI5xRQMRkbA338DkyZJrX2Ke/wSEnQdMRER6YJRTnf47rvvEBcXh4MHD6JTp06ZtvXu3RtDhgzB2rVrERcXh3379iExMRENGjTA3Llz0a1btzwHHBkZCT8/Pxw9ehQ3btzA48ePkZaWhkqVKqF58+YYPnw42rVrl+vj//vvv/j+++8REhKCx48fw8bGBm3atMG0adNQt25dtfs+fPgQ33//PQICAhAZGYmyZcuiefPmmDJlClq2bJnrmIiIiD5kZgb07Sstz54Bfn7Ab78BZ88CgYHSUqKENJ3DwIFA27bIMvJnWpp0b190NFCxIuDqmrUMEREVPTluyQsKCkLdunWzJHgKK1euhLm5OXbs2IEaNWpg3759uHjxolYSPABYu3Ytpk6diuvXr6Nu3boYPnw4+vfvDysrK+zYsQPt27fH0KFDkZ6Lu9EDAgLQpEkT/Pbbb3B2dsaoUaPQoEED7NixA02bNoW/v7/Kfc+fP4/GjRtj5cqVqFatGkaNGoXWrVsjMDAQbm5uWLt2bV6eNhERkUrW1sD48cCZM8CNG++mYHj9Gti6FejQAahc+d09fkJII3VWrSq1DPbvL/2sWlVaT0RERVuOW/IiIyPRr18/ldtLliyJdu3a4cSJE7h06VKeglOmf//+6NGjBxo1apRl2+XLl+Hr64stW7agXr16mDJlisbHjY6OxoABA2BpaYng4GA4OztnbLt69So8PT0xcOBAXL9+HZUrV860b0JCAvr27YuEhAQcPXoUHh4eGdsePHgAT09PjB8/Hi4uLmjcuHEunjUREZFmatYE5s0Dvv4aOH1aat3z85Na6374QVoqV5ZG7/xQVBTQuzewZ4/qCd2JiKjwy3FLXnJyMqysrNSWcXR0xMuXL3MdlDq1a9dWmuABQIMGDbB//37IZDJs3rw5R8f95ptvEBsbi1WrVmVK8ADA2dkZq1evRlxcHObPn59l31WrViEiIgILFizIlOABQJUqVbB9+3akpqZixowZOYqJiIgot2QyoGVLYNUqKcHbt09K4ExMlCd4gNTCJwQwdqw0KfuLF1KXzsIoLQ0IC5MhPNwWYWGyQhsnEZEu5LglDwCMjY3VbjcxMclVMNpQs2ZNWFtb49GjRxrvk5qait9//x3VqlVDjx49lJbp0aMH7O3t4efnh1WrVmWqg82bN6NEiRIYOXKk0n0bN24MNzc3HD16FNHR0ahYsWLOnhQREVEemJgA3bpJy8GDQJcu6ss/eQI4Ob17XKoUUKYMULq09FPV8uH20qWlyd61be9e4PPPgchIIwAuWLYMsLMDVqxgCyQREZDLJK8wi4mJQUxMDFxcXDTe58KFC3j16hV8fX0hk8mUlpHJZOjQoQPWr1+PCxcuoEWLFgCAx48f499//0XHjh1RokQJlefw8vJCeHg4QkND4evrm7MnRUREpCXx8ZqVMzEB3ryRfn/1Slpyo0QJ1UmgugSxTBlALs96vL17pRZJITKvZ1dTIqJ3cpXknTt3DsuWLVO7HQCWL18O8eF/4f9nZmaGMWPG5Ob0KqWmpmL8+PFIT0/H9OnTNd7vypUrAID69eurLdewYUMA0j16iiQvN/syySMiIl3RtDNJUJDU3TM2Fnj5UvmibpsimXz9WlpUdRFVx8wscxJYujQQEpI1wQOkdTIZMHGi1GLJUUKJqDjLVZJ37NgxHDt2LNty6gY+kclkeU7yUlNTERsbi3v37uHUqVNYvXo17ty5g19++SVH8/Ddu3cPgHT/nDqK7Yryed33QykpKUhJScl4HBcXBwB4+/Yt3r59q/b4pJqi7liHBYv1rhusd90oSvXevDlga2uER48AIbL2XpHJBGxtgebNUyGTvUuycio1VWr9k5JB2XuJoSwjOVSslx5L6xWLEDIkJQFJSYCmd2AIISWTISGpcHdX/iUz5V1Rut71CetdNwpTveckhhwnebt27UKCFmZXNTMzy9P+Xl5eCA4OzrSuY8eO2Lt3L2rXrp2jY736/z4oJUuWVFvO0tIyU/m87vuhRYsWYd68eVnWBwcHw9zcXO3xKXuHDx/WdQjFEutdN1jvulFU6n3gwIpYsqQJAAHg/URPQAhgwIDzCAqK1vp5S5SQFjs79eXS04HERCMkJJjg9WtjvH5tjIQEY1y6ZIPDh6tme54BA1LQtu1DuLg8hqPjK6i4E4PyqKhc7/qG9a4bhaHeExMTNS6b4ySvd+/eOd0lX/j6+qJhw4ZITk7GkydPcP78eQQGBuLJkydYvXo1mjVrpvGxFK1n2Q0YY2pqmql8Xvf90MyZMzF58uSMx3FxcahcuTI6dOiQbRJJqr19+xaHDx+Gp6dntoMGkfaw3nWD9a4bRa3evb2BRo3SMHmyIaKi3q23swN++CENPXo0BNBQZ/GpEhYmgyafs54+tcDOnbWwc2ctVKok4O2dDm9vgbZtBfidad4VtetdX7DedaMw1buil58miuzAK0OHDs2y7siRIxg4cCA8PT1x8eJFVK9eXaNjKRKwN4o7zFVITk4GkLkVMi/7fkgul0Ou5C5zY2NjnV9U+oD1qBusd91gvetGUap3Hx+gVy/g+HFpioWKFQFXVxkMDQvvRwMPDykRjYpSfl+eTCY9j3nzgIAAIDgYePRIhg0bDLFhA2BqCrRrJ40u+vHHgK1twT8HfVKUrnd9wnrXjcJQ7zk5f47nySvM2rdvj507dyI+Ph4LFizQeD/FqJjZZceK7e+PopmXfYmIiHTJ0BBo0wbw9ZV+FvbBSgwNpWkSAGTpgql4vHIl8Omn0iicMTHAX38B48YBVaoAycnAoUPA6NFSstioETB3LnDhgtRFlIhIX+hVkgcAbdq0gY2NDYKCgjTeRzEoyoMHD9SWU2y3t7fXyr5ERESUMz17StMkfNgKZ2eXdfoEU1OgY0fg55+Be/eAK1eAb7+VBp+RyYBLl4D584EmTaT9R4wA9u8HtDD0ABGRTuldkgdIg5zExsZqXF4xUMvly5fVllNsr1Wrllb2JSIiopzr2VNK2g4fTsXkyRdw+HAqIiLUz48nkwHOzsCXXwKnTwOPHwObNkn7lCghdVndsAHo3h2wsgI6dwZWr87d1A9ERLqmd0neq1ev8ODBA1SuXFnjfVq0aAEzMzMEBwernNcvPT09Y5RLxRx5AODg4IBq1arh5MmTeP36tcpzBAYGAgDatWuncVxERESknKEh4O4u4OYWBXd3keOupjY2wNChwB9/SN06g4KA8eMBe3sgJUW6p2/sWKmbZ8OGwJw5wLlz7NZJREWD3iV5ixcvxtu3b9GrVy+N9zEzM0OPHj0QERGBP//8U2mZP//8E/fv30e3bt0yBltR8PX1xevXr7Fu3Tql+164cAHHjx9HixYtsp1Pj4iIiAqWXA506CDdzxcRAVy7BixaJE0GL5MBly8D33wDNGsGVKoEDB8O7NsnTfJOROqlpQGhocCOHdLPtDRdR6S5tDRpVN/wcFuEhcmKVOxFKsl7/Pgxrl27pnRbYmIipkyZgsWLF8Pe3h4zZ87M0bHnzJkDuVyOsWPHZjnH1atXMXbsWJiYmGD27NlZ9p08eTLKli2LOXPmICQkJNO2Bw8eYMCAAZDJZJg/f36OYiIiIqKCJZMBdesCM2YAJ08CT54AW7YAvXsDlpbS440bgR49gHLlgE6dgF9+AbK5NZ+oWNq7F6haVRoZt39/6WfVqtL6wk4Ru6enEZYtc4Gnp1GRiR0oYlMoBAcHY8iQIahevTqaNGmC8uXLw9DQEA8fPsThw4fx8uVLNG3aFLt370apUqWy7L9kyRIEBARg27ZtWVrUatWqhU2bNmHIkCFo3LgxOnfujKpVqyIiIgIBAQEQQmDTpk2oU6dOluNaWVnhjz/+QJcuXdC+fXu0b98etWvXxuPHj+Hv74+kpCR8++23aN++fb7VDREREWmftTUweLC0vHkDhIcD/v7SEhEBBAZKy/jx0j1/H38sTdHQtClgoOKr9LS0D6euKPwjmxLl1N690pcjH94JFRUlrf9woKTCpCjHrlCkkjx3d3dMnDgRp06dQmBgIOLi4mBgYABra2u4ublhwIAB6NWrFwxU/FedP38+EhMT4efnh2nTpmXZ7uvri9q1a+O7775DaGgoAgICYGVlhZ49e2LatGlo3LixytjatGmDK1euYMmSJQgKCkJYWBhKliyJtm3bYuLEibwXj4iIqIgzMQHat5eWH38E/vtPSvYOHgROnQKuXpWWhQule/68vaWEz9NTagUEpA+Pn38OREa+O66dnTQ1RGH/0Ei68363QQsLGTw8Cu8XA0lJwNOn0j2tyoa6UKwbMULq8mxsLD0XIyPpp2JR9zgnZT98/OH0Kx9KS5P+RlXFLpMBEycC3boV3tcAKGJJnr29PZYvX57r/fv27YuDBw/C09NTZZkGDRrg999/z9XxHRwcsHbt2tyGR0REREWETAbUqSMt06dLg7cEBkpJX2Cg9CF382ZpMTGR5iGsXFnq6lmUWweo4L37YsAIgAuWLSuYLwaEkJKwmBjg+XNp0eT3xETNjv/iBTBkSP7Fr4qBgfqEMDVVej6qCCGNunv8uPR3XVgVqSQvrzZu3KjrEIiIiEgPlSsHDBwoLW/eACdOvOvWeecOEByset+i1DpQlBXFbrLa6jaYng7ExmqeqCl+f/s2d3HLZMpbwj5Ut67U6p2aKr0+iiUnj5Vty64u0tNz/9wUoqPztn9+K1ZJHhEREVF+MzEB2raVlmXLgBs3pO6d6jr7KFoHbG2laRxsbN4t1taZHyvWGRsX2FPKUJS6Db6vKHaT1aTb4Jgx7xI4VQnb8+dSq1lup/+Qy6UvMays3v3M7veLF6XrPzsrV+ZPa1h6eu4SxrQ04MwZYPTo7M9RsaL249YmJnlERERE+UQmA2rVAtzd1Sd5Ck+eSIsmypTJmvypSgrLlFE9EIymdNVtMK/ycxANIaSW2+Rk6V605GTVv2e3/cPfHz3KnJQqO/fTp0CfPprHa2mZfZL24WNz8+zvY/uQm5t0bURFKU9SZTJpu6trzo6rKQMDacnNFyF160pTpugqdm1hkkdERESUzzT91v+XX6QPkE+fql6ePZNaKl6+lJYbN7I/rqGh8uRPVWJoYZH5g31hGW1QCKm15c0bqbvdmzfqf09OBkaNUj8AyCefSAPnfJisaZKIJSdr1i0xP1WvDjg5Zd/KVras1CpXEAwNpeS/d++sXTcV19WPPxbOVuCiHPv7mOQRERER5TNXV81aNkaNyv7DoyLBU5cIvr/ExkqJ0ePH0qIJM7PMCWBoqPpEafhw4O5dqeubIsnKLgnL7XZti4sDfvhBO8cyMwNMTd/9zMvvd+8CCxZkf8716wvnACA9e0rJv7Jusj/+WLhbf4ty7ApM8oiIiIjymTZbBwwM3rXS1K6dffk3b6TWP0UroLqE8MmTd61V9+9LiyZiYwEls1MVCCMj6T5IY2Pp5/u/Jyaq7/Ko4O0NNGyYt+TMxCTn3RrVSUsDNm0q2t0Ge/aUBhMqagPeAO9iDwlJxV9/XUanTg3g4WFUJGIHmOQRERERFQhdtQ6YmEgDutjaZl9WCCAhIXPi5+8PbNiQ/b6tWgE1a6pOuJSty+t2Y2P1iVVoKODhkX3s06YVvtYwfek2aGhY+OpWU4aGgLu7QEJCFNzd6xf6un4fkzwiIiKiAlLYWzZkMqBECWlxcJDWlSypWZL3zTeF78O8pt1kC2trmD50GyTdYJJHREREVICKWstGUU6U9KE1rKh3GyTdyONgukRERESkzxSJEpC1a2RRSJQUrWEfdle1syu4UUHzStFt0M0tCu7uotDWNRUeTPKIiIiISK2inij17AncuweEhADbt0s/IyIKf9xEucXumkRERESUraLebbCodZMlygsmeURERESkkaI82iBRccLumkRERERERHqESR4REREREZEeYZJHRERERESkR5jkERERERER6REmeURERERERHqESR4REREREZEeYZJHRERERESkR5jkERERERER6REmeURERERERHqESR4REREREZEeYZJHRERERESkR5jkERERERER6REmeURERERERHrESNcBkGpCCABAXFycjiMp2t6+fYvExETExcXB2NhY1+EUG6x33WC96wbrXTdY77rBetcN1rtuFKZ6V+QEihxBHSZ5hVh8fDwAoHLlyjqOhIiIiIiICoP4+HiUKlVKbRmZ0CQVJJ1IT0/Ho0ePYGlpCZlMputwiqy4uDhUrlwZDx8+RMmSJXUdTrHBetcN1rtusN51g/WuG6x33WC960ZhqnchBOLj41GpUiUYGKi/644teYWYgYEB7OzsdB2G3ihZsqTO/ziLI9a7brDedYP1rhusd91gvesG6103Cku9Z9eCp8CBV4iIiIiIiPQIkzwiIiIiIiI9wiSP9J5cLsfcuXMhl8t1HUqxwnrXDda7brDedYP1rhusd91gvetGUa13DrxCRERERESkR9iSR0REREREpEeY5BEREREREekRJnlERERERER6hEkeERERERGRHmGSR3opPDwcI0eOhJOTE8zMzGBubo569eph1qxZePnypa7DK1YuXrwIU1NTyGQyfPfdd7oOR+8dPHgQQ4cOhZOTE0qXLg0zMzNUrVoVPXr0QGxsrK7D0ztnz57FkCFDULVqVZiYmKBEiRJo2LAhZs2ahWfPnuk6vCIvMjISjRo1goGBAc6dO5dt+efPn2POnDmoU6cOLCwsUL58eXTs2BEBAQEFEK3+yEm9X7p0CZMmTUK9evVgYWEBU1NT1KxZExMmTEBkZGQBRawfcnq9K9vfysoKMpkM48aNy4cI9VNu6z08PBxjx45F3bp1YWVlBblcDjs7O3h7e+Pu3bv5GLFmjHQdAJG2jRo1CuvWrYOFhQVat26NDh06ICkpCWFhYVi4cCG2bduG0NBQODg46DpUvff27VsMGzYMxsbGSElJQUJCgq5D0lsPHjzAkCFDEBoaCktLS3h4eMDT0xMAEBUVhdOnT+PVq1coXbq0bgPVI3PmzME333wDQ0NDtG/fHl26dMHLly8z/tesXbsWBw8eRPPmzXUdapF08eJFdOnSBY8ePQIAJCYmqi1/9+5deHp64u7du2jZsiXat2+P2NhY+Pv7o3Pnzpg1axa++eabggi9SMtJvS9atAhffvklTExM0LJlS7i5uSE9PR2nTp3CypUrsW3bNgQHB6NJkyYFFX6RldPrXZlRo0bhzZs3AMD3Ww3lpt5fvnyJkSNHYs+ePTA1NUWbNm3g6uoKExMTREdH48yZM4iMjNT950xBpGfWrVsnfv31V5GYmJhpfUpKihg1apQAIFq3bq2j6IqXefPmCSMjI7Fs2TIBQMydO1fXIemlR48eCUdHR2FsbCzmz58vkpKSdB2S3tuwYYMAIBo3bixu3bqVaVtKSor4+uuvBQBha2srUlJSdBRl0XXgwAFhYWEhqlWrJvr16ycAiJCQEJXl09LSRPPmzYWBgYHYvn17pm3Pnz8XLVq0EADEvn378jnyoi2n9b53716xbNkyERsbm2l9enq6mD9/vgAgHBwcxJs3b/I58qItp/WuzJYtWwQAsXLlSgFADBkyJF9i1Se5qff4+HjRrFkzIZPJxGeffSZevXpVMMHmApM8KlZSUlJEjRo1BABx+/ZtXYej165duyZMTEzEjBkzREhICJO8fNS5c2cBQGzbtk3XoRQb9erVEzKZTNy9e1dlGW9vbwFAHD58uAAjK/qCgoKEgYGBaNasmXj69KmYO3duth++du3aJQCIzz77TOn2hw8fCjMzM1GjRo18irroy029Z8fd3V0AEEeOHNFeoHpGG/UeHR0typYtK/r16yciIiKY5Gkgt/U+btw4AUB88803BRNoHvCePCpWTExM4OHhAQC4ceOGjqPRX2lpaRg2bBjs7e0xd+5cXYej106ePIlDhw6hT58+GDhwoK7DKTaePn2K8uXLo1q1airLNGvWDADw6tWrggpLLzRr1gwzZsxASEgIrK2tNdpn8+bNAIDJkycr3W5nZ4c+ffrg1q1bOHPmjLZC1Su5qffseHl5AeD7rTraqHfF/XcrVqzQZmh6LTf1fv/+faxZswZNmzbFrFmz8jnCvGOSR8WOhYUFAEAul+s4Ev31ww8/4MKFC1i/fj1MTU11HY5e27ZtGwBg6tSpOo6kePnoo48QExODmJgYlWXOnj0LAwMDNGrUqAAjK/pKlSqFb7/9FmZmZhqVT01NRXh4OGrVqoWqVauqLKdIOEJCQrQRpt7Jab1rgu+32ctrve/atQt79+7F8uXLYWNjo+Xo9Fdu6n3Hjh1IS0vDlClT8jEy7WGSR8XOsWPHYGJiwhvB88nNmzcxd+5cjBgxAu7u7roOR+8FBwfDxsYGTZs21XUoxcr06dORmpqKcePGIT09Pcv2jRs3IiAgAKNGjVLb2kd5d+fOHbx+/Rr169dXW65hw4YAgKtXrxZEWATg6NGjAIBWrVrpOBL99Pz5c3z22Wfo0KEDBg8erOtw9F5wcDAMDAzg7e2t61A0wiSPipVjx47hypUr8PHxQcmSJXUdjt4RQmD48OEoW7Ysli5dqutw9F5cXBzu3bsHZ2dnAEBoaCi8vb1Rvnx5mJqaolatWpg0aRKioqJ0HKn+6dChA7777jvs2rULH3/8MZ48eQJAalWaP38+Pv30U/Tu3ZvdpwrAvXv3AABVqlRRW06xXVGe8tetW7dw6NAhtG7dGrVq1dJ1OHppwoQJSEhIwNq1a3UdSrFw9epVODg4oESJErh06RJ8fHxgZ2cHuVwOBwcHjBgxAv/73/90HWYGJnlUbLx9+xaTJ0+GXC7nfWL55Oeff8aJEyewevVqlCpVStfh6L3IyEgIIVCpUiXMmjULHh4eePHiBXx8fDBy5EiULVsWP/74I+rUqYOwsDBdh6t3pk6dikOHDuHmzZuoXr06pkyZgsaNG2Pp0qVYtmwZ/Pz8YGxsrOsw9Z7insfsvrizsLCAgYEB75EsIBMnTkRaWhoWLlyo61D0kr+/P7Zv346FCxeq7aZM2pGYmIjnz5+jUqVKWLNmDZo0aYL//vsPXbp0wZgxY+Do6IiNGzeifv368PPz03W4ADhPHhUjX3/9Na5cuYJvv/0W1atX13U4eufevXuYOXMm+vbti65du+o6nGIhPj4egHSPUVxcHI4cOYJ27dplKnPgwAH4+Pige/fuuHnzptYGVCCJXC5HtWrVEBERgUuXLiEyMhI2NjawsLDAmzdveE9qAUhJSQEgDayVHblcnlGe8s/69esREBCAESNGwNXVVdfh6J1Xr15h9OjRaNmyJcaPH6/rcIoFxfvt7du3MWnSJGzbtg2+vr6Zypw5cwadO3fGwIEDUa9ePdSpU0cXoWZgSx4VC4cOHcKiRYvg5eWFGTNm6DocvTRixAiYmppi5cqVug6l2Hj79i0A4OHDh1i2bFmWBA8AunbtiunTpyM2NhZr1qwp6BD1Vnx8PHr16gVPT09UqFAB//33H44dO4Z79+5h6NChmDhxImrXro3jx4/rOlS9p0ikFZNAq5OSkqLVgUUoq4sXL+Lzzz+Hs7Mzuyvnk8mTJ+P58+fYsGEDDAz4Ub4gKN5vHz16hGnTpmVJ8ACgefPm+P7775GamooffvihoEPMglcG6b1r166hf//+cHBwwPbt2/kPMR9s2LABR44cwY8//siWogKkGLmuUqVKGDZsmMpyQ4cOBcBRBbXJx8cHe/fuxbZt27Bt2zbUrFkTAGBpaYmvvvoKV65cASCN6Kj4nfJHiRIlAEj3qKrz+vVrpKenZ5Qn7YuKikK3bt1gbm6OP//8kwl1Pjh8+DA2btyI2bNno3bt2roOp9hQvN8aGxvjiy++UFnO19cXJiYmheL9lp92Sa89ePAAHTt2hKGhIQ4ePIiyZcvqOiS98/z5c0ydOhWdOnXiPG0FTJFQOzk5qS1XrVo1GBkZITo6uiDC0nsnTpxAYGAgevbsiQEDBigtU716dWzfvh1JSUmYN29eAUdYvCgGVHnw4IHacort9vb2+R5TcRQbG4uOHTvi2bNn2Lt3LxwcHHQdkt5JTU3FyJEj4ezsjOnTp+s6nGKlZMmSMDExgZ2dndovikxNTVG5cuVC8X7LJI/01vPnz+Hl5YUXL15g//79HN0rn0RGRuLVq1f466+/IJPJlC6KCejnzZuXsY4TEuedra0tLCwskJSUpLZceno60tPTOQiIliiu3S5duqgt16JFC5QrVw6nT58uiLCKrerVq8PY2BiXL19WW06xne8F2pecnIyuXbvin3/+wdatW+Hm5qbrkPRSQkIC7t27h6tXr8LExETp+61iypYtW7ZkrNu5c6eOIy/6DA0N4ejomO37LQCkpaUVivdbDrxCeikhIQHe3t64efMm9uzZwxu/85GdnR2mTZumdK4whYcPH2LXrl1o0aIFWrZsCZlMhsqVKxdglPpJJpOhRYsWOHnyJBISEjK6k3zo+vXrSE9P54dbLTE0NASAbAfwSE9PR3JyMiwtLQsirGJLLpejVatWCA0Nxb1791SONBgYGAgASu9dpdxLS0tDv379cPz4caxYsQI+Pj66DklvWVhYYMaMGRn3hykTFxeH9evX46OPPkLHjh0BAHXr1i2oEPVaq1atsGHDBkRERKic//Tly5d48OABGjduXMDRZcUkj/TO27dv0bt3b5w7dw6rV69Gjx49dB2SXrOyssp2TrzQ0FDs2rULHTp0wNdff10wgRUTPj4+OHLkCFasWIEvv/xSaRnF4Ae9evUqyND0VrNmzQAAv/76K4YPHw4jI+Vvpf7+/nj9+jXc3d0LMrxiqX///ggNDcWyZcvw008/ZdkeGRmJ3bt3o3LlymjZsqUOItRfo0aNwv79+zFjxgxMmDBB1+HoNSMjIyxatEhtmXv37mH9+vVwcXHB999/X0CRFQ8+Pj7YsGEDFi1ahHXr1ikt8/PPPyM9Pb1QvN+yuybpFSEEhg0bhsDAQMyePRujR4/WdUhE+WrIkCFwcHDA3Llzs8zNk56ejiVLlmDjxo1o3rw5+vTpo6Mo9UvLli3h5eWF8+fPo0uXLoiIiMhSxt/fH8OGDYOBgQGmTZumgyiLl6FDh6JGjRr45ZdfsGPHjkzbXr58CR8fHyQnJ2Pu3Lkqk3LKuVmzZuHXX3/FoEGDsk0+iIo6T09PtG7dGuvXr8eyZcuybN+6dSsWLFgABwcHjB07VgcRZsb/dKRXNm/ejN9++w1lypTB27dv1U6XUKdOHQwePLgAoyPSPhMTE/z5559o27Yt+vXrh59++glNmjRBUlISjh07htu3b8PZ2Rl79+7lyLJa5OfnBx8fHwQGBqJWrVrw8PBAjRo1EBcXh7///hv//PMPTExMsG7dOrbkFQBjY2Ps27cPHh4e6N+/P1atWoVGjRohNjYW/v7+ePnyJUaPHo3hw4frOlS9ERISgoULF8LExATW1tZq328rVqyIzz//vACjI8ofO3fuROvWrTFlyhRs2bIFbm5uEELgxIkTuHLlCqpUqYKDBw8Wim76TPJIrzx58gSA9M3tkiVL1Jb18vJikldAFPNYcWLo/OHs7Izr169j0aJFOHToENasWQO5XI46depg3LhxGD16NOtey0qVKoWgoCAcOHAAmzZtwrlz53D06FHI5XI4OjpiypQpGDdunMr7Nkhzmv7/qFOnDq5du4YlS5bA398f69atg7m5ORo2bIjRo0ezJTuHsqt3xfvtmzdvlLZqvM/JyYlJnoby+n5pYmICAwMD/s/PIU3r3dbWFleuXMHSpUvx559/YuPGjZDJZKhevTrmzZuHzz//HKVKlSqIkLMlE0IIXQdBRERERERE2sG+O0RERERERHqESR4REREREZEeYZJHRERERESkR5jkERERERER6REmeURERERERHqESR4REREREZEeYZJHRERERESkR5jkERERERER6REmeURERERERHqESR4RUTHUsWNH1KpVS9dhFLjo6Gj069cPVlZWsLS0xCeffKLrkKgIGj16NAwMDHDt2jVdh6ITpqamGD16tK7DICI1mOQRESnh7e0NmUyGxo0bIy0tLdvyTZo0gZmZWQFEph3JyclITk7WdRgFrkePHvDz80OzZs0wYsQIlCtXTqP9li5dCplMpnapUKFCPkdP2UlJScHq1avRtm1bWFlZwdjYGFZWVnBxccGkSZMghNDKeZKTkyGEQEpKilaOV9SkpKQUy/8fREWJka4DICIqjBITEwEAFy9exLp16zBmzBi15ZOSkvihp5C7desWzp49i5EjR2Lt2rU52ldxPXTv3h1OTk5Ky5QpUybPMebFkiVLMGPGDJw+fRrNmzfXaSy6cPfuXXTq1Ak3b96Eo6MjOnXqhIoVKyIhIQHnz5/Hrl27sHz5cl2HqTWdOnVCaGgokpKSdB0KERVCTPKIiNSoWLEi5s6di/79+6NUqVK6Dofy4MaNGwCkVtrcGjBgAHr37q2tkLRK8WG/OH7ZkJqaiu7du+PWrVtYtWoVRo0aBQODzJ2VXr9+raPo8ge/WCIiddhdk4hIjQULFuDZs2dYsGCBrkOhPIqNjQUAWFpa6jYQ0rrg4GBcu3YNI0eOxJgxY7IkeABQokQJHURGRKQbTPKIiNTo1q0bPDw8sHLlSty5c0fX4VAepKamAoDSBICKtuvXrwMAWrdureNIiIgKB77TERFlY9myZUhNTcXUqVNzvO/ixYshk8lw5syZHJcJCgqCTCbDgQMH8M8//6BPnz6wsbFBiRIl0KhRI2zYsCGjbFxcHL766is4OTnBzMwMVapUwRdffKFRF7UTJ06gR48eKF++PORyOapWrYpPP/0Ut2/fVrvf1atX4evriwoVKkAul8Pe3h5jxozBo0ePlJbv2LEjqlWrBkBqeWncuDHMzc3h5OSUkYBp4tixY/Dx8YGtrS3kcjmsra3Rrl07bNq0Cenp6ZnKPnr0CIaGhpDJZBkjaXp4eGQMlrJz506Nz5sbQghs2rQJLVu2hKWlJSwtLeHi4oJffvklS6wKf//9Nz799FPUrVsX5cqVg7GxMWxsbPDxxx8jNDRU5fObN2+e2ueXl2vxzJkzkMlk2LJlC+Lj4zF27FjY2NigdOnSWLNmTaayz549w+TJk+Ho6AhTU1PY2NigR48eOHv2rNJzJiQkYPbs2ahXrx5KlCgBuVyOatWqwdfXF48fP1YZ6/sU90NeunRJo/IfunfvHj799FNUrlwZcrkclSpVwqBBgzK6+OZUeHg4unbtinLlysHU1BQ1atTAF198gVevXqnd77///sPo0aNRvXp1mJmZwdTUFJUqVUKnTp3w+vVr7Ny5M+O1DQsLA4CMx4aGhln+9nJz/SniGDJkSEZ9VKxYET179sSJEydyVR9EVPB4Tx4RUTYaNGiAIUOGYNOmTQgNDUWbNm003ldxz4y6e2dUlTE0NAQAhIWFwdfXFzY2NujZsyeEEAgLC8OIESMQERGB6dOnw8PDA//88w+6dOkCLy8vXLp0Cd999x3Cw8MRFhYGuVyu9NwrV67ExIkTUbduXfTp0wepqakIDQ3Fr7/+ip07d+LQoUNwd3fPst/vv/+OoUOHwsjICN7e3qhSpQpu376N9evXY/fu3QgLC8NHH32U5XkmJSUhNDQUXbp0Qdu2beHu7o6YmBjIZLJs61IIgQkTJuDnn3+GXC5Hhw4d4OjoiOfPnyMoKAjDhg3Dli1b4O/vn9Els3Tp0pgxYwbS0tJw7do1BAQEwNfXF1WqVAEAODs7Z3ve3Hrz5g18fHywf/9+VKlSBb6+vpDL5Th27BjGjx+PwMBA/PnnnzAyevdWnJ6ejubNm8Pc3BzNmjVDkyZNUKpUKTx48AABAQH466+/sGvXLvTq1SvL8ztx4gROnjyp8vnl5VpUPE5MTETv3r1x/fp19OrVC0ZGRpnuVb169So8PT3x9OlTuLu7o0uXLnj+/DkOHDiAAwcOYOvWrRgwYECm5+vj44OAgAA0btwYgwYNQokSJfD48WOcPn0aL1680GjU0p49e+KLL77AihUr4OzsjCFDhmS7j8KxY8fQtWtXJCcno0OHDnByckJkZCT27NmDPXv2ICAgAB4eHhofTzEATsmSJdG5c2eUL18eV69exXfffYc//vgDx48fR6VKlZTuN2vWLABSi6SXlxdMTEwQHR2NS5cuQQgBZ2dnTJ8+HQCwfft2PHz4MOOxoaEhSpcunXG83Fx/AHDkyBF06dIFycnJcHZ2RteuXZGWlobg4GC4u7vj559/1rguiEiHBBERZeHu7i4AiGfPngkhhHj06JGwsLAQDRs2FGlpaVnKf/TRR0LZv9S5c+cKACIkJETluVSVCQkJEQCETCYTAwYMEG/evMnYlpKSIry9vYVcLhfjx48XFSpUEP/++2+m/RcsWCAAiOXLlyt9fnK5XBgaGoqlS5dm2paeni6+/PJLAUDY2dmJhISETNsvXrwojIyMhIODg7h161aWmE1NTcVHH30k3r59m+Wc1tbWom7dumLnzp0q60OVb7/9VgAQjRo1Enfv3s20LTExUXz66acCgOjatavS/Tdt2pTta6GK4jXavXu3xvtMmTJFABCffvqpSElJyViflpYmxo4dKwCIRYsWZdonPT1dbNu2TSQnJ2c53n///ScsLCxEtWrV1Mao6vlp41r08PAQTZs2FXFxcVn2jY+PF1WrVhVmZmbi4MGDmbZFRkYKR0dHYWpqKiIiIjLW79u3TwAQU6ZMURmTpo4cOSLMzc2FTCYTo0aNEq9evcp2n4cPH4pSpUoJKysrce7cuUzbrl+/LqysrISNjY2IjY3NtG3IkCECgDh//nym9f7+/gKAaNKkiXj8+HGmbb///ruQyWTCy8srSxwrVqwQAISLi4u4ceOGRs9X8T9Kldxcf3FxcaJChQpK/2+8efNGjBo1ShgbGwsAYsiQIRrFSUS6wSSPiEiJD5M8IYSYN2+eACA2bNiQpXx+JnnlypXL8iFTCCHOnDkjAAgA4rfffsuyPTk5WZQsWVK4u7urfH49e/ZUGVfbtm0FALF169ZM6zt16iQAiPDwcKX7TZgwQQAQ+/fvV3rOLl26qDynKjExMcLU1FSUKVNGPH36VGU5FxcXAUAcOXIkyzZtJHndu3cX06dPV7oEBwdnlI+KihJGRkaiZs2aWZJdIaTXxsbGRtjY2CjdrsrgwYMFAHHnzh2VMeZnkgdA/P3330r3XbJkiQAg5s+fr3T73r17BQAxadKkjHWLFi0SAMTly5dVxpQTly5dEnXr1hUAhLW1tVi1apVITU1VWX7MmDFKr3GFZcuWCQBixYoVmdarSvLq1KkjjI2Nlb4+QgjRtWtXAUBcuXIlY110dLQwNTUV9vb2Sv/OVVGX5OX2+tu4caMAIHr16qX0uGlpaaJhw4ZM8oiKAN6TR0SkoalTp8LOzg6zZ88u0OHY27dvr3T6htq1awMAypcvj759+2bZLpfL4eDggMjISJXH/uyzz1RuGz9+PADg6NGjGetiY2MRFBQEV1dXuLq6Kt1v6NChAIC//vpL6fZ+/fqpPKcqu3btQnJyMkaOHAlra2uV5b788ksAwKZNm3J8Dk3s27cPS5YsUbq8X0979uxBamoqpk+fnqU7HCC9Nv369cPTp0/x999/a3x+e3t7AEB0dHTen0wu1KhRA40aNVK6befOnTA3N8ekSZOUbu/WrRtKly6d6bqoWbMmAGTcX5ZXDRo0yOiqnJycjLFjx6JJkyZK79UTQsDPzw/29vaZupC+L7tr+X1Xr17Fv//+i379+sHBwUHj4/36669ITk7GrFmztDZNS26vP8U1rIjzQwYGBmr/ZxBR4cEkj4hIQ+bm5li4cCEeP36MhQsXFth5VX1gLFmyJACgTp06Sj/IAUCpUqVUDmpiZGSEFi1aqDxv48aNAQD/+9//MtZdvHgR6enpKhO89+N9f7/3NWvWTOW+qigG7chujrvOnTtDLpfj1KlTOT6HJnbv3g0h9YLJsixevDij3IULFwAg1/UUHh6OCRMmwNXVFfb29rC0tISxsXHGVB5v377V5tPSmKrX7s2bN7h69SoaNGigcqoCAwMDVK1aFTdv3swY9KNbt27w8vLCxIkTMWzYMNy9ezfPMRoZGWHq1Km4ffs2Ro4cicuXL6NVq1ZZBtmJiIjAixcv0KpVK5UjrpYpUwalS5dWeS2/L7evuWIwnbzM36itWG7evAkAaNq0qcr9lN2jS0SFD5M8IqIcGDhwIFxcXLB8+XLcv3+/QM5pbGysdrutrW2ujmttba1yQBYAqFSpEgwMDPDy5cuMdU+fPgUALFy4MGNUvw8XxeAPinnpPmRjY5PjWBWjLCpG51TFxMQEtra2OmvpUlDUU82aNVXW08SJEwFkrqeUlBT06tUL7u7uWLlyJSIiIuDs7IyBAwfi888/R6tWrXTwbN5R9dq9ePECaWlpOHXqlMrnK5PJcPnyZaSnpyM+Ph6ANFjIoUOH8NNPP+Gvv/5CzZo1MWDAAI2SKk1iXbt2LYKCgmBsbIwhQ4ZkarVSvEbbt29XG3NsbKzKa/l9iuONHDlS5bEaNGgAIPNrHhUVBSMjo1z/HauLJafXX2xsLAwNDVGuXDmVx9ZmnESUfzi6JhFRDshkMixbtgxubm6YPn26Vobgz8n0AcooRuHMqbS0NLXbhRAAoHTkS3d3dzRv3lzt/qoSstxMRq6IQZNROIHCMxfe+PHjYWFhobbM+4nbpEmTsHfvXri4uGDFihVo2bJlprJz5szByZMn8yVWIPtrMbvXrlq1avDx8VFbxtDQMFOdGBoaYvz48Rg+fDhWrVqFJUuWYOfOnfjiiy+waNEizYNXwdPTE7t374aXlxcmT56cpWtogwYN4OXlpfYY749amZ2uXbtmdKVW5cMur4rWYE2vb03l9PrT5O9G3dQLRFR4MMkjIsohV1dX9OzZE35+fpgwYUKWD+LvU3xoU/fBSNO5wLTt2bNnePXqlcr7gKKjo5Genp6p9aZs2bIAgBYtWmjlA7imFK0HERERsLOzU1nuzZs3iIqKyphCQFcU9TR+/Hg4OTlptE98fDw2bdoEGxsbHDt2TGlC9ezZs1zHlJ/XYpkyZSCTyVC+fPlM3VZzwszMDFOmTIGvry+6deuGxYsXo3bt2hg8eHCujve+Dh06oEqVKjh//nzGOsVrVKtWrVzH/D7F8by9vTFq1CiN96tcuTL+++8/3LlzB9WrV89zHO/HkpPrDwDKlSuHGzduICYmRmWr7Z07d7QSIxHlr8LxVScRURGzdOlSmJiYYOLEiRktXsqYm5sDAGJiYlSWOX78uNbj04QQAocOHVK5XdG1rX79+hnrFPOuqZrYOr+0bt0aABAQEKC2XEBAAFJSUuDm5lYQYamUm3q6c+dOxlxtqlrM1N1rmF0rUH5ei3K5HDVr1sTVq1fVzsOniUqVKuGPP/4AAGzYsCFPx3pfYmJiRh0AgKOjI8zNzbV2Lef2b0Nxj9uePXtytJ+61zu3sSi6k167dk1lmcDAwBwdk4h0g0keEVEuODo64rPPPsP58+fx+++/qyynGNzgxIkTSrcfOXIkY7ADXVi8eLHKLnq//PILAKB79+4Z6ypUqAAXFxeEhobi4sWLBREiAKBXr14oWbIk1q5dm3G/0YeEEPjmm28AAMOHDy+w2JT5+OOPAQA//fSTxt1xFYPnJCYmKt0eEhKi9sO34v7KlJQUpdvz+1rs0qULEhMTsXr16lwfQ6FMmTIwMDBQm5DmRGhoKGJiYtCmTZuMdYaGhvD29kZERAT+/PPPPJ/DxcUFFStWxK5du9SOaPuhoUOHwsTEBEuXLs3Rfupe79xcf8C7v/X169cr3f769WusWLFC4+MRke4wySMiyqXZs2ejXLlymDlzJpKSkpSWadeuHczMzLBx40b8999/mbbdunULw4YNy9Vok9pQunRpPHz4EEOGDMn0QVEIgTlz5uDo0aNwdXVFu3btMu03e/ZsCCHQo0cPpcP/p6Wlab2lz9LSEvPmzcPLly/RqVMn3Lt3L9P2hIQEDB06FH///Td8fHzUjhpaEOrWrYvu3bvj77//xuDBgxEXF5elzNOnT3H79u2MxzVr1oSNjQ2Cg4Pxzz//ZCp75coVDBw4EPXq1VN5zooVKwJQ3dqX39fihAkTULJkScycOVPlFx9nz57NdC/o8+fPs9wbmp6ejq+//hrp6ekZI7xm5/nz5zhw4IDSVvXjx49j0KBBMDY2xpw5czJtmzFjBoyMjDB8+HAcPnxY6bE1HanVyMgI06dPR0JCAj7++GOl3RpTUlKy/M1UqlQJc+bMwcuXL9G2bVtcvXpVo/Ope71zc/0B0jXSokUL+Pn5Yfny5Zm2JSQkwMfHByYmJhrFR0S6xXvyiIhyqXTp0pg7d67aeaNKly6NhQsXYtKkSWjWrBkGDBiAypUr49atW9i1axdcXFwwYsSIAu/+CEjTKyxbtgz9+vXDyZMn4e3tDSEEQkJCcOPGDdSoUQN+fn5Z9uvWrRu+/vprfP3112jSpAnc3Nzg7OyMtLQ0PHr0CGfOnEGFChWUzk2WFxMnTsSTJ0+wZMkS1K5dGx06dICjoyNiYmLw119/ISYmBp06dcq3OfJyasOGDYiMjMSOHTsQGBgIT09P2NnZ4eXLl7h37x5OnjyJpUuX4vPPPwcgjQz67bffYsSIEWjcuDG6du0KW1tb3Lp1C0FBQWjcuDEmTpwIX19fpYPmuLq6wsjICN9++y1u376NsmXL4sqVKwgPDweQ/9di5cqVsXPnTvTp0wcDBw7EwoUL0bp1a5ibmyM6OhrXrl3Dv//+i9jY2Iz7QCdOnIiAgAC4ubmhcuXKSElJQVhYGG7cuIFKlSpltMxm58qVK+jWrRsqVaqE1q1bw9bWFgkJCbh+/TpOnToFS0tL7Nq1K1PXY0CaJmTNmjUYPXo0OnTogCZNmqBJkyYwMjLCo0ePcOHCBcTGxmYaYVadCRMm4OrVq9i4cSNq166Ndu3aoVatWkhKSkJUVBROnjwJd3f3LC2Hs2bNwvPnz/Hjjz+iUaNGcHd3R926dWFiYoInT57g4sWLOH36dKZuvB4eHti8eTN69+6Nvn37IiUlBXK5HKtWrQKQ8+sPkLqA7tixA66urpg8eTK2bNmC1q1b482bN/D398fr168RFBSk81FeiUgDBT79OhFREeDl5SUMDQ1FbGys2nJv374V9erVEwCEmZmZynK7du0SrVq1EiVKlBBmZmaidu3aYt68eSIpKUns379fABCnT5/OtM/p06cFALF48WKVx5XL5WLUqFFqn4eTk5PS9bVq1co4T9euXYW1tbUwNTUVTk5OYvbs2SI+Pl7tcz958qTw9fUVVapUEXK5XJQoUUI4ODiI/v37i4CAgCzlO3bsKExNTdUeUxOnTp0S/fv3F3Z2dsLExESUK1dOdOjQQezYsUPtfjt27FBaz5pYtGiRACD8/f1ztF9KSopYtWqVcHd3F2XLlhVGRkaiXLlyomHDhuKLL74Q9+/fz7LP/v37RZs2bUSpUqWEmZmZqFevnliyZIlISkoSR48eFQBEUFCQyufo5OQkjI2NRYUKFcTgwYOzlMmva1Hh3r17YsKECaJ27drCwsJCmJqaCltbW9GxY0fxyy+/iPT09IyymzdvFi4uLqJEiRICgLC0tBT169cX8+fPFzExMdmeSyEmJkbMmzdPeHh4iIoVKwq5XC7Mzc1F/fr1xcyZM0VUVJTa/a9duyaGDx8uHB0dhZmZmTAzMxNVqlQRPXr0ENu3b89SfvTo0UImk4lr164pPd7BgwdF9+7dRcWKFYWxsbEoWbKkqFmzphg+fLg4efKkyjjCwsJE3759ha2trTA2NhaGhobCyspKNG/ePMv/ovT0dDFz5kxRsWJFYWJiIhwdHcXy5cszlcnN9SeEEM+fPxeTJ08WDg4OwsTERFSoUEH4+vqKf/75RwghhJmZmdr/O0SkezIh1IwYQEREREREREUK78kjIiIiIiLSI0zyiIiIiIiI9AiTPCIiIiIiIj3CJI+IiIiIiEiPMMkjIiIiIiLSI0zyiIiIiIiI9AiTPCIiIiIiIj3CJI+IiIiIiEiPMMkjIiIiIiLSI0zyiIiIiIiI9AiTPCIiIiIiIj3CJI+IiIiIiEiP/B9545fvFTEKHgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfecv.support_.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA2JSoLDm-9r",
        "outputId": "d0853137-590b-484b-dea7-98adeb39e862"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = np.where(rfecv.support_)[0]\n",
        "selected_features_names = X.columns[selected_features_indices]\n",
        "\n",
        "# Print the names of the selected features\n",
        "print(\"Names of Selected Features:\", selected_features_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ZwxXzFnKIX",
        "outputId": "e36fb8d4-6cb2-4929-e258-b00ac6db9d9e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Names of Selected Features: Index(['browser', 'device', 'new', 'quality', 'duration', 'bounced',\n",
            "       'transaction', 'continent', 'subcontinent', 'country', 'traffic_source',\n",
            "       'keyword'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_rmse = rmse_scorer(y_test, xgb_predictions)"
      ],
      "metadata": {
        "id": "GagH6yDhpmmx"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", xgb_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4twHrIipvsX",
        "outputId": "2e55b981-2a8a-4b98-8f47-2b95a8f397aa"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgb_scores: 2.93554211897225\n",
            "RMSE: 2.7571927400281675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", xgb_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj4HTuyKqh4L",
        "outputId": "a34f4a18-7acd-4b60-ace6-f6d0741a1b18"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgb_scores: 2.8491038194831644\n",
            "RMSE: 2.745348382572756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already defined X, y, and split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = train.drop(['TARGET'], axis=1)\n",
        "y = train['TARGET']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 43)\n",
        "# Define the XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "\n",
        "# Create the RFECV model\n",
        "rfecv = RFECV(estimator=xgb_model, step=1, scoring='neg_mean_squared_error', cv=kf)\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross-validation RMSE\")\n",
        "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), np.sqrt(-rfecv.cv_results_['mean_test_score']), marker='o', linestyle='-')\n",
        "plt.show()\n",
        "\n",
        "# Print the optimal number of features\n",
        "optimal_num_features = rfecv.n_features_\n",
        "print(f\"Optimal number of features: {optimal_num_features}\")\n",
        "\n",
        "# Use the selected features for training and testing\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_test_selected = rfecv.transform(X_test)\n",
        "\n",
        "# Train the XGBoost model on the selected features\n",
        "xgb_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = xgb_model.predict(X_test_selected)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"Test RMSE on selected features: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "OIfXM390IaK9",
        "outputId": "969efca3-3fcb-4994-e5fe-9b2091b6b147"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of features: 16\n",
            "Test RMSE on selected features: 2.745348382572756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfecv.support_.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y337CmmtJCod",
        "outputId": "86fbf2fa-3308-4238-d7a2-c7424e947114"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = np.where(rfecv.support_)[0]\n",
        "selected_features_names = X.columns[selected_features_indices]\n",
        "selected_features_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0nIn0f8MLVP",
        "outputId": "fd2c8272-f46f-477d-c80b-850ad539affd"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['browser', 'OS', 'device', 'new', 'quality', 'duration', 'bounced',\n",
              "       'transaction', 'transaction_revenue', 'continent', 'subcontinent',\n",
              "       'country', 'traffic_source', 'keyword'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.fit(X_train.drop(['device', 'transaction', 'traffic_medium'],axis=1), y_train)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train.drop(['device', 'transaction', 'traffic_medium'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_predictions = xgb_model.predict(X_test.drop(['device', 'transaction', 'traffic_medium'],axis=1))\n",
        "xgb_rmse = rmse_scorer(y_test, xgb_predictions)"
      ],
      "metadata": {
        "id": "JFJU9YjwMYcc"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", xgb_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1n64ealMaK2",
        "outputId": "308b1593-3543-46b3-dc7b-0023eabaae06"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgb_scores: 2.8848577963868527\n",
            "RMSE: 2.7634728673342157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", xgb_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEFg2L6XMm4i",
        "outputId": "6943fc53-0ade-4187-efd0-21e990700ed9"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgb_scores: 2.8491038194831644\n",
            "RMSE: 2.745348382572756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'device', 'subcontinent', 'keyword'\n",
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", xgb_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Nua5shN3bn",
        "outputId": "b5637bc8-db5b-45ff-8673-cdfc012b1086"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgb_scores: 2.8544205391339\n",
            "RMSE: 2.7550007033393524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'device', 'transaction', 'traffic_medium'\n",
        "print(\"xgb_scores:\", xgb_scores.mean())\n",
        "print(\"RMSE:\", xgb_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByxcPAD0OFXv",
        "outputId": "e28c687d-4b93-4e48-bf04-f2bfd0094685"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgb_scores: 2.8842926588142146\n",
            "RMSE: 2.7609070243830485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#grid\n",
        "X = train.drop(['TARGET'], axis=1)\n",
        "y = train['TARGET']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 43)\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_rmse = rmse_scorer(y_test, xgb_predictions)\n",
        "xgb_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5njtPZLu_N7",
        "outputId": "3269a4da-7ec6-41cd-f9dc-4e835adebea0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.745348382572756"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(\n",
        "    random_state=43,\n",
        "    reg_lambda=4,\n",
        "    learning_rate=0.2,\n",
        "    max_depth=4,\n",
        "    n_estimators=100\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_rmse = rmse_scorer(y_test, xgb_predictions)\n",
        "xgb_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrzMKRlizolG",
        "outputId": "7a0b13fd-3986-44b6-902c-4a83479e19de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.76883137114815"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have already defined X_train, y_train, and X_test\n",
        "\n",
        "# Define the parameter grid with fixed reg_lambda and additional parameters\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'reg_lambda' : [3, 4, 5, 6]\n",
        "}\n",
        "\n",
        "# Define the XGBoost model with fixed reg_lambda and GPU acceleration\n",
        "xgb_model = xgb.XGBRegressor(random_state=43, tree_method='gpu_hist', gpu_id=0)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=kf, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding RMSE\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Get the best model from the grid search\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Use the best model to make predictions on the test set\n",
        "best_xgb_predictions = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate the RMSE on the test set\n",
        "best_xgb_rmse = np.sqrt(mean_squared_error(y_test, best_xgb_predictions))\n",
        "print(f\"Test RMSE with best parameters: {best_xgb_rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crtFD2v1vc8k",
        "outputId": "dfa7f1d3-16f5-41a1-ec1a-f043b80c639f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200, 'reg_lambda': 3}\n",
            "Test RMSE with best parameters: 2.7675013711780148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#lgb"
      ],
      "metadata": {
        "id": "P6qF62t4ejnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = LGBMRegressor(random_state=43, reg_lambda=4)\n",
        "# Create the RFECV model with LGBMRegressor\n",
        "rfecv = RFECV(estimator=lgb_model, step=1, scoring='neg_mean_squared_error', cv=kf)\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross-validation RMSE\")\n",
        "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), np.sqrt(-rfecv.cv_results_['mean_test_score']), marker='o', linestyle='-')\n",
        "plt.show()\n",
        "\n",
        "# Print the optimal number of features\n",
        "optimal_num_features = rfecv.n_features_\n",
        "print(f\"Optimal number of features: {optimal_num_features}\")\n",
        "\n",
        "# Use the selected features for training and testing\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_test_selected = rfecv.transform(X_test)\n",
        "\n",
        "# Train the LGBM model on the selected features\n",
        "lgb_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = lgb_model.predict(X_test_selected)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c_hTR6rhelCj",
        "outputId": "e2b63c1d-0104-485a-f524-c56bbcbccc66"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015077 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014984 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1325\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1321\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013369 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032985 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030753 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1278\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059135 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1172\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015814 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1170\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014640 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 916\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013287 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 893\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011689 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 638\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010371 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 623\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009014 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 527\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006392 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003240 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016760 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014968 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1329\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023508 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1322\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020170 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1317\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011827 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1308\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010663 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1203\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010284 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1171\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015528 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1169\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014631 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 917\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012554 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 894\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011514 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 878\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009048 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 782\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011991 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 527\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008659 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004527 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021305 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1330\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1328\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016073 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1321\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014068 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028723 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1313\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010946 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1307\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010666 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1203\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018028 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1170\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014516 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1168\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022330 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1145\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012600 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 891\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011706 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 636\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010005 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 620\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008251 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 527\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 354\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014964 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015123 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030784 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014010 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1321\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034388 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1318\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034587 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010594 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1207\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011245 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1173\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016047 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1171\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014353 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1148\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012727 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 894\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010737 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 878\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008857 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 783\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008418 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 528\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003244 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021573 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1332\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014328 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1327\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014407 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1321\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013371 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010995 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010507 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1278\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018132 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1174\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015588 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1172\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015389 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1149\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018557 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 896\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016071 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 880\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010272 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 783\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008219 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 528\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 354\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003265 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 99\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019599 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1350\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1348\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018837 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1348\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593011\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of features: 15\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1348\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfecv_scores = cross_val_score(rfecv, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdEtly4anp4n",
        "outputId": "fa7f3c7e-ff49-4be8-d6ee-46f33547b214"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035416 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016487 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1311\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011496 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1309\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011264 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010823 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1196\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008974 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1193\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008571 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1187\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014728 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1159\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012622 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011397 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 904\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015502 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 882\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013110 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 793\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012420 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 778\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011846 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 523\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005153 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002572 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592573\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011825 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1317\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011938 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1311\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011163 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1305\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009457 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1302\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008922 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1296\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1266\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015356 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1161\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009942 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1159\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016967 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1136\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013227 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 883\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008801 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 868\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008030 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 613\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006484 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 523\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004992 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002848 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1319\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012697 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1317\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022157 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1311\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011265 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1307\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010763 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1274\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010891 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1268\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1265\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018482 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011646 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 903\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009944 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 880\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009216 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 625\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007966 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 610\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 522\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005373 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003050 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592303\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012151 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1322\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1320\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011741 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011203 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009296 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1307\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012353 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022354 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1269\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023610 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1163\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013178 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1161\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011345 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 907\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009968 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 884\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009411 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 629\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007935 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 538\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 523\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002598 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.593966\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012218 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011531 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012059 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1304\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014878 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1298\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014805 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1266\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009998 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1263\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015314 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013295 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1156\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011689 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1133\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010183 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 880\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 625\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 610\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006476 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 523\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.595497\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014901 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014917 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014728 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1325\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019684 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1321\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018215 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011173 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021677 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1278\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1172\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017756 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1172\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011941 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1309\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011489 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1305\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011491 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011194 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1296\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014266 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1293\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025214 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1287\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009854 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1258\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014827 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012925 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1153\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011454 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 903\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010184 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 881\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008707 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 866\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007021 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 777\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 522\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005062 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003639 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113024, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.594511\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012135 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1313\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012210 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1311\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011814 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1305\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015629 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1300\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028360 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1297\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008774 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1291\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008691 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1187\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013359 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011413 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 903\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010199 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 881\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008683 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 865\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007052 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006125 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005368 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002590 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.595293\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011956 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016688 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1308\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011149 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1301\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009363 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1298\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008875 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1292\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015931 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1186\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015322 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012993 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1153\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012748 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1130\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010015 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 880\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008756 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 864\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007221 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 775\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005750 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007088 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004968 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592692\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017647 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013692 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011439 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1305\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011308 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1299\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009283 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1296\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008970 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1290\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008464 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1190\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015365 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1159\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013157 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011618 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1135\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014957 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 882\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012446 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 866\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010400 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 778\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005120 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003648 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592418\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1318\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011658 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011686 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011380 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1306\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010760 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1300\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008799 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1297\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1195\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015788 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1164\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019113 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1162\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016348 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 910\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010626 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 887\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008719 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 871\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 780\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003700 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014895 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1329\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014816 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1322\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014113 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1317\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011745 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030975 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1308\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014780 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1308\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011975 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013377 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1313\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011489 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1309\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011350 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1302\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1296\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008705 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1293\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008495 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1187\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015391 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1156\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013196 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1154\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017278 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1131\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014861 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 877\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012619 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007031 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 521\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005056 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003615 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011860 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011997 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1313\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012662 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1307\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009926 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1304\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009249 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1298\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008786 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1293\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009834 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1186\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022547 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022448 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016856 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 904\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010053 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 882\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008656 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 866\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007019 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 775\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 520\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005009 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003692 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.595435\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011892 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1320\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011422 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011528 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011216 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1307\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009352 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1304\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008830 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1298\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024534 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1192\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1160\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012745 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012132 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1135\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010623 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 882\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009937 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 627\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007980 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 539\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006436 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 523\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005027 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592333\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011866 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1319\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024886 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1317\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1311\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011283 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1205\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015056 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1200\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013231 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1197\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008619 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1167\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015364 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1161\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012778 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1159\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012036 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1136\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010204 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 882\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009770 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 627\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007934 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 611\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006631 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 524\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005021 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 354\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.591236\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011928 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011724 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1304\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021180 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1300\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1297\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008804 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1291\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008396 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1188\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014799 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012587 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012507 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1132\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010324 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 878\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 623\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008090 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 607\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006588 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 520\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005018 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002700 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.593200\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014923 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1330\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055079 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1328\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1321\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014768 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1321\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012066 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1315\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1313\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011633 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1309\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011979 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1297\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010603 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1294\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008403 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1188\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015389 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020308 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017041 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1132\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008930 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 879\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010905 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 624\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007954 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 536\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 521\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005147 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.593010\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012739 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1320\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012590 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1318\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011645 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011176 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1308\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010648 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1302\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010428 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1195\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008446 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1192\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023892 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1162\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1160\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016985 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 906\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010558 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 883\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008681 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 867\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007061 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 775\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008262 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 520\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005120 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002650 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.594019\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012234 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1311\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012124 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1309\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1305\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011324 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1299\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1296\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008772 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1290\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022997 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1187\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021511 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1156\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012711 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1154\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012081 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1132\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015207 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 879\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008696 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 863\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007045 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006365 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 521\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004977 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.594580\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012706 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1322\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024046 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1320\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011856 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016120 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1304\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012231 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1301\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008351 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1269\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015407 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1163\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013194 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1161\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012421 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1138\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010254 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 883\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008611 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 867\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007130 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 778\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002569 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.588599\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014814 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016958 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031247 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1304\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010738 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1298\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008772 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1295\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008572 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1193\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1161\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012607 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1159\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012144 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1136\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010210 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 883\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008825 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 867\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008202 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 779\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005890 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005116 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003725 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592979\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024406 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011901 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011453 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1308\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011509 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1306\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011355 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1300\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010728 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1294\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008894 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1291\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009605 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1259\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015491 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013601 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017603 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 903\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014563 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 880\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012970 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 865\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007170 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 778\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006860 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 523\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005048 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 354\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 99\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011958 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011953 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013010 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1309\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011228 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010938 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008793 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1272\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008450 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1266\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022772 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1160\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018741 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017512 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 906\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010111 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 737\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008734 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 721\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007617 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 699\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005830 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002574 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 98\n",
            "[LightGBM] [Info] Number of data points in the train set: 113025, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.592223\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012226 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1308\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011580 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011874 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1297\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1294\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012317 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1288\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024240 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1258\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015499 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1155\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012829 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1153\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012645 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 985\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010349 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 733\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 717\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007248 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 632\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 609\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005096 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 354\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002556 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 99\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.595049\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011871 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011405 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1312\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011626 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1310\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034007 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1304\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015561 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1271\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010338 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1265\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008312 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1262\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015153 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1158\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012833 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1156\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1133\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010228 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 881\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008738 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 866\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 609\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005231 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 354\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.589714\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011929 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1316\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017205 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1314\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017401 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1309\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011393 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009307 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1300\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008707 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1294\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015830 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1194\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1161\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012732 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1159\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012094 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 906\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010290 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 734\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008922 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 718\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007850 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 695\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 608\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006748 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 353\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004999 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 113026, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 3.593129\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014733 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfecv_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoXdh08mpkPH",
        "outputId": "a0c59716-fdee-4fe8-a1f9-7c3e474fd420"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.5821706 , 2.66230612, 3.02552239, 2.66967386, 2.8455466 ])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "selected_features_indices = np.where(rfecv.support_)[0]\n",
        "selected_features_names = X.columns[selected_features_indices]\n",
        "rfecv.support_.sum(),selected_features_names,rmse #drop bounced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14TvecQakNYs",
        "outputId": "4c73b137-2f9f-43ef-97a5-b21f025d0a4b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15,\n",
              " Index(['browser', 'OS', 'device', 'new', 'quality', 'duration', 'transaction',\n",
              "        'transaction_revenue', 'continent', 'subcontinent', 'country',\n",
              "        'traffic_source', 'traffic_medium', 'keyword', 'referral_path'],\n",
              "       dtype='object'),\n",
              " 2.7790394541420764)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzQJ8B_QkREO",
        "outputId": "b41caafd-7b7d-42d1-b4ff-8b76e0601a22"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TARGET', 'browser', 'OS', 'device', 'new', 'quality', 'duration',\n",
              "       'bounced', 'transaction', 'transaction_revenue', 'continent',\n",
              "       'subcontinent', 'country', 'traffic_source', 'traffic_medium',\n",
              "       'keyword', 'referral_path'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have already defined X_train, y_train, and X_test\n",
        "\n",
        "# Define the parameter grid for LightGBM\n",
        "param_grid_lgb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# Define the LGBM model\n",
        "lgb_model = LGBMRegressor(random_state=43)\n",
        "\n",
        "# Create the GridSearchCV object for LGBM\n",
        "grid_search_lgb = GridSearchCV(estimator=lgb_model, param_grid=param_grid_lgb, scoring='neg_mean_squared_error', cv=kf, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV object to the data for LGBM\n",
        "grid_search_lgb.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding RMSE for LGBM\n",
        "best_params_lgb = grid_search_lgb.best_params_\n",
        "print(f\"Best parameters for LGBM: {best_params_lgb}\")\n",
        "\n",
        "# Get the best model from the grid search for LGBM\n",
        "best_lgb_model = grid_search_lgb.best_estimator_\n",
        "\n",
        "# Use the best model to make predictions on the test set for LGBM\n",
        "best_lgb_predictions = best_lgb_model.predict(X_test)\n",
        "\n",
        "# Calculate the RMSE on the test set for LGBM\n",
        "best_lgb_rmse = np.sqrt(mean_squared_error(y_test, best_lgb_predictions))\n",
        "print(f\"Test RMSE with best parameters for LGBM: {best_lgb_rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT70fajN1txZ",
        "outputId": "7ea49b55-05d0-4849-ab3a-ef75c3d660bf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007380 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1350\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Best parameters for LGBM: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Test RMSE with best parameters for LGBM: 2.7783908382830558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = LGBMRegressor(random_state=43, reg_lambda=4)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "lgb_predictions = lgb_model.predict(X_test)\n",
        "lgb_scores = cross_val_score(lgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "lgb_rmse = rmse_scorer(y_test, lgb_predictions)\n",
        "lgb_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-VJV3jsH5TN",
        "outputId": "a5296107-32d1-4e09-d06a-2fcb320c701a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007541 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1350\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006010 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1330\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005893 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.7743799222694636"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = LGBMRegressor(random_state=43, reg_lambda=4)\n",
        "lgb_model.fit(X_train.drop(['bounced'],axis=1), y_train)\n",
        "lgb_predictions = lgb_model.predict(X_test.drop(['bounced'],axis=1))\n",
        "lgb_scores = cross_val_score(lgb_model, X_train.drop(['bounced'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "lgb_rmse = rmse_scorer(y_test, lgb_predictions)\n",
        "lgb_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZqfSrXGIOSI",
        "outputId": "85aaaed7-cd26-4435-dbbe-3c029221c218"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006883 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1348\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007509 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1329\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006924 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1328\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007538 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008717 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1332\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.7790394541420764"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting"
      ],
      "metadata": {
        "id": "ougl_MBtOUhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train.drop(['TARGET'], axis=1)\n",
        "y = train['TARGET']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 43)"
      ],
      "metadata": {
        "id": "FtK16XRAOWtg"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(random_state=43)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "rf_rmse = rmse_scorer(y_test, rf_predictions)\n",
        "\n",
        "\n",
        "# Extra Trees\n",
        "et_model = ExtraTreesRegressor(random_state=43)\n",
        "et_model.fit(X_train, y_train)\n",
        "et_predictions = et_model.predict(X_test)\n",
        "et_scores = cross_val_score(et_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "et_rmse = rmse_scorer(y_test, et_predictions)\n",
        "\n",
        "#xgb\n",
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_rmse = rmse_scorer(y_test, xgb_predictions)\n",
        "\n",
        "#cat\n",
        "cat_model = CatBoostRegressor(random_seed=43, l2_leaf_reg=4, verbose=0)\n",
        "cat_model.fit(X_train, y_train)\n",
        "cat_predictions = cat_model.predict(X_test)\n",
        "cat_scores = cross_val_score(cat_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "cat_rmse = rmse_scorer(y_test, cat_predictions)\n",
        "\n",
        "#lgb\n",
        "lgb_model = LGBMRegressor(random_state=43, reg_lambda=4)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "lgb_predictions = lgb_model.predict(X_test)\n",
        "lgb_scores = cross_val_score(lgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "lgb_rmse = rmse_scorer(y_test, lgb_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yhZq3wKOWrQ",
        "outputId": "570daf4c-52dd-450a-bdcf-a5af22fec30c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1350\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014876 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021223 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1330\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022640 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014825 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "voting_regressor = VotingRegressor([('xgb', xgb_model), ('catboost', cat_model),('lgb',lgb_model),('et',et_model),('rf',rf_model)])\n",
        "voting_regressor.fit(X_train, y_train)\n",
        "\n",
        "voting_predictions = voting_regressor.predict(X_test)\n",
        "\n",
        "voting_rmse = rmse_scorer(y_test, voting_predictions)\n",
        "voting_scores = cross_val_score(voting_regressor, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RizTLv1ROWoo",
        "outputId": "df7df2d8-3989-4758-ccf2-68601efff06b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018657 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1350\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014843 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1331\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017979 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1330\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014861 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015026 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1334\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfecv = RFECV(estimator=voting_regressor, step=1, scoring='neg_mean_squared_error', cv=kf)\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross-validation RMSE\")\n",
        "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), np.sqrt(-rfecv.cv_results_['mean_test_score']), marker='o', linestyle='-')\n",
        "plt.show()\n",
        "\n",
        "# Print the optimal number of features\n",
        "optimal_num_features = rfecv.n_features_\n",
        "print(f\"Optimal number of features: {optimal_num_features}\")\n",
        "\n",
        "# Use the selected features for training and testing\n",
        "X_train_selected = rfecv.transform(X_train)\n",
        "X_test_selected = rfecv.transform(X_test)\n",
        "\n",
        "# Train the XGBoost model on the selected features\n",
        "xgb_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = xgb_model.predict(X_test_selected)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"Test RMSE on selected features: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "ZVDoJEO-OlqU",
        "outputId": "8407ff4c-9f7d-4717-eba3-c73e28aac421"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014816 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1333\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593406\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "when `importance_getter=='auto'`, the underlying estimator VotingRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-8bade3a53b39>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfecv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoting_regressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of features selected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rfe_single_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         scores = parallel(\n\u001b[0m\u001b[1;32m    726\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         scores = parallel(\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     return rfe._fit(\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# Get importance and rank them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             importances = _get_feature_importances(\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportance_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36m_get_feature_importances\u001b[0;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_importances_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    209\u001b[0m                     \u001b[0;34m\"when `importance_getter=='auto'`, the underlying \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0;34mf\"estimator {estimator.__class__.__name__} should have \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator VotingRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_indices = np.where(rfecv.support_)[0]\n",
        "selected_features_names = X.columns[selected_features_indices]\n",
        "rfecv.support_.sum(),selected_features_names"
      ],
      "metadata": {
        "id": "GjjNMgnIOyKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Assuming you have already defined X, y, and split the data into train and test sets\n",
        "\n",
        "# Create the VotingRegressor with base models\n",
        "voting_regressor = VotingRegressor([('xgb', xgb_model), ('catboost', cat_model), ('lgb', lgb_model), ('et', et_model), ('rf', rf_model)])\n",
        "\n",
        "# Create a Pipeline with SelectFromModel and VotingRegressor\n",
        "pipeline = Pipeline([\n",
        "    ('feature_selection', SelectFromModel(estimator=voting_regressor)),\n",
        "    ('voting_regressor', voting_regressor)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross-validation RMSE\")\n",
        "plt.plot(range(1, len(pipeline.named_steps['voting_regressor'].estimators_) + 1),\n",
        "         np.sqrt(-cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')), marker='o', linestyle='-')\n",
        "plt.show()\n",
        "\n",
        "# Print the optimal number of features\n",
        "optimal_num_features = np.sum(pipeline.named_steps['feature_selection'].get_support())\n",
        "print(f\"Optimal number of features: {optimal_num_features}\")\n",
        "\n",
        "# Use the selected features for training and testing\n",
        "X_train_selected = pipeline.named_steps['feature_selection'].transform(X_train)\n",
        "X_test_selected = pipeline.named_steps['feature_selection'].transform(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "voting_predictions = pipeline.predict(X_test_selected)\n",
        "voting_rmse = np.sqrt(mean_squared_error(y_test, voting_predictions))\n",
        "print(f\"Test RMSE on selected features: {voting_rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "a5QefGFVT20E",
        "outputId": "d0c4b062-4a82-477a-e7c4-645d1748852c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019412 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1350\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 3.593011\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "when `importance_getter=='auto'`, the underlying estimator VotingRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-6b524f4e7885>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Fit the pipeline on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Visualize the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \"\"\"\n\u001b[1;32m    400\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         )\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;34m\"\"\"Reduce X to the selected features.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mget_support\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mindices\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_from_model.py\u001b[0m in \u001b[0;36m_get_support_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m             )\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         scores = _get_feature_importances(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportance_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36m_get_feature_importances\u001b[0;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_importances_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    209\u001b[0m                     \u001b[0;34m\"when `importance_getter=='auto'`, the underlying \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0;34mf\"estimator {estimator.__class__.__name__} should have \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator VotingRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
          ]
        }
      ]
    }
  ]
}