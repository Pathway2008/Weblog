{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1MkM-NmTyIB0NGTDUUahSCoh4ZgUNRwbU",
      "authorship_tag": "ABX9TyPlLoaX03sY/1Jj9mBHE9Mv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pathway2008/Weblog/blob/main/comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JprT-jd7bGyn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/Weblog/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Weblog/test.csv')\n",
        "sub = pd.read_csv('/content/drive/MyDrive/Weblog/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['sessionID','userID'],axis=1,inplace=True)\n",
        "test.drop(['sessionID','userID'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "oaHV1QqSbPb3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "warnings.filterwarnings('ignore')\n",
        "!apt-get -qq install fonts-nanum\n",
        "\n",
        "\n",
        "fe = fm.FontEntry(\n",
        "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
        "    name='NanumGothic')\n",
        "fm.fontManager.ttflist.insert(0, fe)\n",
        "plt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOIhzmeebPZt",
        "outputId": "82e14228-6c3e-4b05-9329-4e9c51d3b7f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "object_columns = train.drop(columns=['TARGET']).select_dtypes(include='object')\n",
        "for feature in object_columns.columns:\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Convert the column to string type\n",
        "    train[feature] = train[feature].astype(str)\n",
        "    le.fit(train[feature])\n",
        "    train[feature] = le.transform(train[feature])\n",
        "\n",
        "    # Make sure the test set has the same data type\n",
        "    test[feature] = test[feature].astype(str)\n",
        "\n",
        "    # Handle unseen labels in the test set\n",
        "    for label in np.unique(test[feature]):\n",
        "        if label not in le.classes_:\n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "\n",
        "    test[feature] = le.transform(test[feature])"
      ],
      "metadata": {
        "id": "Cqw5DmTsbPXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAoxi-kUbPUc",
        "outputId": "9125fd26-299c-4a16-8bd5-b5bda9ed2c87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
        "from math import sqrt\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xhbCC-oDbPSZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=False)"
      ],
      "metadata": {
        "id": "dS_dmoZlbZGi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse_scorer(y_true, y_pred):\n",
        "    return sqrt(mean_squared_error(y_true, y_pred))"
      ],
      "metadata": {
        "id": "10I-DNCUbZEq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train.drop(['TARGET','keyword' ,'traffic_medium','device'], axis=1)\n",
        "y = train['TARGET']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 43)"
      ],
      "metadata": {
        "id": "1KWVii7UbZCD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(random_state=43)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "rf_rmse = rmse_scorer(y_test, rf_predictions)\n",
        "\n",
        "\n",
        "# Extra Trees\n",
        "et_model = ExtraTreesRegressor(random_state=43)\n",
        "et_model.fit(X_train, y_train)\n",
        "et_predictions = et_model.predict(X_test)\n",
        "et_scores = cross_val_score(et_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "et_rmse = rmse_scorer(y_test, et_predictions)\n",
        "\n",
        "#xgb\n",
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_rmse = rmse_scorer(y_test, xgb_predictions)\n",
        "\n",
        "#cat\n",
        "cat_model = CatBoostRegressor(random_seed=43, l2_leaf_reg=4, verbose=0)\n",
        "cat_model.fit(X_train, y_train)\n",
        "cat_predictions = cat_model.predict(X_test)\n",
        "cat_scores = cross_val_score(cat_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "cat_rmse = rmse_scorer(y_test, cat_predictions)\n",
        "\n",
        "#lgb\n",
        "lgb_model = LGBMRegressor(random_state=43, reg_lambda=4)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "lgb_predictions = lgb_model.predict(X_test)\n",
        "lgb_scores = cross_val_score(lgb_model, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "lgb_rmse = rmse_scorer(y_test, lgb_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IvuFl-xbY_z",
        "outputId": "b1cf67e9-c557-490d-8d44-65961db1c0ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007236 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1236\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004722 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1218\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1216\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011365 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1216\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006025 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1219\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004940 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1221\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basic\n",
        "print(f'Random Forest Cross-Validation RMSE: {rf_scores.mean()}')\n",
        "print(f'RF test RMSE: {rf_rmse}\\n')\n",
        "print(f'Extra Trees Cross-Validation RMSE: {et_scores.mean()}')\n",
        "print(f'ET test RMSE: {et_rmse}\\n')\n",
        "print(f'XGBoost Cross-Validation RMSE: {xgb_scores.mean()}')\n",
        "print(f'XGBoost test RMSE: {xgb_rmse}\\n')\n",
        "print(f'CatBoost Cross-Validation RMSE: {cat_scores.mean()}')\n",
        "print(f'CatBoost test RMSE: {cat_rmse}\\n')\n",
        "print(f\"Cross-validated LightGBM scores: {lgb_scores.mean()}\")\n",
        "print(f\"LightGBM RMSE on test set: {lgb_rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdxHcZNGbu2r",
        "outputId": "04986f65-1124-43f1-89c4-01a1001e4d0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Cross-Validation RMSE: 2.8772603501599288\n",
            "RF test RMSE: 2.787345470753536\n",
            "\n",
            "Extra Trees Cross-Validation RMSE: 2.9151268400916703\n",
            "ET test RMSE: 2.9101033585414218\n",
            "\n",
            "XGBoost Cross-Validation RMSE: 2.8491038194831644\n",
            "XGBoost test RMSE: 2.745348382572756\n",
            "\n",
            "CatBoost Cross-Validation RMSE: 2.7631369388930205\n",
            "CatBoost test RMSE: 2.7357731787807276\n",
            "\n",
            "Cross-validated LightGBM scores: 2.750722150406905\n",
            "LightGBM RMSE on test set: 2.7743799222694636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop 'keyword' ,'traffic_medium','device'\n",
        "print(f'Random Forest Cross-Validation RMSE: {rf_scores.mean()}')\n",
        "print(f'RF test RMSE: {rf_rmse}\\n')\n",
        "print(f'Extra Trees Cross-Validation RMSE: {et_scores.mean()}')\n",
        "print(f'ET test RMSE: {et_rmse}\\n')\n",
        "print(f'XGBoost Cross-Validation RMSE: {xgb_scores.mean()}')\n",
        "print(f'XGBoost test RMSE: {xgb_rmse}\\n')\n",
        "print(f'CatBoost Cross-Validation RMSE: {cat_scores.mean()}')\n",
        "print(f'CatBoost test RMSE: {cat_rmse}\\n')\n",
        "print(f\"Cross-validated LightGBM scores: {lgb_scores.mean()}\")\n",
        "print(f\"LightGBM RMSE on test set: {lgb_rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46HX6r-DheIk",
        "outputId": "d6d9737c-dafe-4232-d926-e58696423a74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Cross-Validation RMSE: 2.8670504774502477\n",
            "RF test RMSE: 2.812503055608758\n",
            "\n",
            "Extra Trees Cross-Validation RMSE: 2.9281515668953237\n",
            "ET test RMSE: 2.921826705209167\n",
            "\n",
            "XGBoost Cross-Validation RMSE: 2.8687832089766863\n",
            "XGBoost test RMSE: 2.773079692905336\n",
            "\n",
            "CatBoost Cross-Validation RMSE: 2.7775146436911076\n",
            "CatBoost test RMSE: 2.7646066612403573\n",
            "\n",
            "Cross-validated LightGBM scores: 2.751366832121126\n",
            "LightGBM RMSE on test set: 2.7803121117453795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "voting_regressor = VotingRegressor([('xgb', xgb_model), ('catboost', cat_model),('lgb',lgb_model),('et',et_model),('rf',rf_model)])\n",
        "#   #cat_model로 수정필요,  weights=[1.5, 1.5, 1, 1, 1.5]\n",
        "voting_regressor.fit(X_train, y_train)\n",
        "\n",
        "voting_predictions = voting_regressor.predict(X_test)\n",
        "\n",
        "voting_rmse = rmse_scorer(y_test, voting_predictions)\n",
        "voting_scores = cross_val_score(voting_regressor, X_train, y_train, cv=kf, scoring=make_scorer(rmse_scorer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLe1n8qNcnfo",
        "outputId": "7d7421ad-356f-4144-8054-d6925df777ff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006059 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1236\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006013 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1218\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1216\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004833 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1216\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004800 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1219\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004784 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1221\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'VotingRegressor Cross-Validation RMSE: {voting_scores.mean()}')\n",
        "print(f'VotingRegressor test RMSE: {voting_rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_i8MpC7crff",
        "outputId": "8d4c693d-e207-4bb8-8975-79134e686d5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingRegressor Cross-Validation RMSE: 2.721710996963167\n",
            "VotingRegressor test RMSE: 2.6907786729299086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop 'keyword' ,'traffic_medium','device'\n",
        "print(f'VotingRegressor Cross-Validation RMSE: {voting_scores.mean()}')\n",
        "print(f'VotingRegressor test RMSE: {voting_rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9VtH1Duhkfb",
        "outputId": "94da32c8-12be-4e7a-d82b-4a9777fc130b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingRegressor Cross-Validation RMSE: 2.725913937034029\n",
            "VotingRegressor test RMSE: 2.707253121736505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop 'keyword' ,'traffic_medium','device' test\n",
        "print(f'VotingRegressor Cross-Validation RMSE: {voting_scores.mean()}')\n",
        "print(f'VotingRegressor test RMSE: {voting_rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftKWv8bMweL_",
        "outputId": "fed72700-d42d-4ca3-a735-c00bddf6300a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingRegressor Cross-Validation RMSE: 2.725913937034029\n",
            "VotingRegressor test RMSE: 2.707253121736505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(random_state=43)\n",
        "rf_model.fit(X_train.drop(['browser','bounced','device'],axis=1), y_train)\n",
        "rf_predictions = rf_model.predict(X_test.drop(['browser','bounced','device'],axis=1))\n",
        "rf_scores = cross_val_score(rf_model, X_train.drop(['browser','bounced','device'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "rf_rmse = rmse_scorer(y_test, rf_predictions)\n",
        "\n",
        "\n",
        "# Extra Trees\n",
        "et_model = ExtraTreesRegressor(random_state=43)\n",
        "et_model.fit(X_train.drop(['device', 'keyword', 'transaction_revenue'],axis=1), y_train)\n",
        "et_predictions = et_model.predict(X_test.drop(['device', 'keyword', 'transaction_revenue'],axis=1))\n",
        "et_scores = cross_val_score(et_model, X_train.drop(['device', 'keyword', 'transaction_revenue'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "et_rmse = rmse_scorer(y_test, et_predictions)\n",
        "\n",
        "#xgb\n",
        "xgb_model = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "xgb_model.fit(X_train.drop(['device', 'subcontinent', 'keyword'],axis=1), y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test.drop(['device', 'subcontinent', 'keyword'],axis=1))\n",
        "xgb_scores = cross_val_score(xgb_model, X_train.drop(['device', 'subcontinent', 'keyword'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_rmse = rmse_scorer(y_test, xgb_predictions)\n",
        "\n",
        "xgb_model2 = xgb.XGBRegressor(random_state=43, reg_lambda=4)\n",
        "xgb_model2.fit(X_train.drop(['device', 'transaction', 'traffic_medium'],axis=1), y_train)\n",
        "xgb_predictions2 = xgb_model2.predict(X_test.drop(['device', 'transaction', 'traffic_medium'],axis=1))\n",
        "xgb_scores2 = cross_val_score(xgb_model2, X_train.drop(['device', 'transaction', 'traffic_medium'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "xgb_rmse2 = rmse_scorer(y_test, xgb_predictions2)\n",
        "\n",
        "#cat\n",
        "cat_model = CatBoostRegressor(random_seed=43, l2_leaf_reg=4, verbose=0)\n",
        "cat_model.fit(X_train.drop(['browser', 'OS', 'bounced'],axis=1), y_train)\n",
        "cat_predictions = cat_model.predict(X_test.drop(['browser', 'OS', 'bounced'],axis=1))\n",
        "cat_scores = cross_val_score(cat_model, X_train.drop(['browser', 'OS', 'bounced'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "cat_rmse = rmse_scorer(y_test, cat_predictions)\n",
        "\n",
        "#lgb\n",
        "lgb_model = LGBMRegressor(random_state=43, reg_lambda=4)\n",
        "lgb_model.fit(X_train.drop(['device', 'keyword', 'transaction_revenue', 'subcontinent'],axis=1), y_train)\n",
        "lgb_predictions = lgb_model.predict(X_test.drop(['device', 'keyword', 'transaction_revenue', 'subcontinent'],axis=1))\n",
        "lgb_scores = cross_val_score(lgb_model, X_train.drop(['device', 'keyword', 'transaction_revenue', 'subcontinent'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "lgb_rmse = rmse_scorer(y_test, lgb_predictions)\n",
        "\n",
        "#lgb\n",
        "lgb_model2 = LGBMRegressor(random_state=43, reg_lambda=4)\n",
        "lgb_model2.fit(X_train.drop(['device', 'browser', 'traffic_medium', 'referral_path'],axis=1), y_train)\n",
        "lgb_predictions2 = lgb_model2.predict(X_test.drop(['device', 'browser', 'traffic_medium', 'referral_path'],axis=1))\n",
        "lgb_scores2 = cross_val_score(lgb_model2, X_train.drop(['device', 'browser', 'traffic_medium', 'referral_path'],axis=1), y_train, cv=kf, scoring=make_scorer(rmse_scorer))\n",
        "lgb_rmse2 = rmse_scorer(y_test, lgb_predictions2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi3tMVhxbY9o",
        "outputId": "43a82cff-b95b-4b9c-f881-f024d27aba7b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005862 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 965\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004517 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 946\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005262 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004579 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 945\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005453 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 947\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 949\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592545\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007630 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1050\n",
            "[LightGBM] [Info] Number of data points in the train set: 176602, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593011\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1036\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593406\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1037\n",
            "[LightGBM] [Info] Number of data points in the train set: 141281, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.593491\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005363 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1033\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592977\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005036 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1036\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1038\n",
            "[LightGBM] [Info] Number of data points in the train set: 141282, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 3.592545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization\n",
        "print(f'Random Forest Cross-Validation RMSE: {rf_scores.mean()}')\n",
        "print(f'RF test RMSE: {rf_rmse}\\n')\n",
        "print(f'Extra Trees Cross-Validation RMSE: {et_scores.mean()}')\n",
        "print(f'ET test RMSE: {et_rmse}\\n')\n",
        "print(f'XGBoost Cross-Validation RMSE: {xgb_scores.mean()}')\n",
        "print(f'XGBoost test RMSE: {xgb_rmse}\\n')\n",
        "print(f'XGBoost Cross-Validation RMSE: {xgb_scores2.mean()}')\n",
        "print(f'XGBoost test RMSE: {xgb_rmse2}\\n')\n",
        "print(f'CatBoost Cross-Validation RMSE: {cat_scores.mean()}')\n",
        "print(f'CatBoost test RMSE: {cat_rmse}\\n')\n",
        "print(f\"Cross-validated LightGBM scores: {lgb_scores.mean()}\")\n",
        "print(f\"LightGBM RMSE on test set: {lgb_rmse}\\n\")\n",
        "print(f\"Cross-validated LightGBM scores: {lgb_scores2.mean()}\")\n",
        "print(f\"LightGBM RMSE on test set: {lgb_rmse2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gejho0i6bywG",
        "outputId": "4a926a4c-10d6-4fa4-df93-92a4a795da6c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Cross-Validation RMSE: 2.898682113834506\n",
            "RF test RMSE: 2.840535879997574\n",
            "\n",
            "Extra Trees Cross-Validation RMSE: 2.932161278546251\n",
            "ET test RMSE: 2.9187279938954465\n",
            "\n",
            "XGBoost Cross-Validation RMSE: 2.8544205391339\n",
            "XGBoost test RMSE: 2.7550007033393524\n",
            "\n",
            "XGBoost Cross-Validation RMSE: 2.8842926588142146\n",
            "XGBoost test RMSE: 2.7609070243830485\n",
            "\n",
            "CatBoost Cross-Validation RMSE: 2.8127841597219634\n",
            "CatBoost test RMSE: 2.8296627668725565\n",
            "\n",
            "Cross-validated LightGBM scores: 2.761286572480066\n",
            "LightGBM RMSE on test set: 2.7674292612011238\n",
            "\n",
            "Cross-validated LightGBM scores: 2.759969462055403\n",
            "LightGBM RMSE on test set: 2.7899963066913798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Cross-Validation RMSE: 2.8772603501599288\n",
        "# RF test RMSE: 2.787345470753536\n",
        "\n",
        "# Extra Trees Cross-Validation RMSE: 2.9151268400916703\n",
        "# ET test RMSE: 2.9101033585414218\n",
        "\n",
        "# XGBoost Cross-Validation RMSE: 2.8491038194831644\n",
        "# XGBoost test RMSE: 2.745348382572756\n",
        "\n",
        "# CatBoost Cross-Validation RMSE: 2.7631369388930205\n",
        "# CatBoost test RMSE: 2.7357731787807276\n",
        "\n",
        "# Cross-validated LightGBM scores: 2.750722150406905\n",
        "# LightGBM RMSE on test set: 2.7743799222694636"
      ],
      "metadata": {
        "id": "QIqCFYYugYBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_mean = rmse_scorer(y_test, (lgb_predictions + rf_predictions + et_predictions + xgb_predictions + cat_predictions+\n",
        "                                 xgb_predictions2 + lgb_predictions2)/6)\n",
        "rmse_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ0vCyz2dU7R",
        "outputId": "44defe2a-05e1-4310-efb1-2b1538e5752a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8611968648301067"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}